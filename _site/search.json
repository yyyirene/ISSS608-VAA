[
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html",
    "title": "In class Exercise 5",
    "section": "",
    "text": "Jsonlite\nWe will transform the json data into table format\n\npacman::p_load(tidygraph, ggraph, \n               tidyverse, graphlayouts, \n               concaveman, ggforce,SmartEDA,jsonlite)\n\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\nInspect structure\n\nstr(kg,max.level=1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\nExtract and Inspect\n\nnodes_tbl&lt;-as_tibble(kg$nodes)\nedges_tbl&lt;-as_tibble(kg$links)\n\nNode type will change to node.type\nInitial EDA\n\nggplot(data = edges_tbl,aes(y=`Edge Type`))+\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = nodes_tbl,aes(y=`Node Type`))+\n  geom_bar()\n\n\n\n\n\n\n\n\nstep 1:Mapping from node id to row index\n\nid_map &lt;- tibble(id=nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)\n                 ))\n\nThis ensure each id from your node list is mapped to the correct row number.\nstep 2:Map source and target IDS to row indices\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index ) %&gt;% \n  left_join(id_map, by = c (\"target\"= \"id\")) %&gt;% \n  rename(to = index )\n\nstep 3 ：filter out any unmatched (invalid) edges\n\nedges_tbl&lt;-edges_tbl %&gt;% \n  filter(!is.na(from), !is.na(to))\n\nstep 4:creating the graph\n\ngraph &lt;- tbl_graph( nodes = nodes_tbl,\n                    edges = edges_tbl,\n                    directed = kg$directed)\ngraph\n\n# A tbl_graph: 17412 nodes and 37857 edges\n#\n# A directed multigraph with 16 components\n#\n# Node Data: 17,412 × 10 (active)\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;  &lt;chr&gt;        &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt; &lt;chr&gt;       \n 1 Song        Breaking Th… TRUE   2017         Ocea… TRUE        0 &lt;NA&gt;        \n 2 Person      Carlos Duffy NA     &lt;NA&gt;         &lt;NA&gt;  NA          1 &lt;NA&gt;        \n 3 Person      Min Qin      NA     &lt;NA&gt;         &lt;NA&gt;  NA          2 &lt;NA&gt;        \n 4 Person      Xiuying Xie  NA     &lt;NA&gt;         &lt;NA&gt;  NA          3 &lt;NA&gt;        \n 5 RecordLabel Nautical Mi… NA     &lt;NA&gt;         &lt;NA&gt;  NA          4 &lt;NA&gt;        \n 6 Song        Unshackled … FALSE  2026         Lo-F… TRUE        5 &lt;NA&gt;        \n 7 Person      Luke Payne   NA     &lt;NA&gt;         &lt;NA&gt;  NA          6 &lt;NA&gt;        \n 8 Person      Xiulan Zeng  NA     &lt;NA&gt;         &lt;NA&gt;  NA          7 &lt;NA&gt;        \n 9 Person      David Frank… NA     &lt;NA&gt;         &lt;NA&gt;  NA          8 &lt;NA&gt;        \n10 RecordLabel Colline-Cas… NA     &lt;NA&gt;         &lt;NA&gt;  NA          9 &lt;NA&gt;        \n# ℹ 17,402 more rows\n# ℹ 2 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;chr&gt;\n#\n# Edge Data: 37,857 × 6\n   from    to `Edge Type`      source target   key\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;             &lt;int&gt;  &lt;int&gt; &lt;int&gt;\n1     1  1842 InterpolatesFrom      0   1841     0\n2     1     5 RecordedBy            0      4     0\n3     2     1 PerformerOf           1      0     0\n# ℹ 37,854 more rows\n\n\nHere is truth\nVisualising the knowledge graph\nOnce have this ,will get back the same graph.\n\nset.seed(1234)\n\n\nggraph(graph,layout= \"fr\") +\n  geom_edge_link(alpha = 0.3,\n                 colour =\"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 4) +\n   geom_node_text(aes(label = name),\n                  repel = TRUE,\n                  size = 2.5) +\n    theme_void()\n\nit is not usual to visual\nStep 1 : Filter edges to only “Memberor”\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type`== \"MemberOf\")\n\nno link but still here\nStep 2 ：Extract only connected nodes\n(i,e., used in the these edges)\ndelete the often nodes\n\nuesed_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from , to )  %&gt;%\n  unlist () %&gt;%\n  unique()\n\nStep 3\n\ngraph_memberof &lt;-  graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% uesed_node_indices) %&gt;%\n  select(-row_id)\n\nneed time to invest\n\nggraph(graph_memberof, layout = \"fr\") +\n  geom_edge_link(alpha = 0.5, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), \n                  size = 1) +\n  geom_node_text(aes(label = name), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this chapter, we will learn the basic principles and essential components of ggplot2. At the same time, we will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter we will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\npacman::p_load(tidyverse,ggplot2,dplyr,qcc)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\n\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nAs you can see that the code chunk is relatively simple if R Graphics is used.\n\n\n\n\n\n\nTip\n\n\n\nKey Advantages of ggplot2 for Beginners: As pointed out by Hadley Wickham\n\nAutomatic Legends:\n\nggplot2 automatically generates legends based on aesthetics, saving beginners from manually coding them (as required in base R).\nEasy Faceting:\n\nggplot2 simplifies the creation of subplots using facet_wrap() or facet_grid(), whereas base R requires complex loops and layout setup.\nEncourages Tidy Data:\n\nWorking with ggplot2 promotes the use of tidy data, which aligns with good practices in R and integrates well with tools like dplyr and lm().\nBetter Visuals by Default:\n\nggplot2 produces cleaner, more visually appealing plots with minimal effort, making it more accessible for beginners.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive.\n\n\n\n\n\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\n\nLet us call the ggplot() function using the code chunk on the right.\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nggplot includes the x-axis and the axis’s label.\n\n\n\n\n\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n::: Be warned The y scale is not very useful, in fact it is very misleading. :::\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nNote that the default bin is 30.\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n1.7.6 Geometric Objects: geom-density()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThe default method used is loess.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale\n\n\n\n\n\nSingapore2017 &lt;- read_csv(\"data/Singapore-2017.csv\")\n\nRows: 21 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Age\ndbl (2): M, F\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nShow the code\ndf_long &lt;- Singapore2017 %&gt;%\n  pivot_longer(cols = c(\"M\", \"F\"), names_to = \"Gender\", values_to = \"Count\") %&gt;%\n  mutate(Gender = recode(Gender, \"M\" = \"Male\", \"F\" = \"Female\"))\n\ntotal_population &lt;- sum(df_long$Count)\n\ndf_long &lt;- df_long %&gt;%\n  mutate(Percent = Count / total_population * 100,\n         Percent = ifelse(Gender == \"Male\", -Percent, Percent))\n\ndf_long$Age &lt;- factor(df_long$Age,\n                      levels = unique(Singapore2017$Age)) \n\nggplot(df_long, aes(x = Age, y = Percent, fill = Gender)) +\n  geom_bar(stat = \"identity\", width = 0.9) +\n  coord_flip() +\n  scale_y_continuous(labels = function(x) paste0(abs(x), \"%\")) +\n  scale_fill_manual(values = c(\"Male\" = \"steelblue\", \"Female\" = \"lightcoral\")) +\n  labs(title = \"Singapore Population Pyramid (2017)\",\n       x = \"Age Group\", y = \"Population (%)\") +\n  theme_minimal() +\n  theme(legend.position = \"top\",\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ndefects &lt;- c(\n  shrink = 67,\n  porosity = 13,\n  weld_LOF = 9,\n  shell_inclusion = 6,\n  hard_alpha_inclusion = 3,\n  tungsten_inclusion = 1\n)\n\ndf &lt;- data.frame(\n  defect = names(defects),\n  freq = as.numeric(defects)\n) %&gt;%\n  arrange(desc(freq)) %&gt;%\n  mutate(\n    cum_freq = cumsum(freq),\n    cum_percent = cum_freq / sum(freq) * 100,\n    defect = factor(defect, levels = defect)  # 控制 x 轴顺序\n  )\n\n\nggplot(df, aes(x = defect, y = freq)) +\n  geom_col(fill = \"tomato\") +\n  geom_line(aes(y = cum_percent * max(freq) / 100), group = 1, color = \"steelblue\", size = 1) +\n  geom_point(aes(y = cum_percent * max(freq) / 100), color = \"steelblue\", size = 2) +\n  scale_y_continuous(\n    name = \"Defect Frequency\",\n    sec.axis = sec_axis(~ . * 100 / max(df$freq), name = \"Cumulative Percentage (%)\")\n  ) +\n  labs(\n    title = \"Pareto Chart of Titanium Defects\",\n    x = \"Defect Type\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title.y.right = element_text(color = \"steelblue\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nexam_long &lt;- exam_data %&gt;%\n  pivot_longer(cols = c(ENGLISH, MATHS, SCIENCE),\n               names_to = \"Subject\",\n               values_to = \"Score\")\n\nggplot(exam_long, aes(x = Score, fill = Subject)) +\n  geom_histogram(bins = 20, color = \"black\", alpha = 0.7) +\n  facet_wrap(~ Subject, scales = \"free\") +\n  labs(title = \"Trellis Display: Score Distribution by Subject\") +\n  theme_minimal()",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this chapter, we will learn the basic principles and essential components of ggplot2. At the same time, we will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter we will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics.",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Note\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\npacman::p_load(tidyverse,ggplot2,dplyr,qcc)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "R Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nAs you can see that the code chunk is relatively simple if R Graphics is used.\n\n\n\n\n\n\nTip\n\n\n\nKey Advantages of ggplot2 for Beginners: As pointed out by Hadley Wickham\n\nAutomatic Legends:\n\nggplot2 automatically generates legends based on aesthetics, saving beginners from manually coding them (as required in base R).\nEasy Faceting:\n\nggplot2 simplifies the creation of subplots using facet_wrap() or facet_grid(), whereas base R requires complex loops and layout setup.\nEncourages Tidy Data:\n\nWorking with ggplot2 promotes the use of tidy data, which aligns with good practices in R and integrates well with tools like dplyr and lm().\nBetter Visuals by Default:\n\nggplot2 produces cleaner, more visually appealing plots with minimal effort, making it more accessible for beginners.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive.",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "There are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Let us call the ggplot() function using the code chunk on the right.\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nggplot includes the x-axis and the axis’s label.",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Geometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n::: Be warned The y scale is not very useful, in fact it is very misleading. :::\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nNote that the default bin is 30.\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n1.7.6 Geometric Objects: geom-density()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThe default method used is loess.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Hadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#statistical-graphics-methods-week-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#statistical-graphics-methods-week-1",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Singapore2017 &lt;- read_csv(\"data/Singapore-2017.csv\")\n\nRows: 21 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Age\ndbl (2): M, F\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nShow the code\ndf_long &lt;- Singapore2017 %&gt;%\n  pivot_longer(cols = c(\"M\", \"F\"), names_to = \"Gender\", values_to = \"Count\") %&gt;%\n  mutate(Gender = recode(Gender, \"M\" = \"Male\", \"F\" = \"Female\"))\n\ntotal_population &lt;- sum(df_long$Count)\n\ndf_long &lt;- df_long %&gt;%\n  mutate(Percent = Count / total_population * 100,\n         Percent = ifelse(Gender == \"Male\", -Percent, Percent))\n\ndf_long$Age &lt;- factor(df_long$Age,\n                      levels = unique(Singapore2017$Age)) \n\nggplot(df_long, aes(x = Age, y = Percent, fill = Gender)) +\n  geom_bar(stat = \"identity\", width = 0.9) +\n  coord_flip() +\n  scale_y_continuous(labels = function(x) paste0(abs(x), \"%\")) +\n  scale_fill_manual(values = c(\"Male\" = \"steelblue\", \"Female\" = \"lightcoral\")) +\n  labs(title = \"Singapore Population Pyramid (2017)\",\n       x = \"Age Group\", y = \"Population (%)\") +\n  theme_minimal() +\n  theme(legend.position = \"top\",\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ndefects &lt;- c(\n  shrink = 67,\n  porosity = 13,\n  weld_LOF = 9,\n  shell_inclusion = 6,\n  hard_alpha_inclusion = 3,\n  tungsten_inclusion = 1\n)\n\ndf &lt;- data.frame(\n  defect = names(defects),\n  freq = as.numeric(defects)\n) %&gt;%\n  arrange(desc(freq)) %&gt;%\n  mutate(\n    cum_freq = cumsum(freq),\n    cum_percent = cum_freq / sum(freq) * 100,\n    defect = factor(defect, levels = defect)  # 控制 x 轴顺序\n  )\n\n\nggplot(df, aes(x = defect, y = freq)) +\n  geom_col(fill = \"tomato\") +\n  geom_line(aes(y = cum_percent * max(freq) / 100), group = 1, color = \"steelblue\", size = 1) +\n  geom_point(aes(y = cum_percent * max(freq) / 100), color = \"steelblue\", size = 2) +\n  scale_y_continuous(\n    name = \"Defect Frequency\",\n    sec.axis = sec_axis(~ . * 100 / max(df$freq), name = \"Cumulative Percentage (%)\")\n  ) +\n  labs(\n    title = \"Pareto Chart of Titanium Defects\",\n    x = \"Defect Type\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title.y.right = element_text(color = \"steelblue\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nexam_long &lt;- exam_data %&gt;%\n  pivot_longer(cols = c(ENGLISH, MATHS, SCIENCE),\n               names_to = \"Subject\",\n               values_to = \"Score\")\n\nggplot(exam_long, aes(x = Score, fill = Subject)) +\n  geom_histogram(bins = 20, color = \"black\", alpha = 0.7) +\n  facet_wrap(~ Subject, scales = \"free\") +\n  labs(title = \"Trellis Display: Score Distribution by Subject\") +\n  theme_minimal()",
    "crumbs": [
      "Home",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html",
    "title": "Hands on Exercise 8.3",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\n\n\n\n\n\n\nNGA_wp$wp_functional &lt;- as.numeric(as.character(NGA_wp$wp_functional))\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(\n    col = \"wp_functional\",\n    style = \"equal\",      \n    n = 10,              \n    palette = \"Blues\",    \n    title = \"Functional WPs\"  \n  ) +\n  tm_borders(lwd = 0.1) +   \n  tm_layout(\n    title = \"Distribution of functional water points by LGAs\",   \n    legend.position = c(\"right\", \"bottom\")                      \n  )\n\n\np2 &lt;- tm_shape(NGA_wp) + \n  tm_polygons(\n    col = \"total_wp\",         \n    style = \"equal\",          \n    n = 10,                   \n    palette = \"Blues\",         \n    title = \"Total water points\" \n  ) +\n  tm_borders(lwd = 0.1, alpha = 1) + \n  tm_layout(\n    legend.position = c(\"right\", \"bottom\"),\n    title = \"Distribution of total water point by LGAs\"\n  )\n\ntmap_mode(\"plot\")  \n\n\ntmap_arrange(p2, p1, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_polygons(\n    col = \"pct_functional\",   \n    style = \"equal\",          \n    n = 10,                   \n    palette = \"Blues\",        \n    title = \"Functional %\"\n  ) +\n  tm_borders(lwd = 0.1, alpha = 1) +\n  tm_layout(\n    title = \"Rate map of functional water point by LGAs\",\n    legend.position = c(\"right\", \"bottom\") \n  )\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#overview",
    "title": "Hands on Exercise 8.3",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#getting-started",
    "title": "Hands on Exercise 8.3",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#basic-choropleth-mapping",
    "title": "Hands on Exercise 8.3",
    "section": "",
    "text": "NGA_wp$wp_functional &lt;- as.numeric(as.character(NGA_wp$wp_functional))\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(\n    col = \"wp_functional\",\n    style = \"equal\",      \n    n = 10,              \n    palette = \"Blues\",    \n    title = \"Functional WPs\"  \n  ) +\n  tm_borders(lwd = 0.1) +   \n  tm_layout(\n    title = \"Distribution of functional water points by LGAs\",   \n    legend.position = c(\"right\", \"bottom\")                      \n  )\n\n\np2 &lt;- tm_shape(NGA_wp) + \n  tm_polygons(\n    col = \"total_wp\",         \n    style = \"equal\",          \n    n = 10,                   \n    palette = \"Blues\",         \n    title = \"Total water points\" \n  ) +\n  tm_borders(lwd = 0.1, alpha = 1) + \n  tm_layout(\n    legend.position = c(\"right\", \"bottom\"),\n    title = \"Distribution of total water point by LGAs\"\n  )\n\ntmap_mode(\"plot\")  \n\n\ntmap_arrange(p2, p1, nrow = 1)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#choropleth-map-for-rates",
    "title": "Hands on Exercise 8.3",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_polygons(\n    col = \"pct_functional\",   \n    style = \"equal\",          \n    n = 10,                   \n    palette = \"Blues\",        \n    title = \"Functional %\"\n  ) +\n  tm_borders(lwd = 0.1, alpha = 1) +\n  tm_layout(\n    title = \"Rate map of functional water point by LGAs\",\n    legend.position = c(\"right\", \"bottom\") \n  )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08C.html#extreme-value-maps",
    "title": "Hands on Exercise 8.3",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html",
    "title": "Hands-on Exercise 9A",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, we will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#overview",
    "title": "Hands-on Exercise 9A",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, we will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9A",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#data-preparation",
    "title": "Hands-on Exercise 9A",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09A.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 9A",
    "section": "",
    "text": "Use ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, we will learn how to create correlation matrix using pairs() of R Graphics. Next, we will learn how to plot corrgram using corrplot package of R. Lastly, we will learn how to create an interactive correlation matrix using plotly R.\n\n\n\nBefore we get started, we are required to open a new Quarto document. Keep the default html authoring format.\nNext, we will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type.\n\n\n\n\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\n\n\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package.\n\n\n\n\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\n\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#overview",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, we will learn how to create correlation matrix using pairs() of R Graphics. Next, we will learn how to plot corrgram using corrplot package of R. Lastly, we will learn how to create an interactive correlation matrix using plotly R.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "Before we get started, we are required to open a new Quarto document. Keep the default html authoring format.\nNext, we will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "In this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "There are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "One of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#building-multiple-plots",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "Since ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 9B",
    "section": "",
    "text": "In this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\n\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09B.html#r-packages",
    "title": "Hands-on Exercise 9B",
    "section": "R packages",
    "text": "R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.\n\n\n\n\nFor this exercise, the GGally, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12)) + \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\") + \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)+ \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1, size = 8))\n\n\n\n\n\n\n\n\n\n\n\n\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\nhistoVisibility &lt;- rep(TRUE, ncol(wh)) parallelPlot(wh, rotateTitle = TRUE, histoVisibility = histoVisibility)\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\n\n\n\n\nggparcoord() of GGally package\nparallelPlot",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#overview",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#installing-and-launching-r-packages",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "For this exercise, the GGally, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#data-preparation",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "In this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "In this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12)) + \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\") + \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)+ \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30,  hjust=1, size = 8))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1, size = 8))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "parallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\nhistoVisibility &lt;- rep(TRUE, ncol(wh)) parallelPlot(wh, rotateTitle = TRUE, histoVisibility = histoVisibility)\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09D.html#references",
    "title": "Hands on Exercise 9D",
    "section": "",
    "text": "ggparcoord() of GGally package\nparallelPlot",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9D"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, we will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, we will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse,grid,ggdist,\n               gridExtra,ggplot2) \n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"Exam_data.csv\",show_col_types = FALSE)\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_label_repel()\ngeom_label()\n\n\n\n\nAutomatically Avoid Overlap\nYes\nNo (labels may overlap)\n\n\nFont Style\nBold (fontface = \"bold\")\nDefault font\n\n\nLabel Position\nAutomatically calculated optimal position\nFixed position (centered horizontally, slightly above)\n\n\nAdaptability to Dense Points\nStrong\nWeak\n\n\nRequired Package\nRequires loading ggrepel package\nNo extra package required\n\n\n\n\n\n\n\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(gridExtra)\n\nbase_plot &lt;- function(theme_func, title_text) {\n  ggplot(data = exam_data, aes(x = MATHS)) +\n    geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") +\n    theme_func() +\n    ggtitle(title_text)\n}\n\np1 &lt;- base_plot(theme_bw,        \"theme_bw()\")\np2 &lt;- base_plot(theme_classic,   \"theme_classic()\")\np3 &lt;- base_plot(theme_dark,      \"theme_dark()\")\np4 &lt;- base_plot(theme_light,     \"theme_light()\")\np5 &lt;- base_plot(theme_linedraw,  \"theme_linedraw()\")\np6 &lt;- base_plot(theme_minimal,   \"theme_minimal()\")\np7 &lt;- base_plot(theme_void,      \"theme_void()\")\n\ngrid.arrange(p1, p2, p3,\n             p4, p5, p6,\n             p7, nullGrob(), nullGrob(),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat can we learn from the code chunk above?\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\n\n\n\n\n\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, we will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nNext\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\np2\n\n\n\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\n\n\nShow the code\np3 &lt;- ggplot(data=exam_data,\n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\") +\n  theme(plot.title = element_text(size = 11))\np3\n\n\n\n\n\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\np1 + gt::gt(exam_data[1:10,  c(\"ID\", \"ENGLISH\", \"MATHS\")])\n\n\n\n\n\n\n\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\nChange the plot to the right bottom:\n\n\nShow the code\np3 + inset_element(p2, \n                   left = 0.5,   \n                   bottom = 0,    \n                   right = 0.98,  \n                   top = 0.3)     \n\n\n\n\n\n\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\n\n\n\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_boxplot(fill = \"lightblue\") +\n  ggtitle(\"Boxplot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_violin(fill = \"plum\") +\n  ggtitle(\"Violin Plot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_boxplot(notch = TRUE, fill = \"lightcoral\") +\n  ggtitle(\"Notched Boxplot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.7) +\n  ggtitle(\"Dot Plot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(ggdist)\n\nggplot(exam_data, aes(x = GENDER, y = ENGLISH, fill = GENDER)) +\n  stat_halfeye(adjust = .5, width = .6, .width = 0, justification = -.2) +\n  geom_boxplot(width = .1, outlier.shape = NA, alpha = 0.5) +\n  geom_jitter(width = .05, alpha = 0.3) +\n  ggtitle(\"Raincloud Plot: English Scores by Gender\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nexam_data &lt;- exam_data %&gt;%\n  mutate(SCORE_LEVEL = ifelse(ENGLISH &gt;= mean(ENGLISH), \"Above\", \"Below\"))\n\nggplot(exam_data, aes(x = GENDER, fill = SCORE_LEVEL)) +\n  geom_bar(position = \"fill\") +\n  coord_flip() +\n  ggtitle(\"Diverging Stacked Bar: English Score Level by Gender\") +\n  scale_fill_manual(values = c(\"Above\" = \"skyblue\", \"Below\" = \"salmon\"))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, we will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, we will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse,grid,ggdist,\n               gridExtra,ggplot2) \n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"Exam_data.csv\",show_col_types = FALSE)\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "One of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_label_repel()\ngeom_label()\n\n\n\n\nAutomatically Avoid Overlap\nYes\nNo (labels may overlap)\n\n\nFont Style\nBold (fontface = \"bold\")\nDefault font\n\n\nLabel Position\nAutomatically calculated optimal position\nFixed position (centered horizontally, slightly above)\n\n\nAdaptability to Dense Points\nStrong\nWeak\n\n\nRequired Package\nRequires loading ggrepel package\nNo extra package required",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "ggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#other-theme-examples",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#other-theme-examples",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Show the code\nlibrary(ggplot2)\nlibrary(gridExtra)\n\nbase_plot &lt;- function(theme_func, title_text) {\n  ggplot(data = exam_data, aes(x = MATHS)) +\n    geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") +\n    theme_func() +\n    ggtitle(title_text)\n}\n\np1 &lt;- base_plot(theme_bw,        \"theme_bw()\")\np2 &lt;- base_plot(theme_classic,   \"theme_classic()\")\np3 &lt;- base_plot(theme_dark,      \"theme_dark()\")\np4 &lt;- base_plot(theme_light,     \"theme_light()\")\np5 &lt;- base_plot(theme_linedraw,  \"theme_linedraw()\")\np6 &lt;- base_plot(theme_minimal,   \"theme_minimal()\")\np7 &lt;- base_plot(theme_void,      \"theme_void()\")\n\ngrid.arrange(p1, p2, p3,\n             p4, p5, p6,\n             p7, nullGrob(), nullGrob(),\n             ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat can we learn from the code chunk above?\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "It is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, we will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nNext\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\np2\n\n\n\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\n\n\nShow the code\np3 &lt;- ggplot(data=exam_data,\n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\") +\n  theme(plot.title = element_text(size = 11))\np3\n\n\n\n\n\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#adding-table",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#adding-table",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "p1 + gt::gt(exam_data[1:10,  c(\"ID\", \"ENGLISH\", \"MATHS\")])\n\n\n\n\n\n\n\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\nChange the plot to the right bottom:\n\n\nShow the code\np3 + inset_element(p2, \n                   left = 0.5,   \n                   bottom = 0,    \n                   right = 0.98,  \n                   top = 0.3)     \n\n\n\n\n\n\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Patchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#visual-analytics-methods-of-the-week-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#visual-analytics-methods-of-the-week-2",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Show the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_boxplot(fill = \"lightblue\") +\n  ggtitle(\"Boxplot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_violin(fill = \"plum\") +\n  ggtitle(\"Violin Plot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_boxplot(notch = TRUE, fill = \"lightcoral\") +\n  ggtitle(\"Notched Boxplot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam_data, aes(x = GENDER, y = ENGLISH)) +\n  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.7) +\n  ggtitle(\"Dot Plot of English Scores by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(ggdist)\n\nggplot(exam_data, aes(x = GENDER, y = ENGLISH, fill = GENDER)) +\n  stat_halfeye(adjust = .5, width = .6, .width = 0, justification = -.2) +\n  geom_boxplot(width = .1, outlier.shape = NA, alpha = 0.5) +\n  geom_jitter(width = .05, alpha = 0.3) +\n  ggtitle(\"Raincloud Plot: English Scores by Gender\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nexam_data &lt;- exam_data %&gt;%\n  mutate(SCORE_LEVEL = ifelse(ENGLISH &gt;= mean(ENGLISH), \"Above\", \"Below\"))\n\nggplot(exam_data, aes(x = GENDER, fill = SCORE_LEVEL)) +\n  geom_bar(position = \"fill\") +\n  coord_flip() +\n  ggtitle(\"Diverging Stacked Bar: English Score Level by Gender\") +\n  scale_fill_manual(values = c(\"Above\" = \"skyblue\", \"Below\" = \"salmon\"))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html",
    "title": "Hands-on Ex4A",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe plotThe code chunk\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#learning-outcome",
    "title": "Hands-on Ex4A",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#getting-started",
    "title": "Hands-on Ex4A",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Ex4A",
    "section": "",
    "text": "Figure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Ex4A",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe plotThe code chunk\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html",
    "title": "Hands-on_Ex04C",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe codeThe Table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist)\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n#95%-99%\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width =c(0.95, 0.99),   \n    show.legend = FALSE\n  ) +\n  labs(\n    title = \"Visualising 95% and 99% Confidence Intervals of Mean Math Score\",\n    subtitle = \"Mean Point + Multiple-Interval Plot\",\n    x = \"Race\",\n    y = \"Math Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n#95%\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#learning-outcome",
    "title": "Hands-on_Ex04C",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#getting-started",
    "title": "Hands-on_Ex04C",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on_Ex04C",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe codeThe Table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on_Ex04C",
    "section": "",
    "text": "ggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist)\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n#95%-99%\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width =c(0.95, 0.99),   \n    show.legend = FALSE\n  ) +\n  labs(\n    title = \"Visualising 95% and 99% Confidence Intervals of Mean Math Score\",\n    subtitle = \"Mean Point + Multiple-Interval Plot\",\n    x = \"Race\",\n    y = \"Math Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n#95%\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on_Ex04C",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html",
    "title": "Hands-on Exercise3B",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, we will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.\n\n\n\n\n\n\n\n\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"chap03/data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')          \n\n\n\n\n\n\n\n\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp\n\n\n\n\n\n\n\n\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#overview",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#overview",
    "title": "Hands-on Exercise3B",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, we will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#getting-started",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#getting-started",
    "title": "Hands-on Exercise3B",
    "section": "",
    "text": "First, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"chap03/data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise3B",
    "section": "",
    "text": "gganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise3B",
    "section": "",
    "text": "In Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#reference",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03B.html#reference",
    "title": "Hands-on Exercise3B",
    "section": "",
    "text": "Getting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#the-scene",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#the-scene",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take Home Exercise 1",
    "section": "Objectives",
    "text": "Objectives\nAssuming the role of the graphical editor of the media company, we are tasked to prepare at most three data visualisation for the article.",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#data-acquisition",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#data-acquisition",
    "title": "Take Home Exercise 1",
    "section": "Data Acquisition",
    "text": "Data Acquisition\nSingapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 A csv file from Department of Statistics, Singapore (DOS)",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#getting-start",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#getting-start",
    "title": "Take Home Exercise 1",
    "section": "Getting start",
    "text": "Getting start\n\nInstalling and Loading R packages\nIn this project,we are going to use the packages as below:\n\ntidyverse – A collection of R packages for data science, including tools for data wrangling and visualization.\nggplot2 – A grammar-based system for creating elegant and complex graphics in R.\ndplyr – A package for fast, intuitive data manipulation using verbs like filter, mutate, and summarise.\nqcc – Tools for statistical quality control charts such as control charts and capability analysis.\npatchwork – Helps combine multiple ggplot2 plots into one graphic layout easily.\ntreemapify – Allows creation of treemaps using ggplot2 syntax to visualize part-to-whole relationships.\nggridges – Enables ridge plots (joyplots) to show distributions across categories.\nggdist – Extends ggplot2 to visualize distributions, uncertainty, and intervals.\nforcats – Simplifies working with categorical (factor) variables in R.\nviridis – Provides colorblind-friendly and perceptually uniform color palettes for plots.\nscales – Formats plot axis labels, legends, and color scales (e.g., commas, percentages).\n\n\npacman::p_load(tidyverse,ggplot2,dplyr,qcc,patchwork,treemapify,ggridges,ggdist,forcats,viridis,scales)",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take Home Exercise 1",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n1.Importing Data\n\nS_data &lt;- read_csv(\"data/respopagesex2024.csv\",show_col_types = FALSE)\n\n\n\n2.Data information\n\npurrr::map_chr(S_data, typeof)\n\n         PA          SZ         Age         Sex         Pop        Time \n\"character\" \"character\" \"character\" \"character\"    \"double\"    \"double\" \n\n\n\n\n\nColumn Headers\nHeaders Info\nData Type\n\n\n\n\nPA\nPlanning Area\nCharacter\n\n\nSZ\nSubzone\nCharacter\n\n\nAge\nSingle Year of Age\nCharacter\n\n\nSex\nSex\nCharacter\n\n\nPop\nResident Count\nDouble\n\n\nTime\nTime/Period\nDouble\n\n\n\n\n\n3.Checking for Missing Values\n\nS_data %&gt;%\n  summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 × 6\n     PA    SZ   Age   Sex   Pop  Time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     0     0     0     0     0     0\n\n\nAs shown from the result,the dataset S_data is clean in terms of missing data — there are no NA values in any of the columns.\n\n\n4.Checking for Duplicates\nThe first one returns the number of duplicated rows, while the second one helps you view the actual duplicated rows in the dataset.\n\n# Check if there are exact duplicate rows\nS_data %&gt;%\n  duplicated() %&gt;%\n  sum()\n\n[1] 0\n\n# View specific rows that are repeated\nS_data %&gt;%\n  filter(duplicated(.))\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PA &lt;chr&gt;, SZ &lt;chr&gt;, Age &lt;chr&gt;, Sex &lt;chr&gt;, Pop &lt;dbl&gt;,\n#   Time &lt;dbl&gt;\n\n\nThe dataset S_data contains no exact duplicate rows. All records are unique.\n\n\n5.Binning Numerical Variables\n\nAge: The age variable is divided into 19 categories, spanning from 0 to 90+ years old , with 4-year intervals (e.g., 0-4, 5-9, 10-14, etc.).\n\n\nunique(S_data$Age)\n\n [1] \"0\"           \"1\"           \"2\"           \"3\"           \"4\"          \n [6] \"5\"           \"6\"           \"7\"           \"8\"           \"9\"          \n[11] \"10\"          \"11\"          \"12\"          \"13\"          \"14\"         \n[16] \"15\"          \"16\"          \"17\"          \"18\"          \"19\"         \n[21] \"20\"          \"21\"          \"22\"          \"23\"          \"24\"         \n[26] \"25\"          \"26\"          \"27\"          \"28\"          \"29\"         \n[31] \"30\"          \"31\"          \"32\"          \"33\"          \"34\"         \n[36] \"35\"          \"36\"          \"37\"          \"38\"          \"39\"         \n[41] \"40\"          \"41\"          \"42\"          \"43\"          \"44\"         \n[46] \"45\"          \"46\"          \"47\"          \"48\"          \"49\"         \n[51] \"50\"          \"51\"          \"52\"          \"53\"          \"54\"         \n[56] \"55\"          \"56\"          \"57\"          \"58\"          \"59\"         \n[61] \"60\"          \"61\"          \"62\"          \"63\"          \"64\"         \n[66] \"65\"          \"66\"          \"67\"          \"68\"          \"69\"         \n[71] \"70\"          \"71\"          \"72\"          \"73\"          \"74\"         \n[76] \"75\"          \"76\"          \"77\"          \"78\"          \"79\"         \n[81] \"80\"          \"81\"          \"82\"          \"83\"          \"84\"         \n[86] \"85\"          \"86\"          \"87\"          \"88\"          \"89\"         \n[91] \"90_and_Over\"\n\n\nAs seen in the value “90_and_Over”,We need to change it into Numeric for better bin and Create Age_group 19 bins\n\n\nCode-Binning Numerical Variables\nS_data &lt;- S_data %&gt;%\n  mutate(\n    Age = as.character(Age),                            \n    Age_num = suppressWarnings(as.numeric(Age)),        \n    Age_Group = case_when(\n      Age == \"90_and_Over\"              ~ \"90_and_Over\",\n      Age_num &gt;= 0  & Age_num &lt;= 4      ~ \"0-4\",\n      Age_num &gt;= 5  & Age_num &lt;= 9      ~ \"5-9\",\n      Age_num &gt;= 10 & Age_num &lt;= 14     ~ \"10-14\",\n      Age_num &gt;= 15 & Age_num &lt;= 19     ~ \"15-19\",\n      Age_num &gt;= 20 & Age_num &lt;= 24     ~ \"20-24\",\n      Age_num &gt;= 25 & Age_num &lt;= 29     ~ \"25-29\",\n      Age_num &gt;= 30 & Age_num &lt;= 34     ~ \"30-34\",\n      Age_num &gt;= 35 & Age_num &lt;= 39     ~ \"35-39\",\n      Age_num &gt;= 40 & Age_num &lt;= 44     ~ \"40-44\",\n      Age_num &gt;= 45 & Age_num &lt;= 49     ~ \"45-49\",\n      Age_num &gt;= 50 & Age_num &lt;= 54     ~ \"50-54\",\n      Age_num &gt;= 55 & Age_num &lt;= 59     ~ \"55-59\",\n      Age_num &gt;= 60 & Age_num &lt;= 64     ~ \"60-64\",\n      Age_num &gt;= 65 & Age_num &lt;= 69     ~ \"65-69\",\n      Age_num &gt;= 70 & Age_num &lt;= 74     ~ \"70-74\",\n      Age_num &gt;= 75 & Age_num &lt;= 79     ~ \"75-79\",\n      Age_num &gt;= 80 & Age_num &lt;= 84     ~ \"80-84\",\n      Age_num &gt;= 85 & Age_num &lt;= 89     ~ \"85-89\",\n      TRUE ~ NA_character_\n    )\n  )\n\n\n\n\n6.Data preparation\n6.1Data preparation for Region :\n\nMapping Planning Area (PA) to Region: A reference table is manually constructed to assign each Planning Area to one of Singapore’s five broad Regions (e.g., North, East). This enables aggregation and comparison at the regional level.\nExpanding Data and Merging Region Info:\nThe dataset is expanded using uncount() to generate one row per individual based on the population count (Pop). Then, left_join() integrates the region information into the dataset. This transformation facilitates detailed demographic breakdowns by Region, Age, and Gender in subsequent analysis and plots.\n\n\n\nCode-Data preparation for Region\nregion_map &lt;- tibble::tibble(\n  PA = c(\n    \"Ang Mo Kio\", \"Bedok\", \"Bishan\", \"Bukit Batok\", \"Bukit Merah\",\n    \"Bukit Panjang\", \"Bukit Timah\", \"Central Water Catchment\", \"Changi\",\n    \"Choa Chu Kang\", \"Clementi\", \"Downtown Core\", \"Geylang\", \"Hougang\",\n    \"Jurong East\", \"Jurong West\", \"Kallang\", \"Mandai\", \"Marine Parade\",\n    \"Novena\", \"Orchard\", \"Outram\", \"Pasir Ris\", \"Punggol\", \"Queenstown\",\n    \"River Valley\", \"Rochor\", \"Sembawang\", \"Sengkang\", \"Serangoon\",\n    \"Simpang\", \"Tampines\", \"Tanglin\", \"Tengah\", \"Toa Payoh\", \"Tuas\",\n    \"Western Islands\", \"Western Water Catchment\", \"Woodlands\", \"Yishun\",\n    \"Seletar\", \"Southern Islands\", \"Singapore River\", \"Museum\", \"Newton\",\n    \"Straits View\", \"Sungei Kadut\", \"North-Eastern Islands\", \"Marina East\",\n    \"Marina South\"\n  ),\n  Region = c(\n    \"North\", \"East\", \"North\", \"West\", \"South\",\n    \"West\", \"South\", \"South\", \"East\",\n    \"West\", \"West\", \"South\", \"South\", \"North\",\n    \"West\", \"West\", \"South\", \"North\", \"East\",\n    \"South\", \"South\", \"South\", \"East\", \"East\", \"South\",\n    \"South\", \"South\", \"North\", \"East\", \"East\",\n    \"North\", \"East\", \"South\", \"West\", \"South\", \"West\",\n    \"West\", \"West\", \"North\", \"North\",\n    \"East\", \"South\", \"South\", \"South\", \"South\",\n    \"South\", \"North\", \"East\", \"East\", \"East\"\n  )\n)\n\n# Step 2: Merge Region into S_data\ndf_long_region &lt;- S_data %&gt;%\n  uncount(weights = Pop) %&gt;%\n  left_join(region_map, by = \"PA\")\n\n\n6.2 Data preparation for Age :\n\nGroup by Age Group and Sex: Aggregates population counts (Pop) to get total individuals for each combination of age group and gender.\nCalculate Gender-wise Percentage: Within each gender group, computes what proportion each age group represents as a percentage.\nCreate Plot-ready Columns:\n\nPop_plot: Multiplies male values by -1 to align them to the left in a population pyramid.\nPerc_plot: Same logic, but for percentage values.\nLabel_pop and Label_perc: Format population and percentage for cleaner label display in the plot.\n\nSet Age Group Factor Levels:\nEnsures age groups are ordered from youngest to oldest in the vertical axis of the pyramid.1.\nDefine Age Group Order:\nOriginal Age_Group classification and Manually define a logical order for Age_Group using factor(levels = ...) to ensure the y-axis in the plot appears from youngest to oldest.\n\n\n\nCode-Data preparation for Age\npyramid_data &lt;- S_data %&gt;%\n  group_by(Age_Group, Sex) %&gt;%\n  summarise(Population = sum(Pop), .groups = \"drop\") %&gt;%\n  group_by(Sex) %&gt;%\n  mutate(Percentage = Population / sum(Population) * 100) %&gt;%\n  mutate(\n    Pop_plot = ifelse(Sex == \"Males\", -Population, Population),\n    Perc_plot = ifelse(Sex == \"Males\", -Percentage, Percentage),\n    Label_pop = format(Population, big.mark = \",\"),  \n    Label_perc = paste0(round(Percentage, 1), \"%\")\n  )\n\nage_levels &lt;- c(\n  \"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\",\n  \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n  \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80-84\", \"85-89\", \"90_and_Over\"\n)\npyramid_data$Age_Group &lt;- factor(pyramid_data$Age_Group, levels = age_levels)\n\n#Keep original Age_Group classification and use factor to manually sort\nage_levels &lt;- c(\n  \"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\",\n  \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n  \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80-84\", \"85-89\", \"90_and_Over\"\n)\n\n\n6.3 Data preparation for desnsity:\n\nStandardize the Age Variable：\nConvert the Age variable into numeric format. The \"90_and_Over\" label is replaced with the numeric value 90 to allow proper statistical calculations (e.g., mean, density).\nExpand the Data by Population Count：\nTransform the dataset so each row represents one individual, replicating rows according to the Pop column (population count). This makes it suitable for density estimation.\nCompute Density Peaks and Median\nFor each gender:\nEstimate a density curve over age.\nIdentify the peak point (the age with the highest density) and Median point.\nStore the peak age and corresponding density value for annotation.\n\n\n\nCode-Data preparation for desnsity\n# Step 1: Clean the Age data with data type transformation\nS_data &lt;- S_data %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"90\", Age),\n         Age_numeric = as.numeric(Age))\n\n# Step 2: Expand to \"one row per person\"\nS_long &lt;- S_data %&gt;%\n  uncount(weights = Pop)\n\n# Step 3: Average age (mean)\navg_age &lt;- S_long %&gt;%\n  group_by(Sex) %&gt;%\n  summarise(mean_age = mean(Age_numeric))\n\n# Step 4: Density peak + y-coordinate adjustments for vertical separation\ndensity_peaks &lt;- S_long %&gt;%\n  group_by(Sex) %&gt;%\n  summarise(\n    peak_age = density(Age_numeric)$x[which.max(density(Age_numeric)$y)],\n    peak_density = max(density(Age_numeric)$y)\n  ) %&gt;%\n  mutate(\n    label_text = paste0(Sex, \": \", round(peak_age, 1)),\n    label_y = peak_density + ifelse(Sex == \"Males\", 0.0006, 0.0009)  \n  )\n\n# Step 5: Prepare mean_labels for bottom annotation\nmean_labels &lt;- avg_age %&gt;%\n  mutate(\n    label_text = paste0(round(mean_age, 1)),\n    label_y = 0.001,  \n    label_x = ifelse(Sex == \"Males\", mean_age - 8, mean_age + 5) \n  )\n\n# Step 4 : Median calculation with cleaning\ndf_long_region &lt;- df_long_region %&gt;%\n  mutate(\n    Age = ifelse(Age == \"90_and_Over\", \"90\", Age),  \n    Age = as.numeric(Age)                          \n  ) %&gt;%\n  filter(!is.na(Age))  \n\nmedian_age &lt;- median(df_long_region$Age)\ndf_median &lt;- data.frame(Median = median_age)\n\n\nmedian_age &lt;- median(df_long_region$Age, na.rm = TRUE)\ndf_median &lt;- data.frame(Median = median_age)\n\ndf_region_gender &lt;- df_long_region %&gt;%\n  filter(!is.na(Sex), !is.na(Region)) %&gt;%\n  group_by(Region, Sex) %&gt;%\n  summarise(n = n(), .groups = \"drop\")\n\n\n6.4 Data preparation for Multivariate relationship between Region × Age Group × Gender:\n\nGroup Data by Region, Age Group, and Gender\nUse group_by(Region, Age_Group, Sex) and summarise() to count the number of individuals (Pop) in each subgroup.\nConvert to Wide Format\nUse pivot_wider() to restructure the data so that each row contains counts of both Males and Females, facilitating ratio calculation.\nFill missing values with 0 to avoid calculation errors.\nCalculate Female-to-Male Ratio\nCreate a new variable SexRatio = Females / Males.\n\n\n\nCode-Data preparation for Heatmap\ndf_sex_ratio &lt;- df_long_region %&gt;%\n  filter(!is.na(Sex), !is.na(Age_Group)) %&gt;%\n  mutate(Age_Group = factor(Age_Group, levels = age_levels)) \n\n# Count the number of people in each Region + AgeGroup + Sex\ndf_grouped &lt;- df_sex_ratio %&gt;%\n  group_by(Region, Age_Group, Sex) %&gt;%\n  summarise(Pop = n(), .groups = \"drop\")\n\n# Convert to wide format, one line contains the number of female / male\ndf_wide &lt;- df_grouped %&gt;%\n  pivot_wider(names_from = Sex, values_from = Pop, values_fill = 0)\n\n# Calculating Female-to-Male Ratios\ndf_wide &lt;- df_wide %&gt;%\n  mutate(SexRatio = Females / ifelse(Males == 0, NA, Males))",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#data-analysis",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#data-analysis",
    "title": "Take Home Exercise 1",
    "section": "Data Analysis",
    "text": "Data Analysis\n\nI.Exploration of Singapore Population and Age Distribution by Gender (2024)\n1.1 Population pyramid using gender and age group information from S_data.And it shows the structural proportion of each group\n\n\nCode-Population pyramid\nP1 &lt;- ggplot(pyramid_data, aes(x = Age_Group, y = Perc_plot, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  \n  geom_text(aes(y = ifelse(Sex == \"Males\", Perc_plot - 0.6, Perc_plot + 0.6), \n                label = Label_perc),\n            size = 3, color = \"black\") +\n\n  scale_y_continuous(\n    limits = c(-10, 10),\n    breaks = seq(-10, 10, 2),\n    labels = function(x) paste0(abs(x), \"%\")\n  ) +\n\n  coord_flip() +\n  labs(title = \"Population Pyramid (2024)\",\n       x = \"Age Group\",\n       y = \"Population (%)\") +\n  scale_fill_manual(values = c(\"Males\" = \"#91C4F2\", \"Females\" = \"#F4B183\")) +\n  theme_minimal() +\n  theme(\n    axis.text = element_text(color = \"black\", face = \"bold\"),\n    axis.title = element_text(color = \"black\", face = \"plain\"),\n    plot.title.position = \"plot\",\n    \n  )\n\n\n1.2 Density Plot highlights where the population is most concentrated\n\n\nCode-Density Plot\n# Step 6: Plot\nP2 &lt;- ggplot(S_long, aes(x = Age_numeric, fill = Sex, color = Sex)) +\n  geom_density(alpha = 0.4, size = 1) +\n\n  # Vertical dashed mean line\n  geom_vline(data = avg_age, aes(xintercept = mean_age, color = Sex),\n             linetype = \"dashed\", size = 1) +\n\n  # Mean text near bottom\n  geom_text(data = mean_labels,\n            aes(x = label_x, y = label_y, label = label_text),\n            size = 4, color = \"black\", hjust = 0.2) +\n\n  # Peak text near top, vertically spaced\n  geom_text(data = density_peaks,\n            aes(x = peak_age, y = label_y, label = label_text),\n            size = 4, color = \"black\") +\n\n  labs(\n    title = \"Age Density by Gender (with Mean & Peak)\",\n    x = \"Age (Years)\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),\n    plot.title.position = \"plot\",\n    axis.text = element_text(color = \"black\", face = \"bold\"),\n    legend.position = \"right\"\n  ) +\n  scale_fill_manual(values = c(\"Males\" = \"#91C4F2\", \"Females\" = \"#F4B183\")) +\n  scale_color_manual(values = c(\"Males\" = \"#91C4F2\", \"Females\" = \"#F4B183\"))\n\n\n\n\nVisualisation I\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlayout &lt;- \"\nA#\nB#\n\"\n\nP1 + P2 +\n  plot_layout(design = layout) +\n  plot_annotation(\n    title = \"Singapore Population Structure and Age Distribution by Gender (2024)\",\n    theme = theme(plot.title = element_text(hjust = 0.5, face = \"bold\",size = 16))\n  )\n\n\n\n\n\n\nKey Observations & Insights\n\n\nThe largest population share is in the 30–54 age groups for both genders.\nThe base of the pyramid (ages 0–19) is narrower, indicating lower birth rates in recent years.\nBeyond age 65, the number of females exceeds males significantly.\nThe oldest age groups (especially 85+) are mostly female.\nThe density plot shows peaks around age 34–35 for both genders.\nMean age is slightly higher for females (34.7) than males (34.3).\nThe female curve extends further right, suggesting longer life expectancy.\n\nThese visualisations collectively reflect a maturing demographic structure. The dominance of the working-age population (30–54) suggests current economic stability, but the shrinking young cohort (0–19) raises concerns about future workforce replacement. The clear rise in elderly females implies a gendered ageing trend, pointing to disproportionate healthcare and eldercare demands on women. This has policy implications in terms of labour planning, social support systems, and retirement infrastructure. An ageing population with longer female longevity also highlights the need for gender-sensitive ageing policies and sustainable intergenerational support mechanisms.\n\n\n\nII.Exploration of Age Density Distributions Across Singapore’s Planning Areas (2024)\nThe reason why choosing Boxplot is that it highlights variations in median age and age spread and helps identify areas with younger or older populations relative to the national median,supporting demographic insights for targeted policy and planning.\n\n\nCode-Boxplot\nP3 &lt;- ggplot(df_long_region, aes(x = PA, y = Age)) +\n  geom_boxplot(\n    fill = \"white\",\n    color = \"black\",\n    outlier.color = \"gray40\",\n    outlier.size = 1,\n    width = 0.6,\n    alpha = 0.9\n  ) +\n  geom_hline(\n    data = df_median,\n    aes(yintercept = Median, color = \"Median\"),\n    linetype = \"dashed\",\n    size = 0.8,\n    show.legend = TRUE\n  ) +\n  scale_color_manual(\n    name = NULL,\n    values = c(\"Median\" = \"red\"),\n    labels = c(\"Median\" = paste0(\"National Median = \", median_age))\n  ) +\n  facet_wrap(~ Region, scales = \"free_x\", ncol = 4, nrow = 1) +\n  labs(\n    title = \"Boxplot of Age Distribution by Planning Region (2024)\",\n    x = \"Planning Area\", y = \"Age\"\n  ) +\n  theme_gray(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 10, hjust = 0.5),\n    axis.title = element_text(size = 11, face = \"bold\"),\n    axis.text.x = element_text(size = 10, angle = 45, hjust = 1, face = \"bold\"),\n    axis.text.y = element_text(size = 10),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12)\n  )\n\n\nThe reason why choosing Ridgeline density plot with ECDF shading is that it can highlight where population age is most concentrated and emphasizes core age groups within each area.\n\n\nCode-Density Distributions Plot\nP4&lt;-ggplot(df_long_region, aes(x = Age, y = PA, fill = 0.5 - abs(0.5 - stat(ecdf)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    scale = 1.2,\n    rel_min_height = 0.01,\n    alpha = 0.95,\n    from = 0 \n  ) +\n  facet_wrap(~ Region, scales = \"free\", ncol = 4) +\n  scale_fill_viridis_c(\n    option = \"D\", direction = -1,\n    name = \"0.5 - |0.5 - ECDF|-Density emphasis on the core age group in each planning area\",\n    guide = guide_colorbar(\n      title.position = \"top\", \n      title.hjust = 0.5, \n      barwidth = 20,   \n      barheight = 0.8\n    )\n  ) +\n  labs(\n    title = \"Age Density Distributions Across Singapore's Planning Areas (2024)\",\n    x = \"Age\", y = \"Planning Area\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n  plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n  axis.text.y = element_text(size = 12, face = \"bold\"),  \n  axis.text.x = element_text(size = 12, face = \"bold\"),  \n  axis.title.y = element_text(size = 13, face = \"bold\"), \n  axis.title.x = element_text(size = 13, face = \"bold\"), \n  strip.text = element_text(face = \"bold\", size = 11),\n  legend.position = \"bottom\",\n  legend.box.margin = margin(t = 3),\n  legend.title = element_text(size = 9, face = \"bold\"),\n  legend.text = element_text(size = 12)\n  )\n\n\n\n\nVisualisation II\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP4 / P3 \n\n\n\n\n\n\nKey Observations & Insights\n\n\nAge distributions in Seletar and Bukit Timah are skewed toward older age groups, with density curves leaning to the right.\nNewer planning areas like Tengah and Punggol show younger age profiles, with left-skewed density curves and lower median ages in the boxplots.\nMost planning areas have median ages between 35 and 50, with the red dashed line (median = 42) intersecting many boxplots.\nThe South region has many planning areas with highly varied age distributions and numerous outliers.\nThe intensity of the density plot’s shading highlights age concentration levels, with some areas showing clear peaks around core age groups.\n\nThese visualisations reveal distinct demographic differences between older and newer planning areas. New towns like Punggol and Tengah attract a younger population, reflecting family-oriented migration and urban development, while mature estates such as Seletar and Orchard show a concentration of older residents—indicating housing stability and long-term settlement. The overall median age centers around 42, underscoring Singapore’s twin demographic challenges: an ageing population and declining birth rates. The spatial disparity in age structure calls for region-specific resource planning—particularly in childcare, healthcare, and transport. Notably, ageing districts may require targeted investments in elder-friendly infrastructure and services to address future demands effectively.\n\n\n\nIII.Exploration of Population Structure and Gender Distribution Across Singapore’s Planning Areas (2024)\nStacked plots ：To provide a clear overview of the total population breakdown by gender (Males vs. Females) across Singapore’s four regions (East, North, South, West)\n\n\nCode-Stacked plots\ndf_region_gender &lt;- df_long_region %&gt;%\n  filter(!is.na(Sex), !is.na(Region)) %&gt;%\n  group_by(Region, Sex) %&gt;%\n  summarise(n = n(), .groups = \"drop\")\n\nP5 &lt;- ggplot(df_region_gender, aes(x = Region, y = n, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.5, alpha = 0.85) +  \n\n  geom_text(\n    aes(label = comma(n)),\n    position = position_stack(vjust = 0.5),  \n    size = 4,\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n\n  labs(\n    title = \"Total Population by Region and Gender\",\n    x = \"Region\",\n    y = \"Population\"\n  ) +\n  scale_y_continuous(labels = comma, expand = expansion(mult = c(0, 0.05))) +\n  scale_fill_manual(values = c(\"Males\" = \"#4575b4\", \"Females\" = \"#d73027\")) +  # 更浅颜色\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"plain\", size = 14, margin = margin(b = 15)),\n    axis.title = element_text(face = \"plain\"),\n    axis.text = element_text(size = 11),\n    legend.title = element_blank(),\n    legend.position = \"bottom\"\n  )\n\n\nThe reason why choosing Heatmap is that it can identify gender imbalances and demographic aging patterns across Singapore.The color gradient can show whether there are more women than men (red) or vice versa (blue) across age groups and regions.\n\n\nCode-Heatmap\n# Step 5: Draw a heat map\nP6&lt;-ggplot(df_wide, aes(x = Region, y = fct_rev(Age_Group), fill = SexRatio)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(\n    low = \"#4575b4\", mid = \"white\", high = \"#d73027\", midpoint = 1,\n    name = \"F/M Ratio\",\n    guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5),\n    limits = c(0.5, 1.5),\n    na.value = \"grey70\"\n  ) +\n  labs(\n    title = \"Gender Ratio Heatmap by Age Group and Region (F/M)\",\n    x = \"Region\",\n    y = \"Age Group\",caption = \"Note: &lt;1 = More Males, &gt;1 = More Females\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"plain\"),\n    axis.title = element_text(face = \"plain\"),\n    axis.text = element_text(size = 11),\n    legend.title = element_text(face = \"plain\"),\n    legend.position = \"bottom\",\n    plot.caption = element_text(hjust = 0, size = 9, face = \"italic\", color = \"black\")\n  )\n\n\n\n\nVisualisation III\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(P5 + P6) +\n  plot_annotation(\n    title = \"Population Structure and Gender Distribution Across Regions (2024)\",\n    theme = theme(\n      plot.title = element_text(size = 17, face = \"bold\", hjust = 0.5)\n    ))\n\n\n\n\n\n\nKey Observations & Insights\n\n\nEast Region has the highest population for both males and females.\nFemale counts exceed male counts in all four regions.\nSouth Region has the smallest total population among the four.\nAge groups 30–54 show near parity in the F/M ratio across all regions.\nOlder age groups (75–89), especially in the West, show a higher female-to-male ratio (&gt;1.25).\nYounger age groups (0–24) tend to show balanced or male-skewed ratios (&lt;1).\n\nThese visualisations reveal Singapore’s ageing population structure, with women outliving men especially in the older age brackets. The stacked bar chart highlights female dominance in total population counts, while the heatmap deepens the picture, showing where gender imbalances become more pronounced with age. This dual perspective underscores the need for gender-sensitive ageing policies, such as healthcare and community support tailored for older women, particularly in regions like the West where the female-to-male ratio peaks in the elderly segment.",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "title": "Take Home Exercise 1",
    "section": "Conclusion",
    "text": "Conclusion\nThese visualisations provide a comprehensive overview of Singapore’s evolving demographic landscape. They reveal a society characterised by a dominant working-age population, a steadily ageing citizen base, and notable gender disparities in longevity. While younger cohorts are shrinking—particularly in newer towns like Punggol and Tengah—the elderly population is expanding, especially among women in mature estates and western regions. The rising median age and widening spatial age gaps underscore the urgency of tailored policy interventions. These include region-specific investments in eldercare, healthcare, and childcare infrastructure, alongside broader strategies to support intergenerational cohesion and economic sustainability. Singapore’s demographic trajectory calls for integrated planning that is both age- and gender-responsive, ensuring resilience amid shifting population dynamics.",
    "crumbs": [
      "Home",
      "Take-home Exercise"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html",
    "title": "Take Home Exercise1B",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.\n\n\n\nIn this take-home exercise, we are required to:\n\nSelecting one submission provided by our classmate,\ncritic three good design principles and three areas for further improvement.\nWith reference to the comment, prepare the makeover version of the data visualisation.\nI will use clarity and aesthetics as criteria to comment on my classmate’s work.\n\n\n\n\n\n\nCriteria for criticism—clarity or aesthetics?\n\n\n\nThe original visualisation can be found in this link\n\n\n\n\nWe will now set up according to the original code provided in the link.\nThe following packages are used for data wrangling and visualization:\n\ntidyverse: A collection of R packages for data science, including dplyr, ggplot2, and others for data manipulation and visualization.\nggplot2: A grammar of graphics for creating static, animated, and interactive data visualizations.\ndplyr: Provides a set of functions for efficiently manipulating datasets (e.g., filtering, selecting, and summarising).\nforcats: Tools for working with categorical variables (factors), especially useful for reordering and relabeling.\nggthemes: Offers additional themes and scales to improve the aesthetics of ggplot2 charts.\npatchwork: Enables combining multiple ggplot2 plots into a single layout.\nknitr: Facilitates dynamic report generation by weaving R code into documents.\ngt: Used to create elegant tables for display in HTML or markdown reports.\n\nThe following code chunk uses p_load () of pacman packages to check if tidyverse packages are installed and can be called into R.\n\npacman::p_load(tidyverse, ggplot2, dplyr, forcats, ggthemes, patchwork, knitr, gt,scales,gghalves,ggdist,ggforce)\n\n\n\n\n\n\nThis dataset stores “90_and_Over” as a character value in the Age column, we need to clean and convert it to a numeric value to perform age-based analysis. We use 95 as a conservative numeric replacement.\n\ndata &lt;- read_csv(\"Data/respopagesex2024.csv\") %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"95\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  drop_na(Age)\n\n\n\n\n\nsum(duplicated(data))\n\n[1] 0\n\n\n\n\n\n\ngrouped &lt;- data %&gt;%\n  select(PA, SZ) %&gt;%\n  distinct() %&gt;%\n  arrange(PA, SZ) %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Subzones = paste(SZ, collapse = \", \"))\n\ngrouped %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Planning Areas and Their Subzones\"\n  )\n\n\n\n\n\n\n\n\n\nCode-Original Plot 1\nage_groups &lt;- data %&gt;%\n  filter(Age &lt;= 14 | Age &gt;= 65) %&gt;%\n  mutate(group = case_when(\n    Age &lt;= 14 ~ \"Young\",\n    Age &gt;= 65 ~ \"Aging\"\n  )) %&gt;%\n  group_by(PA, group) %&gt;%\n  summarise(total_pop = sum(Pop), .groups = \"drop\")\n\ntop_pa &lt;- age_groups %&gt;%\n  group_by(PA) %&gt;%\n  summarise(total = sum(total_pop)) %&gt;%\n  arrange(desc(total)) %&gt;%\n  slice_head(n = 20)  # select top 20\n\ntop_age_groups &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa$PA)\n\n# Define the order (e.g. by total population descending)\npa_order &lt;- top_age_groups %&gt;%\n  group_by(PA) %&gt;%\n  summarise(total = sum(total_pop)) %&gt;%\n  arrange(desc(total)) %&gt;%\n  pull(PA)\n\n# Apply the same factor levels\ntop_age_groups &lt;- top_age_groups %&gt;%\n  mutate(PA = factor(PA, levels = pa_order))\n\nratio_data &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa$PA) %&gt;%\n  pivot_wider(names_from = group, values_from = total_pop) %&gt;%\n  mutate(ratio = Aging / Young) %&gt;%\n  filter(!is.na(PA)) %&gt;%  # Remove NAs\n  mutate(PA = factor(PA, levels = pa_order))\n\n# Top bar chart\nbar_plot &lt;- ggplot(top_age_groups, aes(x = total_pop, y = fct_rev(PA), fill = group)) +\n  geom_col(position = \"dodge\") +\n  labs(x = \"Population\", y = NULL, fill = \"Age Group\") +\n  theme_minimal()\n\n# Bottom line chart with consistent PA order\nline_plot &lt;- ggplot(ratio_data, aes(x = PA, y = ratio)) +\n  geom_point(size = 3, color = \"black\") +\n  geom_line(aes(group = 1), color = \"black\") +\n  labs(x = \"Planning Area\", y = \"Aging / Young Ratio\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Combine them\n(bar_plot / line_plot) + plot_layout(heights = c(2, 1)) +\n  plot_annotation(title = \"Population Distribution and Aging Ratio by Planning Area\")\n\n\n\n\n\n\n\n\n\nThe combination of the plots reflect both absolute population numbers and structural proportions by top 20 region.\n\nGood pointsMakeover points\n\n\n1.The classmate selected the top 20 most relevant regions to display insights more clearly. In her original population chart, some of the population gaps between regions were so large that it was difficult to interpret the bar values. Focusing on the top 20 regions helps highlight the key areas and improves readability\n2.The basic color pairing (red vs. teal) effectively distinguishes the two age groups, allowing readers to quickly understand the meaning without much effort.the basic color pairing (red vs. teal) effectively distinguishes the two age groups, allowing readers to quickly understand the meaning without much effort.\n3.Using horizontal bar charts and applying a 45-degree tilt to the labels in the lower chart improves clarity, especially for long region names. While reviewing other classmates’ charts, I noticed that vertical text labels were often hard to read. This layout enhances accessibility and viewer experience.\n4.The aging-to-young ratio is a meaningful indicator that reflects the structural skew of the population. It helps identify whether a region is dominated by an aging population or has a relatively younger demographic, providing useful context for planning and policy decisions.\n\n\nThe bar chart:\nClarity:\n\nEnsure correct initial interpretation of the chart:the upper plot would benefit from a clearer title, as the current layout may cause confusion—viewers might initially think the bar chart represents the aging-to-young ratio.\nSeparates the focus areas and avoids misinterpretation:to improve clarity, it’s advisable to include both a main title and distinct subtitles for the two charts.\nImproves user navigation and insight extraction:sorting the bars by total or aging population would enhance readability and help viewers identify key regions more easily.\nProvides exact values and supports better comprehension:It would be beneficial to include data labels on the bars.\nMakes age group definitions explicit and avoids ambiguity : Add a legend label like: “Aging = 65 and above”.\n\nAesthetics:\n\nReduces visual density and makes the plot more digestible:The physical spacing between grouped bars could be adjusted to reduce clutter and improve visual clarity.\nImproves inclusivity and visual distinction:Consider enhancing the legend or replacing colors with more accessible alternatives.\nImproves user comfort and aesthetic appeal:The colour here is too glaring. We need to adjust the colour depth or transparency to make the plot more comfortable and readable for readers.\n\nThe ratio plot\nClarity:\n\nAdd a Structural Reference Line: The current chart lacks a visual indicator to help interpret what constitutes a “balanced” aging structure. Adding a horizontal line at y = 1, labeled as “Balanced Ratio” or “1.0 Threshold”, would make it clear that a ratio above 1 indicates the elderly population exceeds the youth population.\nHighlight Extreme Values:Certain regions such as Punggol (lowest ratio) and Ang Mo Kio (highest ratio) show significant extremes but are not explicitly emphasized. These key points could be highlighted using different colors or text annotations, such as “Highest: Ang Mo Kio (Ratio = 2.2)”, to draw attention and enhance insight.\nEnhance Axis Labels and Styling:The current Y-axis uses plain numeric values (e.g., 0.5 to 2.0) without explanation. It should be relabeled as “Aging-to-Young Ratio (Elderly / Youth)”, and a subtitle like “Ratio above 1.0 indicates elderly outnumber youth” can provide context.\n\nAesthetics:\n\nVisual Styling for Reference and Highlights:Replacing the plain black reference line with a blue gradient and using red highlights for extreme points would improve both aesthetic appeal and clarity.\n\n\n\n\n\n\nCode-Makeover Plot 2\n# Data preprocessing\nage_groups &lt;- data %&gt;%\n  filter(Age &lt;= 14 | Age &gt;= 65) %&gt;%\n  mutate(group = case_when(\n    Age &lt;= 14 ~ \"Young\",\n    Age &gt;= 65 ~ \"Aging\"\n  )) %&gt;%\n  group_by(PA, group) %&gt;%\n  summarise(total_pop = sum(Pop), .groups = \"drop\")\n\n# Sort by elderly population and select the top 20 PAs\ntop_pa &lt;- age_groups %&gt;%\n  filter(group == \"Aging\") %&gt;%\n  arrange(desc(total_pop)) %&gt;%\n  slice_head(n = 20) %&gt;%\n  pull(PA)\n\n# Create top_age_groups\ntop_age_groups &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa)\n\n# Sort order: By elderly population\npa_order &lt;- top_age_groups %&gt;%\n  filter(group == \"Aging\") %&gt;%\n  arrange(desc(total_pop)) %&gt;%\n  pull(PA)\n\n# Apply factor levels for consistent plotting\ntop_age_groups &lt;- top_age_groups %&gt;%\n  mutate(PA = factor(PA, levels = pa_order))\n\n# Calculate national averages\navg_pop &lt;- mean(age_groups$total_pop)\n\navg_aging_pop &lt;- age_groups %&gt;%\n  filter(group == \"Aging\") %&gt;%\n  summarise(mean_pop = mean(total_pop)) %&gt;%\n  pull(mean_pop)\n\navg_young_pop &lt;- age_groups %&gt;%\n  filter(group == \"Young\") %&gt;%\n  summarise(mean_pop = mean(total_pop)) %&gt;%\n  pull(mean_pop)\n\n# Calculate aging-to-young ratio for top PAs\nratio_data &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa) %&gt;%\n  pivot_wider(names_from = group, values_from = total_pop) %&gt;%\n  mutate(ratio = Aging / Young) %&gt;%\n  filter(!is.na(PA)) %&gt;%\n  mutate(PA = factor(PA, levels = pa_order))\n\n# Extreme value labels\nmax_label &lt;- ratio_data %&gt;% slice_max(ratio, n = 1)\nmin_label &lt;- ratio_data %&gt;% slice_min(ratio, n = 1)\nnon_extreme &lt;- ratio_data %&gt;%\n  filter(!(PA %in% c(max_label$PA, min_label$PA)))\n\n# Top Bar Chart\nbar_plot &lt;- ggplot(top_age_groups, aes(x = total_pop, y = PA, fill = group)) +\n  geom_col(position = position_dodge(width = 0.6), width = 0.5, alpha = 0.85) +\n  geom_text(aes(label = comma(total_pop)), \n            position = position_dodge(width = 0.9), \n            hjust = -0.1, size = 3) +\n  geom_vline(xintercept = avg_aging_pop, linetype = \"dashed\", color = \"#29B4B6\", size = 0.6) +\n  geom_vline(xintercept = avg_young_pop, linetype = \"dashed\", color = \"#F0776D\", size = 0.6) +\n  scale_fill_manual(\n    values = c(\"Young\" = \"#F0776D\", \"Aging\" = \"#29B4B6\"),\n    name = \"Age Group\",\n    labels = c(\"Aging = 65 and above\", \"Young = 0–14\")\n  ) +\n  labs(\n    x = \"Population\", \n    y = NULL,\n    title = \"Distribution of Aging vs. Young Population and Dependency Ratio across SG Planning Areas (2024)\",\n    subtitle = paste0(\n      \"Top 20 Planning Areas by Aging Population\\n\",\n      \"Dashed lines: National Average — Aging (\", comma(round(avg_aging_pop)), \n      \"), Young (\", comma(round(avg_young_pop)), \")\"\n    )\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"bottom\",\n    plot.subtitle = element_text(size = 11)\n  )\n\n# Ratio Plot\nline_plot &lt;- ggplot(ratio_data, aes(x = PA, y = ratio)) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"grey40\") +\n  geom_line(aes(group = 1), color = \"steelblue\") +\n  geom_point(size = 3, color = \"steelblue\") +\n  geom_text(data = max_label, aes(label = paste0(\"Highest: \", PA, \" (\", round(ratio, 2), \")\")),\n            vjust = -1.2, color = \"red\", size = 3.5,hjust = 1,          \n          nudge_x = -0.5,nudge_y=-0.2) +\n  geom_text(data = min_label, aes(label = paste0(\"Lowest: \", PA, \" (\", round(ratio, 2), \")\")),\n            vjust = 1.8, color = \"red\", size = 3.5) +\n  geom_text(data = non_extreme, \n          aes(label = round(ratio, 2)), \n          hjust = 0,nudge_x = 0.3, size = 3, color = \"black\")+\n  scale_y_continuous(name = \"Aging-to-Young Ratio (Elderly / Youth)\", limits = c(0, NA)) +\n  labs(x = \"Planning Area\",\n       subtitle = \"Aging-to-Young Population Ratio (Ratio &gt; 1: Elderly Outnumber Youth)\") +\n  theme_minimal(base_size = 12) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Combine plots with improved title\nfinal_plot &lt;- (bar_plot / line_plot) +\n  plot_layout(heights = c(2, 1)) +\n  plot_annotation(\n    title = \"Aging and Youth Population Structure across Singapore Planning Areas (2024)\",\n    theme = theme(plot.title = element_text(size = 15, face = \"bold\"))\n  )\n\nprint(final_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Value to the Reader after improvement\n\n\n\n\nComparability: Enables direct comparisons between regions vs. national average and elderly vs. youth populations\nSorted structure: Helps highlight priority areas with the highest aging population\nClear information hierarchy: Presents both population distribution (bar chart) and structural insights (aging-to-youth ratio line chart)\nIf the goal is to inform policy decisions, guide resource allocation, or highlight the severity of aging issues, Improvement Figure which with more information is better suited as the main visualization.\n\n\n\n\n\n\n\n\nCode-Original Plot 2\nexpanded_data &lt;- data %&gt;%\n  filter(!is.na(PA)) %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"95\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  filter(!is.na(Age)) %&gt;%\n  mutate(PA = str_trim(PA)) %&gt;%\n  mutate(region_type = case_when(\n    # Core Central Region\n    PA %in% c(\"Downtown Core\", \"Outram\", \"Sentosa\", \"Rochor\", \"Orchard\", \"Newton\",\n              \"River Valley\", \"Bukit Timah\", \"Holland Road\", \"Tanglin\", \"Novena\", \"Thomson\") ~ \"Core Central Region \",\n    \n    # Rest of Central Region\n    PA %in% c(\"Bishan\", \"Bukit Merah\", \"Geylang\", \"Kallang\", \"Marine Parade\", \"Queenstown\", \"Southern Islands\", \"Toa Payoh\") ~ \"Rest of Central Region \",\n    \n    # North Region\n    PA %in% c(\"Central Water Catchment\", \"Lim Chu Kang\", \"Mandai\", \"Sembawang\", \"Simpang\", \"Sungei Kadut\", \"Woodlands\", \"Yishun\") ~ \"North Region \",\n    \n    # North-East Region\n    PA %in% c(\"Ang Mo Kio\", \"Hougang\", \"North-Eastern Islands\", \"Punggol\", \"Seletar\",\n              \"Sengkang\", \"Serangoon\") ~ \"North-East Region \",\n    \n    # East Region\n    PA %in% c(\"Bedok\", \"Changi\", \"Changi Bay\", \"Paya Lebar\", \"Pasir Ris\", \"Tampines\") ~ \"East Region \",\n    \n    # West Region\n    PA %in% c(\"Bukit Batok\", \"Bukit Panjang\", \"Boon Lay\", \"Pioneer\", \"Choa Chu Kang\", \"Clementi\", \"Jurong East\", \"Jurong West\", \"Tengah\", \"Tuas\", \"Western Islands\", \"Western Water Catchment\") ~ \"West Region \",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(region_type)) %&gt;%\n  uncount(weights = Pop)\n\np1 &lt;- ggplot(expanded_data, aes(x = region_type, y = Age, fill = region_type)) +\n  geom_boxplot() +\n  labs(title = \"Age Distribution by Region Type\", x = \"Region\", y = \"Age\") +\n  theme_minimal() +\n  coord_flip()\n\np2 &lt;- ggplot(expanded_data, aes(x = Age, y = fct_reorder(PA, Age), fill = region_type)) +\n  geom_boxplot() +\n  facet_wrap(~ region_type, scales = \"free_y\") +\n  labs(\n    title = \"Age Distribution by Planning Area and Region\",\n    x = \"Age\",\n    y = \"Planning Area\"\n  ) +\n  theme_minimal()\n\np1 / p2 +\n  plot_annotation(title = \"Overview: Regional and Planning Area Age Distribution\")\n\n\n\n\n\n\n\n\n\nThis set of charts aims to present the age structure of the population across different areas of Singapore at both the regional (Region) and planning area (Planning Area) levels.\n\nGood pointsMakeover points\n\n\n\nClear hierarchical structure display : the data is divided into two levels (Region and Planning Area), helping readers understand the population structure from a macro to a micro perspective.\nConsistent color scheme : the same color is used to represent the same region, making it easier for readers to transition from the top chart to the bottom chart (e.g., pink for West Region, green for North Region).\nEffective use of space : by arranging the small charts in columns, horizontal space is fully utilized, delivering a large amount of information without appearing cluttered.\nBoxplots enhance statistical insight : each boxplot provides information on the median, quartiles, and outliers, making the distribution characteristics of the data clear at a glance.\nStrong comparative capability : the top chart allows for horizontal comparison across regions, while the bottom chart supports vertical comparison within regions, enabling multi-dimensional analysis.\n\n\n\nClarity\n\nImproves data richness and interpretability : the current chart type is relatively simple; it can be made more informative by incorporating distribution plots such as density or overlaying median lines.\nHelps users understand key metrics at a glance : the boxplots do not explicitly display statistical indicators. Adding a median ect. reference information would improve clarity and interpretability.\nSupports intuitive comparison across categories : if the plots are grouped by region, a side-by-side (faceted) layout would enhance cross-regional comparisons.\n\nAesthetics\n\nReduces clutter and improves visual balance:the legends can be consolidated—retaining just one main legend would simplify the visual presentation.\nEnhances overall design appeal and coherence:The color palette could be optimized by adopting a magazine-style or publication-friendly aesthetic for a more polished and professional look.\n\n\n\n\n\n\nCode-Makeover Plot 2\nexpanded_data &lt;- data %&gt;%\n  filter(!is.na(PA)) %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"95\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  filter(!is.na(Age)) %&gt;%\n  mutate(PA = str_trim(PA)) %&gt;%\n  mutate(region_type = case_when(\n    PA %in% c(\"Downtown Core\", \"Outram\", \"Sentosa\", \"Rochor\", \"Orchard\", \"Newton\",\n              \"River Valley\", \"Bukit Timah\", \"Holland Road\", \"Tanglin\", \"Novena\", \"Thomson\") ~ \"Core Central Region\",\n    \n    PA %in% c(\"Bedok\", \"Changi\", \"Changi Bay\", \"Paya Lebar\", \"Pasir Ris\", \"Tampines\") ~ \"East Region\",\n    \n    PA %in% c(\"Central Water Catchment\", \"Lim Chu Kang\", \"Mandai\", \"Sembawang\", \"Simpang\", \"Sungei Kadut\", \"Woodlands\", \"Yishun\") ~ \"North Region\",\n    \n    PA %in% c(\"Ang Mo Kio\", \"Hougang\", \"North-Eastern Islands\", \"Punggol\", \"Seletar\", \"Sengkang\", \"Serangoon\") ~ \"North-East Region\",\n    \n    PA %in% c(\"Bishan\", \"Bukit Merah\", \"Geylang\", \"Kallang\", \"Marine Parade\", \"Queenstown\", \"Southern Islands\", \"Toa Payoh\") ~ \"Rest of Central Region\",\n    \n    PA %in% c(\"Bukit Batok\", \"Bukit Panjang\", \"Boon Lay\", \"Pioneer\", \"Choa Chu Kang\", \"Clementi\", \"Jurong East\", \"Jurong West\", \"Tengah\", \"Tuas\", \"Western Islands\", \"Western Water Catchment\") ~ \"West Region\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(region_type)) %&gt;%\n  uncount(weights = Pop) %&gt;%\n  mutate(region_type = factor(region_type, levels = c(\"Core Central Region\",\"East Region\", \"North Region\",\"North-East Region\",\"Rest of Central Region\",\"West Region\" ))) \n\nregion_colors &lt;- c(\n  \"Core Central Region\" = \"#E07B91\",\n  \"East Region\" = \"#D7B45A\",\n  \"North Region\" = \"#60B15A\",\n  \"North-East Region\" = \"#4BC1C1\",\n  \"Rest of Central Region\" = \"#6598EA\",\n  \"West Region\" = \"#DA8AE0\"\n)\n\noverall_median &lt;- median(expanded_data$Age, na.rm = TRUE)\n\nP4 &lt;- ggplot(expanded_data, aes(x = fct_reorder(PA, Age), y = Age, fill = region_type)) +\n  geom_boxplot(outlier.size = 0.8, width = 0.6, alpha = 0.6) +\n  facet_wrap(~ region_type, scales = \"free_x\", nrow = 1) +\n  geom_hline(aes(yintercept = overall_median, color = \"Median\"), linetype = \"dashed\", linewidth = 0.8) +\n  labs(title = \"Age Distribution by Subzones (2024)\", x = \"Planning Areas\", y = \"Age\") +\n  \n  scale_fill_manual(\n    values = region_colors,\n    guide = guide_legend(order = 1)\n  ) +\n  scale_color_manual(\n    name = NULL,\n    values = c(\"Median\" = \"red\"),\n    labels = paste0(\"National Median Age = \", overall_median),\n    guide = guide_legend(order = 2)\n  ) +\n  \n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 60, hjust = 0.9, face = \"bold\"),\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    legend.spacing.x = unit(1.5, \"cm\"),\n    legend.text = element_text(size = 10),\n    legend.box = \"horizontal\",\n    panel.spacing = unit(1, \"lines\")\n  )\n\n\n\nstats &lt;- expanded_data %&gt;%\n  group_by(region_type) %&gt;%\n  summarise(\n    Min = min(Age),\n    Q1 = quantile(Age, 0.25),\n    Median = median(Age),\n    Q3 = quantile(Age, 0.75),\n    Max = max(Age)\n  ) %&gt;%\n  pivot_longer(cols = c(Min, Q1, Median, Q3, Max), names_to = \"stat\", values_to = \"value\") %&gt;%\n  mutate(label = paste0(stat, \": \", round(value, 1)))\n\nstats$region_type &lt;- factor(stats$region_type, levels = levels(expanded_data$region_type))\n\n\nP5 &lt;- ggplot(expanded_data, aes(x = region_type, y = Age, fill = region_type)) +\n  geom_half_violin(side = \"r\", alpha = 0.3, color = NA, trim = FALSE) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +\n  geom_text(\n    data = stats,\n    aes(x = region_type, y = value, label = label),\n    inherit.aes = FALSE,\n    size = 4,\n    hjust = 1.4\n  ) +\n  scale_fill_manual(values = region_colors) +\n  labs(\n    title = \"Age Distribution by Region (2024)\",\n    x= NULL,\n    y = \"Age\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_blank(),\n    strip.text = element_blank()\n  ) +\n  coord_cartesian(clip = \"off\")\n\nfinal_plot &lt;- (P5 / P4) +\n  plot_layout(heights = c(2, 1)) +\n  plot_annotation(\n    title = \"Age Distribution Across Regions and Planning Areas in Singapore (2024)\",\n    theme = theme(plot.title = element_text(size = 16, face = \"bold\"))\n  )\n\nprint(final_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Value to the Reader after improvement\n\n\n\n\nClear understanding of region-to-subregion age structure hierarchy\nEasy identification of age distribution shape and spread differences\nImmediate recognition of deviation from national norms\n\n\n\n\n\n\n\nAfter virewing some classmates visualisation,I want to share four key principles to keep in mind to ensure that our visualization is clear, insightful, and effective in communicating data:\n\nPurpose\n\nEvery chart should serve a clear purpose. Focus on what we want the viewer to take away—select the appropriate chart type, avoid unnecessary complexity, and emphasize the key insight the chart is meant to reveal.\nClarity & Accuracy\n\nEnsure our chart includes clear titles, well-defined terms, and meaningful reference lines. Metrics should be accurate and relevant, helping viewers understand the data without confusion.\nReadability & Insight\n\nArrange the chart to guide the viewer’s eye—use logical sorting, highlight important values, and ensure adequate spacing. Group comparisons should be easy to follow and visually intuitive.\nAesthetics\n\nChoose a color palette that is visually comfortable and accessible. Maintain layout balance, ensure font clarity, and avoid clutter. Good design not only looks professional but also supports comprehension.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 1B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#overview",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#overview",
    "title": "Take Home Exercise1B",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.\n\n\n\nIn this take-home exercise, we are required to:\n\nSelecting one submission provided by our classmate,\ncritic three good design principles and three areas for further improvement.\nWith reference to the comment, prepare the makeover version of the data visualisation.\nI will use clarity and aesthetics as criteria to comment on my classmate’s work.\n\n\n\n\n\n\nCriteria for criticism—clarity or aesthetics?\n\n\n\nThe original visualisation can be found in this link",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 1B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#set-up",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#set-up",
    "title": "Take Home Exercise1B",
    "section": "",
    "text": "We will now set up according to the original code provided in the link.\nThe following packages are used for data wrangling and visualization:\n\ntidyverse: A collection of R packages for data science, including dplyr, ggplot2, and others for data manipulation and visualization.\nggplot2: A grammar of graphics for creating static, animated, and interactive data visualizations.\ndplyr: Provides a set of functions for efficiently manipulating datasets (e.g., filtering, selecting, and summarising).\nforcats: Tools for working with categorical variables (factors), especially useful for reordering and relabeling.\nggthemes: Offers additional themes and scales to improve the aesthetics of ggplot2 charts.\npatchwork: Enables combining multiple ggplot2 plots into a single layout.\nknitr: Facilitates dynamic report generation by weaving R code into documents.\ngt: Used to create elegant tables for display in HTML or markdown reports.\n\nThe following code chunk uses p_load () of pacman packages to check if tidyverse packages are installed and can be called into R.\n\npacman::p_load(tidyverse, ggplot2, dplyr, forcats, ggthemes, patchwork, knitr, gt,scales,gghalves,ggdist,ggforce)",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 1B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#data-preparation",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#data-preparation",
    "title": "Take Home Exercise1B",
    "section": "",
    "text": "This dataset stores “90_and_Over” as a character value in the Age column, we need to clean and convert it to a numeric value to perform age-based analysis. We use 95 as a conservative numeric replacement.\n\ndata &lt;- read_csv(\"Data/respopagesex2024.csv\") %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"95\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  drop_na(Age)\n\n\n\n\n\nsum(duplicated(data))\n\n[1] 0\n\n\n\n\n\n\ngrouped &lt;- data %&gt;%\n  select(PA, SZ) %&gt;%\n  distinct() %&gt;%\n  arrange(PA, SZ) %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Subzones = paste(SZ, collapse = \", \"))\n\ngrouped %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Planning Areas and Their Subzones\"\n  )",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 1B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#the-original-data-visualisation-1",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#the-original-data-visualisation-1",
    "title": "Take Home Exercise1B",
    "section": "",
    "text": "Code-Original Plot 1\nage_groups &lt;- data %&gt;%\n  filter(Age &lt;= 14 | Age &gt;= 65) %&gt;%\n  mutate(group = case_when(\n    Age &lt;= 14 ~ \"Young\",\n    Age &gt;= 65 ~ \"Aging\"\n  )) %&gt;%\n  group_by(PA, group) %&gt;%\n  summarise(total_pop = sum(Pop), .groups = \"drop\")\n\ntop_pa &lt;- age_groups %&gt;%\n  group_by(PA) %&gt;%\n  summarise(total = sum(total_pop)) %&gt;%\n  arrange(desc(total)) %&gt;%\n  slice_head(n = 20)  # select top 20\n\ntop_age_groups &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa$PA)\n\n# Define the order (e.g. by total population descending)\npa_order &lt;- top_age_groups %&gt;%\n  group_by(PA) %&gt;%\n  summarise(total = sum(total_pop)) %&gt;%\n  arrange(desc(total)) %&gt;%\n  pull(PA)\n\n# Apply the same factor levels\ntop_age_groups &lt;- top_age_groups %&gt;%\n  mutate(PA = factor(PA, levels = pa_order))\n\nratio_data &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa$PA) %&gt;%\n  pivot_wider(names_from = group, values_from = total_pop) %&gt;%\n  mutate(ratio = Aging / Young) %&gt;%\n  filter(!is.na(PA)) %&gt;%  # Remove NAs\n  mutate(PA = factor(PA, levels = pa_order))\n\n# Top bar chart\nbar_plot &lt;- ggplot(top_age_groups, aes(x = total_pop, y = fct_rev(PA), fill = group)) +\n  geom_col(position = \"dodge\") +\n  labs(x = \"Population\", y = NULL, fill = \"Age Group\") +\n  theme_minimal()\n\n# Bottom line chart with consistent PA order\nline_plot &lt;- ggplot(ratio_data, aes(x = PA, y = ratio)) +\n  geom_point(size = 3, color = \"black\") +\n  geom_line(aes(group = 1), color = \"black\") +\n  labs(x = \"Planning Area\", y = \"Aging / Young Ratio\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Combine them\n(bar_plot / line_plot) + plot_layout(heights = c(2, 1)) +\n  plot_annotation(title = \"Population Distribution and Aging Ratio by Planning Area\")\n\n\n\n\n\n\n\n\n\nThe combination of the plots reflect both absolute population numbers and structural proportions by top 20 region.\n\nGood pointsMakeover points\n\n\n1.The classmate selected the top 20 most relevant regions to display insights more clearly. In her original population chart, some of the population gaps between regions were so large that it was difficult to interpret the bar values. Focusing on the top 20 regions helps highlight the key areas and improves readability\n2.The basic color pairing (red vs. teal) effectively distinguishes the two age groups, allowing readers to quickly understand the meaning without much effort.the basic color pairing (red vs. teal) effectively distinguishes the two age groups, allowing readers to quickly understand the meaning without much effort.\n3.Using horizontal bar charts and applying a 45-degree tilt to the labels in the lower chart improves clarity, especially for long region names. While reviewing other classmates’ charts, I noticed that vertical text labels were often hard to read. This layout enhances accessibility and viewer experience.\n4.The aging-to-young ratio is a meaningful indicator that reflects the structural skew of the population. It helps identify whether a region is dominated by an aging population or has a relatively younger demographic, providing useful context for planning and policy decisions.\n\n\nThe bar chart:\nClarity:\n\nEnsure correct initial interpretation of the chart:the upper plot would benefit from a clearer title, as the current layout may cause confusion—viewers might initially think the bar chart represents the aging-to-young ratio.\nSeparates the focus areas and avoids misinterpretation:to improve clarity, it’s advisable to include both a main title and distinct subtitles for the two charts.\nImproves user navigation and insight extraction:sorting the bars by total or aging population would enhance readability and help viewers identify key regions more easily.\nProvides exact values and supports better comprehension:It would be beneficial to include data labels on the bars.\nMakes age group definitions explicit and avoids ambiguity : Add a legend label like: “Aging = 65 and above”.\n\nAesthetics:\n\nReduces visual density and makes the plot more digestible:The physical spacing between grouped bars could be adjusted to reduce clutter and improve visual clarity.\nImproves inclusivity and visual distinction:Consider enhancing the legend or replacing colors with more accessible alternatives.\nImproves user comfort and aesthetic appeal:The colour here is too glaring. We need to adjust the colour depth or transparency to make the plot more comfortable and readable for readers.\n\nThe ratio plot\nClarity:\n\nAdd a Structural Reference Line: The current chart lacks a visual indicator to help interpret what constitutes a “balanced” aging structure. Adding a horizontal line at y = 1, labeled as “Balanced Ratio” or “1.0 Threshold”, would make it clear that a ratio above 1 indicates the elderly population exceeds the youth population.\nHighlight Extreme Values:Certain regions such as Punggol (lowest ratio) and Ang Mo Kio (highest ratio) show significant extremes but are not explicitly emphasized. These key points could be highlighted using different colors or text annotations, such as “Highest: Ang Mo Kio (Ratio = 2.2)”, to draw attention and enhance insight.\nEnhance Axis Labels and Styling:The current Y-axis uses plain numeric values (e.g., 0.5 to 2.0) without explanation. It should be relabeled as “Aging-to-Young Ratio (Elderly / Youth)”, and a subtitle like “Ratio above 1.0 indicates elderly outnumber youth” can provide context.\n\nAesthetics:\n\nVisual Styling for Reference and Highlights:Replacing the plain black reference line with a blue gradient and using red highlights for extreme points would improve both aesthetic appeal and clarity.\n\n\n\n\n\n\nCode-Makeover Plot 2\n# Data preprocessing\nage_groups &lt;- data %&gt;%\n  filter(Age &lt;= 14 | Age &gt;= 65) %&gt;%\n  mutate(group = case_when(\n    Age &lt;= 14 ~ \"Young\",\n    Age &gt;= 65 ~ \"Aging\"\n  )) %&gt;%\n  group_by(PA, group) %&gt;%\n  summarise(total_pop = sum(Pop), .groups = \"drop\")\n\n# Sort by elderly population and select the top 20 PAs\ntop_pa &lt;- age_groups %&gt;%\n  filter(group == \"Aging\") %&gt;%\n  arrange(desc(total_pop)) %&gt;%\n  slice_head(n = 20) %&gt;%\n  pull(PA)\n\n# Create top_age_groups\ntop_age_groups &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa)\n\n# Sort order: By elderly population\npa_order &lt;- top_age_groups %&gt;%\n  filter(group == \"Aging\") %&gt;%\n  arrange(desc(total_pop)) %&gt;%\n  pull(PA)\n\n# Apply factor levels for consistent plotting\ntop_age_groups &lt;- top_age_groups %&gt;%\n  mutate(PA = factor(PA, levels = pa_order))\n\n# Calculate national averages\navg_pop &lt;- mean(age_groups$total_pop)\n\navg_aging_pop &lt;- age_groups %&gt;%\n  filter(group == \"Aging\") %&gt;%\n  summarise(mean_pop = mean(total_pop)) %&gt;%\n  pull(mean_pop)\n\navg_young_pop &lt;- age_groups %&gt;%\n  filter(group == \"Young\") %&gt;%\n  summarise(mean_pop = mean(total_pop)) %&gt;%\n  pull(mean_pop)\n\n# Calculate aging-to-young ratio for top PAs\nratio_data &lt;- age_groups %&gt;%\n  filter(PA %in% top_pa) %&gt;%\n  pivot_wider(names_from = group, values_from = total_pop) %&gt;%\n  mutate(ratio = Aging / Young) %&gt;%\n  filter(!is.na(PA)) %&gt;%\n  mutate(PA = factor(PA, levels = pa_order))\n\n# Extreme value labels\nmax_label &lt;- ratio_data %&gt;% slice_max(ratio, n = 1)\nmin_label &lt;- ratio_data %&gt;% slice_min(ratio, n = 1)\nnon_extreme &lt;- ratio_data %&gt;%\n  filter(!(PA %in% c(max_label$PA, min_label$PA)))\n\n# Top Bar Chart\nbar_plot &lt;- ggplot(top_age_groups, aes(x = total_pop, y = PA, fill = group)) +\n  geom_col(position = position_dodge(width = 0.6), width = 0.5, alpha = 0.85) +\n  geom_text(aes(label = comma(total_pop)), \n            position = position_dodge(width = 0.9), \n            hjust = -0.1, size = 3) +\n  geom_vline(xintercept = avg_aging_pop, linetype = \"dashed\", color = \"#29B4B6\", size = 0.6) +\n  geom_vline(xintercept = avg_young_pop, linetype = \"dashed\", color = \"#F0776D\", size = 0.6) +\n  scale_fill_manual(\n    values = c(\"Young\" = \"#F0776D\", \"Aging\" = \"#29B4B6\"),\n    name = \"Age Group\",\n    labels = c(\"Aging = 65 and above\", \"Young = 0–14\")\n  ) +\n  labs(\n    x = \"Population\", \n    y = NULL,\n    title = \"Distribution of Aging vs. Young Population and Dependency Ratio across SG Planning Areas (2024)\",\n    subtitle = paste0(\n      \"Top 20 Planning Areas by Aging Population\\n\",\n      \"Dashed lines: National Average — Aging (\", comma(round(avg_aging_pop)), \n      \"), Young (\", comma(round(avg_young_pop)), \")\"\n    )\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"bottom\",\n    plot.subtitle = element_text(size = 11)\n  )\n\n# Ratio Plot\nline_plot &lt;- ggplot(ratio_data, aes(x = PA, y = ratio)) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"grey40\") +\n  geom_line(aes(group = 1), color = \"steelblue\") +\n  geom_point(size = 3, color = \"steelblue\") +\n  geom_text(data = max_label, aes(label = paste0(\"Highest: \", PA, \" (\", round(ratio, 2), \")\")),\n            vjust = -1.2, color = \"red\", size = 3.5,hjust = 1,          \n          nudge_x = -0.5,nudge_y=-0.2) +\n  geom_text(data = min_label, aes(label = paste0(\"Lowest: \", PA, \" (\", round(ratio, 2), \")\")),\n            vjust = 1.8, color = \"red\", size = 3.5) +\n  geom_text(data = non_extreme, \n          aes(label = round(ratio, 2)), \n          hjust = 0,nudge_x = 0.3, size = 3, color = \"black\")+\n  scale_y_continuous(name = \"Aging-to-Young Ratio (Elderly / Youth)\", limits = c(0, NA)) +\n  labs(x = \"Planning Area\",\n       subtitle = \"Aging-to-Young Population Ratio (Ratio &gt; 1: Elderly Outnumber Youth)\") +\n  theme_minimal(base_size = 12) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Combine plots with improved title\nfinal_plot &lt;- (bar_plot / line_plot) +\n  plot_layout(heights = c(2, 1)) +\n  plot_annotation(\n    title = \"Aging and Youth Population Structure across Singapore Planning Areas (2024)\",\n    theme = theme(plot.title = element_text(size = 15, face = \"bold\"))\n  )\n\nprint(final_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Value to the Reader after improvement\n\n\n\n\nComparability: Enables direct comparisons between regions vs. national average and elderly vs. youth populations\nSorted structure: Helps highlight priority areas with the highest aging population\nClear information hierarchy: Presents both population distribution (bar chart) and structural insights (aging-to-youth ratio line chart)\nIf the goal is to inform policy decisions, guide resource allocation, or highlight the severity of aging issues, Improvement Figure which with more information is better suited as the main visualization.\n\n\n\n\n\n\n\n\nCode-Original Plot 2\nexpanded_data &lt;- data %&gt;%\n  filter(!is.na(PA)) %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"95\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  filter(!is.na(Age)) %&gt;%\n  mutate(PA = str_trim(PA)) %&gt;%\n  mutate(region_type = case_when(\n    # Core Central Region\n    PA %in% c(\"Downtown Core\", \"Outram\", \"Sentosa\", \"Rochor\", \"Orchard\", \"Newton\",\n              \"River Valley\", \"Bukit Timah\", \"Holland Road\", \"Tanglin\", \"Novena\", \"Thomson\") ~ \"Core Central Region \",\n    \n    # Rest of Central Region\n    PA %in% c(\"Bishan\", \"Bukit Merah\", \"Geylang\", \"Kallang\", \"Marine Parade\", \"Queenstown\", \"Southern Islands\", \"Toa Payoh\") ~ \"Rest of Central Region \",\n    \n    # North Region\n    PA %in% c(\"Central Water Catchment\", \"Lim Chu Kang\", \"Mandai\", \"Sembawang\", \"Simpang\", \"Sungei Kadut\", \"Woodlands\", \"Yishun\") ~ \"North Region \",\n    \n    # North-East Region\n    PA %in% c(\"Ang Mo Kio\", \"Hougang\", \"North-Eastern Islands\", \"Punggol\", \"Seletar\",\n              \"Sengkang\", \"Serangoon\") ~ \"North-East Region \",\n    \n    # East Region\n    PA %in% c(\"Bedok\", \"Changi\", \"Changi Bay\", \"Paya Lebar\", \"Pasir Ris\", \"Tampines\") ~ \"East Region \",\n    \n    # West Region\n    PA %in% c(\"Bukit Batok\", \"Bukit Panjang\", \"Boon Lay\", \"Pioneer\", \"Choa Chu Kang\", \"Clementi\", \"Jurong East\", \"Jurong West\", \"Tengah\", \"Tuas\", \"Western Islands\", \"Western Water Catchment\") ~ \"West Region \",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(region_type)) %&gt;%\n  uncount(weights = Pop)\n\np1 &lt;- ggplot(expanded_data, aes(x = region_type, y = Age, fill = region_type)) +\n  geom_boxplot() +\n  labs(title = \"Age Distribution by Region Type\", x = \"Region\", y = \"Age\") +\n  theme_minimal() +\n  coord_flip()\n\np2 &lt;- ggplot(expanded_data, aes(x = Age, y = fct_reorder(PA, Age), fill = region_type)) +\n  geom_boxplot() +\n  facet_wrap(~ region_type, scales = \"free_y\") +\n  labs(\n    title = \"Age Distribution by Planning Area and Region\",\n    x = \"Age\",\n    y = \"Planning Area\"\n  ) +\n  theme_minimal()\n\np1 / p2 +\n  plot_annotation(title = \"Overview: Regional and Planning Area Age Distribution\")\n\n\n\n\n\n\n\n\n\nThis set of charts aims to present the age structure of the population across different areas of Singapore at both the regional (Region) and planning area (Planning Area) levels.\n\nGood pointsMakeover points\n\n\n\nClear hierarchical structure display : the data is divided into two levels (Region and Planning Area), helping readers understand the population structure from a macro to a micro perspective.\nConsistent color scheme : the same color is used to represent the same region, making it easier for readers to transition from the top chart to the bottom chart (e.g., pink for West Region, green for North Region).\nEffective use of space : by arranging the small charts in columns, horizontal space is fully utilized, delivering a large amount of information without appearing cluttered.\nBoxplots enhance statistical insight : each boxplot provides information on the median, quartiles, and outliers, making the distribution characteristics of the data clear at a glance.\nStrong comparative capability : the top chart allows for horizontal comparison across regions, while the bottom chart supports vertical comparison within regions, enabling multi-dimensional analysis.\n\n\n\nClarity\n\nImproves data richness and interpretability : the current chart type is relatively simple; it can be made more informative by incorporating distribution plots such as density or overlaying median lines.\nHelps users understand key metrics at a glance : the boxplots do not explicitly display statistical indicators. Adding a median ect. reference information would improve clarity and interpretability.\nSupports intuitive comparison across categories : if the plots are grouped by region, a side-by-side (faceted) layout would enhance cross-regional comparisons.\n\nAesthetics\n\nReduces clutter and improves visual balance:the legends can be consolidated—retaining just one main legend would simplify the visual presentation.\nEnhances overall design appeal and coherence:The color palette could be optimized by adopting a magazine-style or publication-friendly aesthetic for a more polished and professional look.\n\n\n\n\n\n\nCode-Makeover Plot 2\nexpanded_data &lt;- data %&gt;%\n  filter(!is.na(PA)) %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"95\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  filter(!is.na(Age)) %&gt;%\n  mutate(PA = str_trim(PA)) %&gt;%\n  mutate(region_type = case_when(\n    PA %in% c(\"Downtown Core\", \"Outram\", \"Sentosa\", \"Rochor\", \"Orchard\", \"Newton\",\n              \"River Valley\", \"Bukit Timah\", \"Holland Road\", \"Tanglin\", \"Novena\", \"Thomson\") ~ \"Core Central Region\",\n    \n    PA %in% c(\"Bedok\", \"Changi\", \"Changi Bay\", \"Paya Lebar\", \"Pasir Ris\", \"Tampines\") ~ \"East Region\",\n    \n    PA %in% c(\"Central Water Catchment\", \"Lim Chu Kang\", \"Mandai\", \"Sembawang\", \"Simpang\", \"Sungei Kadut\", \"Woodlands\", \"Yishun\") ~ \"North Region\",\n    \n    PA %in% c(\"Ang Mo Kio\", \"Hougang\", \"North-Eastern Islands\", \"Punggol\", \"Seletar\", \"Sengkang\", \"Serangoon\") ~ \"North-East Region\",\n    \n    PA %in% c(\"Bishan\", \"Bukit Merah\", \"Geylang\", \"Kallang\", \"Marine Parade\", \"Queenstown\", \"Southern Islands\", \"Toa Payoh\") ~ \"Rest of Central Region\",\n    \n    PA %in% c(\"Bukit Batok\", \"Bukit Panjang\", \"Boon Lay\", \"Pioneer\", \"Choa Chu Kang\", \"Clementi\", \"Jurong East\", \"Jurong West\", \"Tengah\", \"Tuas\", \"Western Islands\", \"Western Water Catchment\") ~ \"West Region\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(region_type)) %&gt;%\n  uncount(weights = Pop) %&gt;%\n  mutate(region_type = factor(region_type, levels = c(\"Core Central Region\",\"East Region\", \"North Region\",\"North-East Region\",\"Rest of Central Region\",\"West Region\" ))) \n\nregion_colors &lt;- c(\n  \"Core Central Region\" = \"#E07B91\",\n  \"East Region\" = \"#D7B45A\",\n  \"North Region\" = \"#60B15A\",\n  \"North-East Region\" = \"#4BC1C1\",\n  \"Rest of Central Region\" = \"#6598EA\",\n  \"West Region\" = \"#DA8AE0\"\n)\n\noverall_median &lt;- median(expanded_data$Age, na.rm = TRUE)\n\nP4 &lt;- ggplot(expanded_data, aes(x = fct_reorder(PA, Age), y = Age, fill = region_type)) +\n  geom_boxplot(outlier.size = 0.8, width = 0.6, alpha = 0.6) +\n  facet_wrap(~ region_type, scales = \"free_x\", nrow = 1) +\n  geom_hline(aes(yintercept = overall_median, color = \"Median\"), linetype = \"dashed\", linewidth = 0.8) +\n  labs(title = \"Age Distribution by Subzones (2024)\", x = \"Planning Areas\", y = \"Age\") +\n  \n  scale_fill_manual(\n    values = region_colors,\n    guide = guide_legend(order = 1)\n  ) +\n  scale_color_manual(\n    name = NULL,\n    values = c(\"Median\" = \"red\"),\n    labels = paste0(\"National Median Age = \", overall_median),\n    guide = guide_legend(order = 2)\n  ) +\n  \n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 60, hjust = 0.9, face = \"bold\"),\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    legend.spacing.x = unit(1.5, \"cm\"),\n    legend.text = element_text(size = 10),\n    legend.box = \"horizontal\",\n    panel.spacing = unit(1, \"lines\")\n  )\n\n\n\nstats &lt;- expanded_data %&gt;%\n  group_by(region_type) %&gt;%\n  summarise(\n    Min = min(Age),\n    Q1 = quantile(Age, 0.25),\n    Median = median(Age),\n    Q3 = quantile(Age, 0.75),\n    Max = max(Age)\n  ) %&gt;%\n  pivot_longer(cols = c(Min, Q1, Median, Q3, Max), names_to = \"stat\", values_to = \"value\") %&gt;%\n  mutate(label = paste0(stat, \": \", round(value, 1)))\n\nstats$region_type &lt;- factor(stats$region_type, levels = levels(expanded_data$region_type))\n\n\nP5 &lt;- ggplot(expanded_data, aes(x = region_type, y = Age, fill = region_type)) +\n  geom_half_violin(side = \"r\", alpha = 0.3, color = NA, trim = FALSE) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.6) +\n  geom_text(\n    data = stats,\n    aes(x = region_type, y = value, label = label),\n    inherit.aes = FALSE,\n    size = 4,\n    hjust = 1.4\n  ) +\n  scale_fill_manual(values = region_colors) +\n  labs(\n    title = \"Age Distribution by Region (2024)\",\n    x= NULL,\n    y = \"Age\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_blank(),\n    strip.text = element_blank()\n  ) +\n  coord_cartesian(clip = \"off\")\n\nfinal_plot &lt;- (P5 / P4) +\n  plot_layout(heights = c(2, 1)) +\n  plot_annotation(\n    title = \"Age Distribution Across Regions and Planning Areas in Singapore (2024)\",\n    theme = theme(plot.title = element_text(size = 16, face = \"bold\"))\n  )\n\nprint(final_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Value to the Reader after improvement\n\n\n\n\nClear understanding of region-to-subregion age structure hierarchy\nEasy identification of age distribution shape and spread differences\nImmediate recognition of deviation from national norms",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 1B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#conclusion",
    "href": "Take-home_Exercise/Take-home_Ex01/Take-home_Ex01B.html#conclusion",
    "title": "Take Home Exercise1B",
    "section": "",
    "text": "After virewing some classmates visualisation,I want to share four key principles to keep in mind to ensure that our visualization is clear, insightful, and effective in communicating data:\n\nPurpose\n\nEvery chart should serve a clear purpose. Focus on what we want the viewer to take away—select the appropriate chart type, avoid unnecessary complexity, and emphasize the key insight the chart is meant to reveal.\nClarity & Accuracy\n\nEnsure our chart includes clear titles, well-defined terms, and meaningful reference lines. Metrics should be accurate and relevant, helping viewers understand the data without confusion.\nReadability & Insight\n\nArrange the chart to guide the viewer’s eye—use logical sorting, highlight important values, and ensure adequate spacing. Group comparisons should be easy to follow and visually intuitive.\nAesthetics\n\nChoose a color palette that is visually comfortable and accessible. Maintain layout balance, ensure font clarity, and avoid clutter. Good design not only looks professional but also supports comprehension.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 1B"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "title": "Take Home Exercise 2",
    "section": "Getting Started",
    "text": "Getting Started\nFor the purpose of this exercise, four R packages will be used. They are tidyverse, jsonlite, tidygraph and ggraph.\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environemnt.\n\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph,ggplot2,SmartEDA,igraph,visNetwork,DiagrammeR)",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#importing-kownledge-graph-data",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#importing-kownledge-graph-data",
    "title": "Take Home Exercise 2",
    "section": "Importing Kownledge Graph Data",
    "text": "Importing Kownledge Graph Data\nFor the purpose of this exercise, MC1_graph.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\nWhat are the components of kg data?\n\nglimpse(kg)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n  ..$ node_default: Named list()\n  ..$ edge_default: Named list()\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n  ..$ Node Type     : chr [1:17412] \"Song\" \"Person\" \"Person\" \"Person\" ...\n  ..$ name          : chr [1:17412] \"Breaking These Chains\" \"Carlos Duffy\" \"Min Qin\" \"Xiuying Xie\" ...\n  ..$ single        : logi [1:17412] TRUE NA NA NA NA FALSE ...\n  ..$ release_date  : chr [1:17412] \"2017\" NA NA NA ...\n  ..$ genre         : chr [1:17412] \"Oceanus Folk\" NA NA NA ...\n  ..$ notable       : logi [1:17412] TRUE NA NA NA NA TRUE ...\n  ..$ id            : int [1:17412] 0 1 2 3 4 5 6 7 8 9 ...\n  ..$ written_date  : chr [1:17412] NA NA NA NA ...\n  ..$ stage_name    : chr [1:17412] NA NA NA NA ...\n  ..$ notoriety_date: chr [1:17412] NA NA NA NA ...\n $ links     :'data.frame': 37857 obs. of  4 variables:\n  ..$ Edge Type: chr [1:37857] \"InterpolatesFrom\" \"RecordedBy\" \"PerformerOf\" \"ComposerOf\" ...\n  ..$ source   : int [1:37857] 0 0 1 1 2 2 3 5 5 5 ...\n  ..$ target   : int [1:37857] 1841 4 0 16180 0 16180 0 5088 14332 11677 ...\n  ..$ key      : int [1:37857] 0 0 0 0 0 0 0 0 0 0 ...\n\n\nThe result shows a typical knowledge graph (KG) data structure, the detail explanation is as followed:\n1.The overall structure is a list of 5 elements:\n\n\n\n\n\n\n\nElement Name\nMeaning\n\n\n\n\ndirected: TRUE\nIndicates the graph is directed (i.e., relationships have direction, like “someone performed a song”)\n\n\nmultigraph: TRUE\nIndicates this is a multigraph, meaning multiple edges (relationships) can exist between the same pair of nodes (e.g., a person can be both “composer” and “performer”)\n\n\ngraph\nContains default attributes for nodes and edges (currently empty named lists)\n\n\nnodes\nA data.frame, each row represents a node (e.g., a person or a song)\n\n\nlinks\nA data.frame, each row represents an edge (i.e., a relationship between two nodes)\n\n\n\n2.nodes table (node metadata)\nThere are 17,412 nodes, with the following variables:\n\n\n\nColumn Name\nExample / Meaning\n\n\n\n\nNode Type\nNode type, such as \"Song\" or \"Person\"\n\n\nname\nName of the node (e.g., a person or song title)\n\n\nsingle\nWhether it is a single (TRUE / FALSE)\n\n\nrelease_date\nRelease date (e.g., \"2017\")\n\n\ngenre\nGenre (e.g., \"Oceanus Folk\")\n\n\nnotable\nWhether it’s notable (TRUE / FALSE)\n\n\nid\nUnique ID for the node\n\n\nwritten_date\nDate the song was written\n\n\nstage_name\nStage name (if any)\n\n\nnotoriety_date\nDate the artist became known (if any)\n\n\n\n3.links table (edge/relationship information)\nThere are 37,857 edges, with the following columns:\n\n\n\n\n\n\n\nColumn Name\nMeaning / Example\n\n\n\n\nEdge Type\nType of relationship (e.g., \"PerformerOf\", \"ComposerOf\", \"InterpolateFrom\")\n\n\nsource\nID of the source node\n\n\ntarget\nID of the target node\n\n\nkey\nDifferentiates multiple edges between the same nodes\n\n\n\nInspect structure\nBefore preparing the data, it is always a good practice to examine the structure of kg object.\nIn the code chunk below str() is used to reveal the structure of kg object.\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "title": "Take Home Exercise 2",
    "section": "Extracting the edges and nodes tables",
    "text": "Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from kg object into two separate tibble data frames called nodes_tbl and edges_tbl respectively.\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links) \n\n\nInitial EDA\nIt is time for us to apply appropriate EDA methods to examine the data.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Edge Type field of edges_tbl.\n\nNodesEdges\n\n\n\nnodes_tbl %&gt;%\n  count(`Node Type`) %&gt;%\n  ggplot(aes(x = n, y = reorder(`Node Type`, n))) +\n  geom_col(fill = \"steelblue\") +\n  labs(title = \"Distribution of Node Types in Knowledge Graph\",\n       x = \"Count\", y = \"Node Type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nMost nodes are of type Person\n\nExplanation: Individuals (singers, composers, producers, etc.) form the majority of nodes.\nInsight: The knowledge graph is person-centric, emphasizing individual contributions in the music ecosystem.\n\nSong is the second most frequent node type\n\nExplanation: Songs are heavily represented, as expected in a music-related knowledge graph.\nInsight: This reflects the graph’s role in mapping who is connected to which songs, enabling analysis of performance, authorship, and influence.\n\nOther node types (e.g., RecordLabel, Album, MusicalGroup) are far fewer\n\nExplanation: Entities like music labels, albums, and groups are present but much less prominent.\nInsight: These nodes play a supporting role in contextualizing the people-song relationships, potentially useful for advanced analyses (e.g., influence of labels, collaborations within groups).\n\nMusicalGroup nodes are very rare\n\nInsight: Either the graph focuses more on individual artists rather than bands/groups, or group membership data may be under-represented.\n\n\n\n\nedges_tbl %&gt;%\n  count(`Edge Type`) %&gt;%\n  ggplot(aes(x = n, y = reorder(`Edge Type`, n))) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Edge Type Distribution in Knowledge Graph\",\n       x = \"Count\", y = \"Edge Type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n“PerformerOf” is the most frequent edge type\n\nExplanation: The majority of edges connect a person to a song via a performance relationship.\nInsight: This indicates that the relationship between performers and songs is a core structure in the knowledge graph, showing that the graph places a strong emphasis on who performed what.\n\n“RecordedBy”, “ComposerOf”, and “ProducerOf” are also common\n\nExplanation: Besides performers, the graph also documents many creators of the music, including composers, producers, and recording personnel.\nInsight: This suggests the graph goes beyond surface-level links, capturing multiple roles across the music creation pipeline.\n\nEdge types like “DirectlySamples”, “CoverOf”, “MemberOf”, and “LyricalReferenceTo” are less frequent\n\nExplanation: These edges represent more complex or less common musical relationships, such as:\nDirectlySamples: relates to copyright and musical inspiration\nCoverOf: shows the propagation of classic works through cover versions\nMemberOf: describes group or band membership\nInsight: Although less common, these edge types may hold higher value in studying musical influence and cultural transmission.\n\n\n\n\n\nOn the other hands, code chunk below uses ggplot2 functions to reveal the frequency distribution of Node Type field of nodes_tbl.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#creating-knowledge-graph",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#creating-knowledge-graph",
    "title": "Take Home Exercise 2",
    "section": "Creating Knowledge Graph",
    "text": "Creating Knowledge Graph\n\nMapping from node id to row index\nBefore we can go ahead to build the tidygraph object, it is important for us to ensures each id from the node list is mapped to the correct row number. This requirement can be achive by using the code chunk below.\n\nid_map &lt;- tibble(id = nodes_tbl$id,  #Retrieve the ID column of each row node\n                 index = seq_len(\n                   nrow(nodes_tbl)))  #Generate a line number sequence from 1 to n\n\n\n\nMap source and target IDs to row indices\nNext, we will map the source and the target IDs to row indices by using the code chunk below.\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%  # source id → from index\n  rename(from = index) %&gt;% \n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%  # target id → to index\n  rename(to = index)\n\n\n\n\n\n\n\nNote\n\n\n\nTo better understand the changes before and after the process, it is to take a screenshot of edges_tbl before and after this process and examine the differences.\n\n\n\n\nNow we can see the difference between before and after the edges_tbl.\n\ntable(edges_tbl$`Edge Type`)\n\n\n        ComposerOf            CoverOf    DirectlySamples      DistributedBy \n              3290               1429                619               3013 \n         InStyleOf   InterpolatesFrom LyricalReferenceTo         LyricistOf \n              2289               1574               1496               2985 \n          MemberOf        PerformerOf         ProducerOf         RecordedBy \n               568              13587               3209               3798 \n\n\n\n\nFilter out any unmatched (invalid) edges\nLastly, the code chunk below will be used to exclude the unmatch edges.\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\nCreating tidygraph\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl, \n                   edges = edges_tbl, \n                   directed = kg$directed)\n\n\ngraph\n\n# A tbl_graph: 17412 nodes and 37857 edges\n#\n# A directed multigraph with 16 components\n#\n# Node Data: 17,412 × 10 (active)\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;  &lt;chr&gt;        &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt; &lt;chr&gt;       \n 1 Song        Breaking Th… TRUE   2017         Ocea… TRUE        0 &lt;NA&gt;        \n 2 Person      Carlos Duffy NA     &lt;NA&gt;         &lt;NA&gt;  NA          1 &lt;NA&gt;        \n 3 Person      Min Qin      NA     &lt;NA&gt;         &lt;NA&gt;  NA          2 &lt;NA&gt;        \n 4 Person      Xiuying Xie  NA     &lt;NA&gt;         &lt;NA&gt;  NA          3 &lt;NA&gt;        \n 5 RecordLabel Nautical Mi… NA     &lt;NA&gt;         &lt;NA&gt;  NA          4 &lt;NA&gt;        \n 6 Song        Unshackled … FALSE  2026         Lo-F… TRUE        5 &lt;NA&gt;        \n 7 Person      Luke Payne   NA     &lt;NA&gt;         &lt;NA&gt;  NA          6 &lt;NA&gt;        \n 8 Person      Xiulan Zeng  NA     &lt;NA&gt;         &lt;NA&gt;  NA          7 &lt;NA&gt;        \n 9 Person      David Frank… NA     &lt;NA&gt;         &lt;NA&gt;  NA          8 &lt;NA&gt;        \n10 RecordLabel Colline-Cas… NA     &lt;NA&gt;         &lt;NA&gt;  NA          9 &lt;NA&gt;        \n# ℹ 17,402 more rows\n# ℹ 2 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;chr&gt;\n#\n# Edge Data: 37,857 × 6\n   from    to `Edge Type`      source target   key\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;             &lt;int&gt;  &lt;int&gt; &lt;int&gt;\n1     1  1842 InterpolatesFrom      0   1841     0\n2     1     5 RecordedBy            0      4     0\n3     2     1 PerformerOf           1      0     0\n# ℹ 37,854 more rows\n\n\nwe might want to confirm the output object is indeed in tidygraph format by using the code chunk below.\n\nclass(graph)\n\n[1] \"tbl_graph\" \"igraph\"",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#visualising-the-knowledge-graph",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#visualising-the-knowledge-graph",
    "title": "Take Home Exercise 2",
    "section": "Visualising the knowledge graph",
    "text": "Visualising the knowledge graph\nIn this section, we will use ggraph’s functions to visualise and analyse the graph object.\n\n\n\n\n\n\nWarning\n\n\n\nThe two examples below are not model answers, they are examples to show you how to use the mantra of Overview first, details on demand of visual investigation.\n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)\n\n\nVisualising the whole graph\nIn the code chunk below, ggraph functions are used to visualise the whole graph.\n\nggraph(graph, layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), \n                  size = 4) +\n  geom_node_text(aes(label = name), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\nNotice that the whole graph is very messy and we can hardy discover any useful patterns. This is always the case in graph visualisation and analysis. In order to gain meaningful visual discovery, it is always useful for us to looking into the details, for example by plotting sub-graphs.\n\n\nVisualising the sub-graph\nIn this section, we are interested to create a sub-graph base on MemberOf value in Edge Type column of the edges data frame.\n\nFiltering edges to only “MemberOf”\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%   ##\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\nExtracting only connected nodes (i.e., used in these edges)\n\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\nKeeping only those nodes\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id)  # optional cleanup\n\n\n\nPlotting the sub-graph\n\nggraph(graph_memberof, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.5, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), \n                  size = 1) +\n  geom_node_text(aes(label = name), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\nNotice that the sub-graph above is very clear and the relationship between musical group and person can be visualise easily.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#proceed-to-answer-the-questions-for-mini-challenge-1",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#proceed-to-answer-the-questions-for-mini-challenge-1",
    "title": "Take Home Exercise 2",
    "section": "Proceed to answer the questions for Mini-Challenge 1",
    "text": "Proceed to answer the questions for Mini-Challenge 1\nFirstly, I created an extract_subnetwork function to simplify the process of extracting network data. The methodology was referenced from a senior’s work. In this case, I will also add a direction parameter to allow for further filtering.\n\n\nExtract_subnetwork\nextract_subnetwork &lt;- function(graph, node_name, \n                               distance = NULL, \n                               direction = c(\"all\", \"in\", \"out\"),\n                               edge_types = NULL,\n                               node_types = NULL) {\n  direction &lt;- match.arg(direction)\n  node &lt;- which(V(graph)$name == node_name)\n  if (length(node) == 0) stop(\"Node name not found in graph.\")\n  distance &lt;- ifelse(is.null(distance), length(graph), distance)\n\n  mode &lt;- switch(direction,\n                 all = \"all\",\n                 `in` = \"in\",\n                 out = \"out\")\n\n  igraph_subgraph &lt;- induced_subgraph(graph, vids = ego(graph, node, order = distance, mode = mode)[[1]])\n\n  nodes_df &lt;- igraph::as_data_frame(igraph_subgraph, what = \"vertices\")\n  edges_df &lt;- igraph::as_data_frame(igraph_subgraph, what = \"edges\")\n\n  if (!is.null(edge_types)) {\n    edges_df &lt;- edges_df %&gt;% dplyr::filter(`Edge Type` %in% edge_types)\n  }\n\n  if (!is.null(node_types)) {\n    nodes_df &lt;- nodes_df %&gt;% dplyr::filter(`Node Type` %in% node_types)\n  }\n\n  used_node_ids &lt;- unique(c(edges_df$from, edges_df$to))\n  nodes_df &lt;- nodes_df %&gt;% dplyr::filter(name %in% used_node_ids)\n\n  tidygraph::tbl_graph(nodes = nodes_df, edges = edges_df, directed = igraph::is_directed(graph))\n}\n\n\nMini-Challenge 1 consists of three questions. Following a group discussion, I selected Question 1, and the steps I took to address the three sub-questions are described below.\n\nWho has she been most influenced by over time?\n\nTo address the first question, we considered both direct and indirect influences on Sailor Shift, as well as the temporal dynamics of these influences. The process was divided into three main steps:\n1.1 Identify the individuals who directly influenced her.\n\n1.2 Examine the works created by Sailor Shift, and trace any indirect influences on these works from others.\n\n1.3 Apply a timeline to analyze how these influences evolved over time and observe any trends in their impact.\nSailor Shift &lt;– Person\nSailor Shift –&gt; work &lt;– Person\nSailor Shift –&gt; work_s &lt;– work_p &lt;– Person\n\n\nWho has she been most influenced by over time?\ngrViz(\"\ndigraph complex_influence {\n  graph [layout = dot, rankdir = LR, splines = true]\n\n  node [fontname = Helvetica, style = filled, fillcolor = \\\"white\\\", shape = box]\n  edge [style = italic, fontname = Helvetica, fontsize = 12, labeldistance = 1.2, labelloc = c, color = gray30]\n\n\n  A   [label = 'Person A']\n  B   [label = 'Person B']\n  SS  [label = 'Sailor Shift', shape = ellipse, fillcolor = \\\"#fff7c0\\\"]\n  W   [label = 'Work s']\n  W1  [label = 'Work p']\n  WO  [label = 'Work o']  \n\n  A  -&gt; SS  [label = 'influences']\n  SS -&gt; W   [label = 'creates']\n  B  -&gt; W1  [label = 'creates']\n  W1 -&gt; W   [label = 'influences']\n  WO -&gt; SS  [label = 'influences']  \n}\n\")\n\n\n\n\nWho has she collaborated with and directly or indirectly influenced?\n\nTo address the second question, we examined both direct and indirect influences involving Sailor Shift, placing her at the center of the analysis.The process was divided into three main steps:\n2.1 Identify who she has collaborated with\nSailor Shift–&gt;work &lt;– Person\n\n\nWho has she collaborated with and directly or indirectly influenced?\ngrViz(\"\ndigraph sailor_collab {\n  graph [layout = dot, rankdir = LR]\n\n  node [fontname = Helvetica, style = filled, fillcolor = \\\"#ffffff\\\", shape = box,fontsize = 10, width = 0.5, height = 0.3]\n  edge [fontname = Helvetica, fontsize = 10, color = gray40]\n\n  Sailor [label = 'Sailor Shift', shape = ellipse, fillcolor = '#fff7c0']\n  Work   [label = 'Work', shape = box, fillcolor = '#e0f7fa']\n  Person [label = 'Collaborator', shape = ellipse]\n\n  Sailor -&gt; Work [label = 'co-created']\n  Person -&gt; Work [label = 'co-created']\n}\n\")\n\n\n\n2.2 Determine who she has directly or indirectly influenced\nSailor Shift –&gt; Person –&gt; work (direct)\nSailor Shift–&gt; work –&gt; Person (indirect)\n\n\nDetermine who she has directly or indirectly influenced\ngrViz(\"\ndigraph sailor_influence {\n  graph [layout = dot, rankdir = LR]\n\n  node [fontname = Helvetica, style = filled, fillcolor = \\\"#ffffff\\\", shape = box]\n  edge [fontname = Helvetica, fontsize = 11, labelfontsize = 11, color = gray40]\n\n  SS  [label = 'Sailor Shift', shape = ellipse, fillcolor = '#fff7c0']\n  P1  [label = 'Person\\n(direct)']\n  W1  [label = 'Work']\n  W2  [label = 'Work\\n(indirect)']\n  P2  [label = 'Person ']\n\n  SS -&gt; P1 [label = 'influences']\n  P1 -&gt; W1 [label = 'creates']\n\n  SS -&gt; W2 [label = 'creates']\n  W2 -&gt; P2 [label = 'influences']\n}\n\")\n\n\n\n3.How has she influenced collaborators of the broader Oceanus Folk community?\nSailor Shift–&gt; Person/community(Oceanus Folk) –&gt; Work(Oceanus Folk)\n\n\nHow has she influenced collaborators of the broader Oceanus Folk community?\ngrViz(\"\ndigraph oceanus_influence {\n  graph [layout = dot, rankdir = LR]\n\n  node [fontname = Helvetica, style = filled, fillcolor = \\\"#ffffff\\\", shape = box, fontsize = 10]\n  edge [fontname = Helvetica, fontsize = 9, color = gray40]\n\n  Sailor   [label = 'Sailor Shift', shape = ellipse, fillcolor = '#fff7c0']\n  Community [label = 'Person/Community\\\\n(Oceanus Folk)', shape = ellipse]\n  Work     [label = 'Work\\\\n(Oceanus Folk)', shape = box, fillcolor = '#e0f7fa']\n\n  Sailor -&gt; Community [label = 'influenced']\n  Community -&gt; Work   [label = 'created']\n}\n\")\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nIt is important to be especially careful with the direction of relationships such as “PerformerOf,” “ComposerOf,” “LyricistOf,” “ProducerOf,” as well as “DirectlySamples,” “InStyleOf,” “CoverOf,” “InterpolatesFrom,” and “LyricalReferenceTo.”\n\nSpecial attention must be paid to accurately identifying the source and target of each edge to preserve the correct semantic meaning.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#lets-begin.",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#lets-begin.",
    "title": "Take Home Exercise 2",
    "section": "Let’s begin.",
    "text": "Let’s begin.\n\n1.Who has she been most influenced by over time?\nThe following is the thinking process:\nSailor Shift &lt;– Person\nSailor Shift–&gt; work &lt;– Person\nSailor Shift–&gt; work_s &lt;– work_p &lt;– Person\nFrom the initial (though imperfect) visNetwork visualization, we first examined what she had produced, and then proceeded to explore further connections.\n\n\nFirst examined what she had produced\nsubgraph_in &lt;- extract_subnetwork(\n  graph, \n  node_name = \"Sailor Shift\", \n  distance = 5, \n  direction = \"out\"\n)\n\nsubgraph_igraph &lt;- as.igraph(subgraph_in)\n\nnodes_all &lt;- igraph::as_data_frame(subgraph_igraph, what = \"vertices\")\nedges_all &lt;- igraph::as_data_frame(subgraph_igraph, what = \"edges\")\n\nsailor_id &lt;- nodes_all$name[nodes_all$name == \"Sailor Shift\"]\nedges_1st &lt;- edges_all %&gt;% filter(from == \"Sailor Shift\")\n\nvalid_targets &lt;- edges_1st %&gt;%\n  left_join(nodes_all, by = c(\"to\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"MusicalGroup\", \"Song\", \"Album\",\"RecordLabel\")) %&gt;%\n  pull(to)\n\nvalid_node_ids &lt;- unique(c(\"Sailor Shift\", valid_targets))\nedges_vn &lt;- edges_all %&gt;% \n  filter(from %in% valid_node_ids | to %in% valid_node_ids)\n\nused_nodes &lt;- unique(c(edges_vn$from, edges_vn$to))\nnodes_vn &lt;- nodes_all %&gt;%\n  filter(name %in% used_nodes) %&gt;%\n  mutate(id = name, label = name, group = `Node Type`)\n\nedges_vn &lt;- edges_vn %&gt;%\n  mutate(\n    label = `Edge Type`, \n    title = paste0(\"Edge Type: \", `Edge Type`)  \n  )\n\n\n\nvisNetwork(nodes_vn, edges_vn, height = \"800px\", width = \"100%\") %&gt;%\n  visEdges(\n    arrows = \"to\",\n    font = list(\n      size = 12,         \n      align = \"middle\", \n      color = \"black\"    \n    )\n  ) %&gt;%  \n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 4, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\"\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1234) %&gt;%\n  visInteraction(navigationButtons = TRUE)\n\n\n\n\n\n\nFirst Layer Exploration\nWe started with all nodes directly connected from Sailor Shift, and added the type information of each corresponding from-node.\n\nedges_1st_full_named &lt;- edges_1st %&gt;%\n  left_join(nodes_all %&gt;% select(name, `Node Type`) %&gt;%\n              rename(from = name, `From Type` = `Node Type`), by = \"from\") %&gt;%\n  \n  left_join(nodes_all %&gt;% select(name, `Node Type`, release_date, genre, notable, notoriety_date) %&gt;%\n              rename(to = name, `To Type` = `Node Type`, `To Release` = release_date,\n                     `To Genre` = genre, `To Notable` = notable, `To Notoriety Date` = notoriety_date),\n            by = \"to\") %&gt;%\n  \n  select(from, `From Type`, to, `To Type`, `Edge Type`, `To Release`, `To Genre`, `To Notable`, `To Notoriety Date`)\n\n\nknitr::kable(edges_1st_full_named)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nNeon Heartbeat\nAlbum\nLyricistOf\n2031\nSynthwave\nFALSE\nNA\n\n\nSailor Shift\nPerson\nBallads for the End of Time\nAlbum\nLyricistOf\n2033\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nMelancholy Circuitry\nAlbum\nLyricistOf\n2033\nAmericana\nTRUE\nNA\n\n\nSailor Shift\nPerson\nDrifting Between the Stars and the Sea\nAlbum\nLyricistOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nArtificial Sunsets\nAlbum\nLyricistOf\n2035\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nElectric Reverie\nAlbum\nLyricistOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nBallads for the Low Tide\nAlbum\nLyricistOf\n2037\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Fiddle & The Fjord\nMusicalGroup\nInStyleOf\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nTides of Echos\nAlbum\nLyricistOf\n2029\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nHidden Depths\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nIvy Echos\nMusicalGroup\nDirectlySamples\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nIvy Echos\nMusicalGroup\nMemberOf\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nThe Kelp Forest Canticles\nAlbum\nLyricistOf\n2024\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nLuminescent Tides\nAlbum\nLyricistOf\n2025\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nShoreline Sonnets\nAlbum\nLyricistOf\n2026\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidal Pop Waves\nAlbum\nLyricistOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidal Pop Waves\nAlbum\nPerformerOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalty Dreams\nAlbum\nLyricistOf\n2030\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalty Dreams\nAlbum\nPerformerOf\n2030\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Current & The Chord\nAlbum\nLyricistOf\n2032\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Current & The Chord\nAlbum\nPerformerOf\n2032\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nCoral Beats\nAlbum\nLyricistOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nCoral Beats\nAlbum\nPerformerOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides & Ballads\nAlbum\nLyricistOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides & Ballads\nAlbum\nPerformerOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nOceanbound\nAlbum\nLyricistOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nOceanbound\nAlbum\nPerformerOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nEchoes of the Deep\nAlbum\nLyricistOf\n2040\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nEchoes of the Deep\nAlbum\nPerformerOf\n2040\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nHigh Tide Heartbeat\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nElectric Eel Love\nSong\nPerformerOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSun-Drenched Daydream\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nChord of the Deep\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nHeart of the Habitat\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nReef Rhythm\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nDriftwood Lullaby\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nSaltwater Hymn\nSong\nPerformerOf\n2032\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nMoon Over the Tide\nSong\nPerformerOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nInto the Current\nSong\nPerformerOf\n2034\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nBarnacle Heart\nSong\nPerformerOf\n2034\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nFog & Fiddle\nSong\nPerformerOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Fisherman’s Prayer\nSong\nPerformerOf\n2036\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nStormsong\nSong\nPerformerOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalt in My Veins\nSong\nPerformerOf\n2040\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nThe Last Mariner\nSong\nPerformerOf\n2040\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nThe Saltwater Weavers\nMusicalGroup\nInStyleOf\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nDrowned Harbor\nMusicalGroup\nLyricalReferenceTo\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nTidesworn Ballads\nAlbum\nPerformerOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidesworn Ballads\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSubmerged Sonatas\nAlbum\nPerformerOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSubmerged Sonatas\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSeashell Serenade\nSong\nPerformerOf\n2030\nOceanus Folk\nTRUE\n2030\n\n\n\n\n\nBelow is all the information on the First layer, and then remove if there is no other influenced layer\n\nDirectlySamples #InStyleOf #LyricalReferenceTo #LyricistOfMemberOf #PerformerOf\n\n\n\nselected_types &lt;- c(\"DirectlySamples\")\n\nedges_selected &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\nknitr::kable(edges_selected)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nIvy Echos\nMusicalGroup\nDirectlySamples\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\nselected_types &lt;- c(\"InStyleOf\")\n\nedges_selected &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\nknitr::kable(edges_selected)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nThe Fiddle & The Fjord\nMusicalGroup\nInStyleOf\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nThe Saltwater Weavers\nMusicalGroup\nInStyleOf\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\nselected_types &lt;- c(\"LyricalReferenceTo\")\n\nedges_selected_LyricalReferenceTo &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\nknitr::kable(edges_selected_LyricalReferenceTo)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nDrowned Harbor\nMusicalGroup\nLyricalReferenceTo\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\nselected_types &lt;- c(\"LyricistOf\")\n\nedges_selected &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\nknitr::kable(edges_selected)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nNeon Heartbeat\nAlbum\nLyricistOf\n2031\nSynthwave\nFALSE\nNA\n\n\nSailor Shift\nPerson\nBallads for the End of Time\nAlbum\nLyricistOf\n2033\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nMelancholy Circuitry\nAlbum\nLyricistOf\n2033\nAmericana\nTRUE\nNA\n\n\nSailor Shift\nPerson\nDrifting Between the Stars and the Sea\nAlbum\nLyricistOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nArtificial Sunsets\nAlbum\nLyricistOf\n2035\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nElectric Reverie\nAlbum\nLyricistOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nBallads for the Low Tide\nAlbum\nLyricistOf\n2037\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides of Echos\nAlbum\nLyricistOf\n2029\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nHidden Depths\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Kelp Forest Canticles\nAlbum\nLyricistOf\n2024\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nLuminescent Tides\nAlbum\nLyricistOf\n2025\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nShoreline Sonnets\nAlbum\nLyricistOf\n2026\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidal Pop Waves\nAlbum\nLyricistOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalty Dreams\nAlbum\nLyricistOf\n2030\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Current & The Chord\nAlbum\nLyricistOf\n2032\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nCoral Beats\nAlbum\nLyricistOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides & Ballads\nAlbum\nLyricistOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nOceanbound\nAlbum\nLyricistOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nEchoes of the Deep\nAlbum\nLyricistOf\n2040\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidesworn Ballads\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSubmerged Sonatas\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\n\n\n\n\n\n\nselected_types &lt;- c(\"MemberOf\")\n\nedges_selected &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\nknitr::kable(edges_selected)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nIvy Echos\nMusicalGroup\nMemberOf\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\nselected_types &lt;- c(\"PerformerOf\")\n\nedges_selected &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\nknitr::kable(edges_selected)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nTidal Pop Waves\nAlbum\nPerformerOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalty Dreams\nAlbum\nPerformerOf\n2030\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Current & The Chord\nAlbum\nPerformerOf\n2032\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nCoral Beats\nAlbum\nPerformerOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides & Ballads\nAlbum\nPerformerOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nOceanbound\nAlbum\nPerformerOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nEchoes of the Deep\nAlbum\nPerformerOf\n2040\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nHigh Tide Heartbeat\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nElectric Eel Love\nSong\nPerformerOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSun-Drenched Daydream\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nChord of the Deep\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nHeart of the Habitat\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nReef Rhythm\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nDriftwood Lullaby\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nSaltwater Hymn\nSong\nPerformerOf\n2032\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nMoon Over the Tide\nSong\nPerformerOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nInto the Current\nSong\nPerformerOf\n2034\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nBarnacle Heart\nSong\nPerformerOf\n2034\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nFog & Fiddle\nSong\nPerformerOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Fisherman’s Prayer\nSong\nPerformerOf\n2036\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nStormsong\nSong\nPerformerOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalt in My Veins\nSong\nPerformerOf\n2040\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nThe Last Mariner\nSong\nPerformerOf\n2040\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nTidesworn Ballads\nAlbum\nPerformerOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSubmerged Sonatas\nAlbum\nPerformerOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSeashell Serenade\nSong\nPerformerOf\n2030\nOceanus Folk\nTRUE\n2030\n\n\n\n\n\n\n\n\nThen we can visual all the connect from Sailor:\n\nedges_1st_filtered &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% c(\"LyricistOf\", \"PerformerOf\", \"MemberOf\"))\n\nknitr::kable(edges_1st_filtered)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Type\nto\nTo Type\nEdge Type\nTo Release\nTo Genre\nTo Notable\nTo Notoriety Date\n\n\n\n\nSailor Shift\nPerson\nNeon Heartbeat\nAlbum\nLyricistOf\n2031\nSynthwave\nFALSE\nNA\n\n\nSailor Shift\nPerson\nBallads for the End of Time\nAlbum\nLyricistOf\n2033\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nMelancholy Circuitry\nAlbum\nLyricistOf\n2033\nAmericana\nTRUE\nNA\n\n\nSailor Shift\nPerson\nDrifting Between the Stars and the Sea\nAlbum\nLyricistOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nArtificial Sunsets\nAlbum\nLyricistOf\n2035\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nElectric Reverie\nAlbum\nLyricistOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nBallads for the Low Tide\nAlbum\nLyricistOf\n2037\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides of Echos\nAlbum\nLyricistOf\n2029\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nHidden Depths\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nIvy Echos\nMusicalGroup\nMemberOf\nNA\nNA\nNA\nNA\n\n\nSailor Shift\nPerson\nThe Kelp Forest Canticles\nAlbum\nLyricistOf\n2024\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nLuminescent Tides\nAlbum\nLyricistOf\n2025\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nShoreline Sonnets\nAlbum\nLyricistOf\n2026\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidal Pop Waves\nAlbum\nLyricistOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidal Pop Waves\nAlbum\nPerformerOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalty Dreams\nAlbum\nLyricistOf\n2030\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalty Dreams\nAlbum\nPerformerOf\n2030\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Current & The Chord\nAlbum\nLyricistOf\n2032\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Current & The Chord\nAlbum\nPerformerOf\n2032\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nCoral Beats\nAlbum\nLyricistOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nCoral Beats\nAlbum\nPerformerOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides & Ballads\nAlbum\nLyricistOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTides & Ballads\nAlbum\nPerformerOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nOceanbound\nAlbum\nLyricistOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nOceanbound\nAlbum\nPerformerOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nEchoes of the Deep\nAlbum\nLyricistOf\n2040\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nEchoes of the Deep\nAlbum\nPerformerOf\n2040\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nHigh Tide Heartbeat\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nElectric Eel Love\nSong\nPerformerOf\n2028\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSun-Drenched Daydream\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nChord of the Deep\nSong\nPerformerOf\n2028\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nHeart of the Habitat\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nReef Rhythm\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nDriftwood Lullaby\nSong\nPerformerOf\n2030\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nSaltwater Hymn\nSong\nPerformerOf\n2032\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nMoon Over the Tide\nSong\nPerformerOf\n2034\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nInto the Current\nSong\nPerformerOf\n2034\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nBarnacle Heart\nSong\nPerformerOf\n2034\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nFog & Fiddle\nSong\nPerformerOf\n2036\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nThe Fisherman’s Prayer\nSong\nPerformerOf\n2036\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nStormsong\nSong\nPerformerOf\n2038\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSalt in My Veins\nSong\nPerformerOf\n2040\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nThe Last Mariner\nSong\nPerformerOf\n2040\nOceanus Folk\nFALSE\nNA\n\n\nSailor Shift\nPerson\nTidesworn Ballads\nAlbum\nPerformerOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nTidesworn Ballads\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSubmerged Sonatas\nAlbum\nPerformerOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSubmerged Sonatas\nAlbum\nLyricistOf\n2031\nOceanus Folk\nTRUE\nNA\n\n\nSailor Shift\nPerson\nSeashell Serenade\nSong\nPerformerOf\n2030\nOceanus Folk\nTRUE\n2030\n\n\n\n\n\n\n\nAll the connect from Sailor-Song & Album & Group\nedge_colors &lt;- c(\n  \"PerformerOf\"         = \"#2ca02c\",\n\n  \"LyricistOf\"          = \"#1f77b4\",\n \n \n  \"MemberOf\"            = \"#d62728\"\n)\n\nnodes_subgraph &lt;- nodes_all %&gt;%\n  filter(name %in% c(\"Sailor Shift\", edges_1st_filtered$to)) %&gt;%\n  transmute(id = name, label = name, group = `Node Type`)\n\nedges_subgraph &lt;- edges_1st_filtered %&gt;%\n  left_join(\n    nodes_all %&gt;% select(name, `Node Type`) %&gt;% rename(to = name, to_type = `Node Type`),\n    by = \"to\"\n  ) %&gt;%\n  mutate(\n    color = edge_colors[`Edge Type`],\n    title = paste0(\"Edge Type: \", `Edge Type`, \"&lt;br&gt;To Type: \", to_type)\n  ) %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    title = title,\n    color = color,\n    arrows = \"to\"\n  )\n\nedge_legend &lt;- data.frame(\n  label = names(edge_colors),\n  color = unname(edge_colors),\n  arrows = rep(\"to\", length(edge_colors)),\n  stringsAsFactors = FALSE\n)\n\n\n\nvisNetwork(nodes_subgraph, edges_subgraph, width = \"100%\", height = \"700px\") %&gt;%\n  visEdges(smooth = TRUE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLegend(\n    addEdges = edge_legend,\n    useGroups = TRUE,\n    position = \"right\",\n  ) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(gravitationalConstant = -80),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\nWhat we can find from the network？\n\n\n\nShe is a highly prolific creator\n\nThe dense number of outgoing edges indicates that Sailor Shift has contributed to or performed a large number of works, including both songs and albums.\nThe number of connected nodes shows she is linked to over 20 works, placing her at the center of the network.\n\nShe plays both performer and lyricist roles\nThe presence of many green edges (PerformerOf) and blue edges (LyricistOf) suggests:\n\nShe not only performs but also writes lyrics for her works.\nShe plays a dual role in the music creation process, showing versatility as both a performer and a songwriter.\n\nShe is not an entirely solo artist\nA red edge (MemberOf) connects her to the red node Ivy Echos, indicating:\n\nShe is a member of this musical group.\nSome of her creative output may result from group collaboration.\nShe maintains a balance between solo and group work.\n\nSailor Shift is a central figure,skilled in both songwriting and performance, and active in both solo and collaborative projects. Her work likely forms a key part of the community’s creative landscape.\n\n\n\n\nThird Layer Exploration\nNext, we aim to explore other’s relationship with Ivy Echos.”\n\nivy_groups &lt;- edges_all %&gt;%\n  filter(to == \"Ivy Echos\", `Edge Type` == \"MemberOf\") %&gt;%\n  pull(from)\nivy_groups\n\n[1] \"Sailor Shift\"\n\n\n\ngroup_members &lt;- edges_all %&gt;%\n  filter(`Edge Type` == \"MemberOf\", to %in% ivy_groups) %&gt;%\n  select(from, to) %&gt;%\n  rename(Member = from, Group = to)\n\nprint(group_members)\n\n[1] Member Group \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nWe attempted to identify the MemberOf relationships for Ivy Echos, but the results suggest that this information is not included in the current dataset.”\n\nsailor_works &lt;- edges_1st_full_named %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\", \"LyricistOf\", \"ProducerOf\",\"MemberOf\"),\n         `To Type` %in% c(\"Song\", \"Album\",\"MusicalGroup\",\"Person\",\"RecordLabel\")) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\nedges_others &lt;- edges_all %&gt;%\n  filter(\n    to %in% sailor_works,\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\", \"LyricistOf\", \"ProducerOf\"),\n    from != \"Sailor Shift\"  \n  )\n\nedges_others_full &lt;- edges_others %&gt;%\n  left_join(nodes_all, by = c(\"from\" = \"name\")) %&gt;%\n  rename(Participant = from, ParticipantType = `Node Type`) %&gt;%\n  select(Participant, ParticipantType, to, `Edge Type`)\n\nknitr::kable(edges_others_full)\n\n\n\n\nParticipant\nParticipantType\nto\nEdge Type\n\n\n\n\nIvy Echos\nMusicalGroup\nThe Kelp Forest Canticles\nPerformerOf\n\n\nIvy Echos\nMusicalGroup\nLuminescent Tides\nPerformerOf\n\n\nIvy Echos\nMusicalGroup\nShoreline Sonnets\nPerformerOf\n\n\n\n\n\nFrom the result we can see, in this dataset,Ivy Echos has perform three songs.These will late add in the Folk Musci Group for further analysis.\nFor more convenient exploration, we selected the nodes connected to the third layer in order to observe indirect influences\nGet the complete information of the from node\nSailor Shift –(PerformerOf etc.)–&gt; Song A –(InStyleOf etc.)–&gt; Song B\n\n\nGet the complete information of the from node\nnodes_tbl &lt;- nodes_tbl %&gt;% mutate(index = row_number())\n\nsailor_index &lt;- nodes_tbl %&gt;%\n  filter(name == \"Sailor Shift\") %&gt;%\n  pull(index)\n\nedges_from_sailor &lt;- edges_tbl %&gt;%\n  filter(from == sailor_index)\n\nfirst_layer_info &lt;- edges_from_sailor %&gt;%\n  inner_join(nodes_tbl, by = c(\"to\" = \"index\")) %&gt;%\n  filter(`Node Type` %in% c(\"Song\", \"Album\", \"MusicalGroup\", \"RecordLabel\"))\n\nfirst_layer_targets &lt;- first_layer_info$to\n\ninfluence_edges &lt;- c(\"InStyleOf\", \"LyricalReferenceTo\", \"InterpolatesFrom\", \"CoverOf\", \"DirectlySamples\")\n\nedges_2nd &lt;- edges_tbl %&gt;%\n  filter(from %in% first_layer_targets & `Edge Type` %in% influence_edges)\n\n\nIn order to find more insights in one table, we have added the “from” information to the data frame\n\n\nGet the complete information of the from node\nedges_1st &lt;- edges_all %&gt;%\n  filter(from == \"Sailor Shift\")\n\nedges_1st_full &lt;- edges_1st %&gt;%\n  left_join(nodes_all, by = c(\"to\" = \"name\")) %&gt;%\n  select(from, to, `Edge Type`, `Node Type`, release_date,genre,notable,notoriety_date)\n\nselected_types &lt;- c(\"LyricistOf\", \"PerformerOf\")\nedges_selected &lt;- edges_1st_full %&gt;%\n  filter(`Edge Type` %in% selected_types)\n\ntarget_nodes &lt;- unique(edges_selected$to)\n\nedges_2nd &lt;- edges_all %&gt;%\n  filter(from %in% target_nodes)\n\nfrom_info &lt;- nodes_all %&gt;%\n  select(name, `Node Type`) %&gt;%\n  rename(from = name, `From Node Type` = `Node Type`)\n\nto_info &lt;- nodes_all %&gt;%\n  select(name, `Node Type`, release_date, genre, notable, notoriety_date) %&gt;%\n  rename(\n    to = name,\n    `To Node Type` = `Node Type`,\n    to_release_date = release_date,\n    to_genre = genre,\n    to_notable = notable,\n    to_notoriety_date = notoriety_date\n  )\n\nedges_2nd_full &lt;- edges_2nd %&gt;%\n  left_join(from_info, by = \"from\") %&gt;%\n  left_join(to_info, by = \"to\") %&gt;%\n  select(\n    from, `From Node Type`, to, `To Node Type`, `Edge Type`,\n    to_release_date, to_genre, to_notable, to_notoriety_date\n  )\n\n\nknitr::kable(edges_2nd_full)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Node Type\nto\nTo Node Type\nEdge Type\nto_release_date\nto_genre\nto_notable\nto_notoriety_date\n\n\n\n\nMelancholy Circuitry\nAlbum\nTwilight’s Threshold\nSong\nCoverOf\n2007\nSynthwave\nTRUE\n2007\n\n\nElectric Reverie\nAlbum\nReflejo Interior\nSong\nInterpolatesFrom\n1983\nAmericana\nTRUE\nNA\n\n\nElectric Reverie\nAlbum\nFolklore’s Heartbeat\nSong\nInStyleOf\n2020\nBlues Rock\nTRUE\n2033\n\n\nTides of Echos\nAlbum\nThe Long Way Home\nAlbum\nInStyleOf\n2023\nDream Pop\nTRUE\nNA\n\n\nTides of Echos\nAlbum\nWeathered Miles\nSong\nInterpolatesFrom\n2023\nDoom Metal\nTRUE\nNA\n\n\nThe Kelp Forest Canticles\nAlbum\nHallowed Transaction\nAlbum\nDirectlySamples\n2017\nDoom Metal\nTRUE\nNA\n\n\nThe Kelp Forest Canticles\nAlbum\nFür uns alle zusammen\nSong\nCoverOf\n2017\nAlternative Rock\nTRUE\nNA\n\n\nSalty Dreams\nAlbum\nSusurros de Pasión\nSong\nInStyleOf\n2004\nSynthwave\nTRUE\n2004\n\n\nSalty Dreams\nAlbum\nPartisan’s Lament\nSong\nCoverOf\n2030\nIndie Pop\nTRUE\nNA\n\n\nCoral Beats\nAlbum\nSacred Fragments\nSong\nInStyleOf\n2003\nSynthwave\nTRUE\n2003\n\n\nCoral Beats\nAlbum\nHarvest Dance at Ler Valley\nSong\nCoverOf\n2010\nPsychedelic Rock\nTRUE\nNA\n\n\nOceanbound\nAlbum\nBold Without Apology\nSong\nLyricalReferenceTo\n2010\nIndie Rock\nTRUE\nNA\n\n\nOceanbound\nAlbum\nAltitude of Mistakes\nSong\nLyricalReferenceTo\n2015\nAmericana\nTRUE\n2015\n\n\nHigh Tide Heartbeat\nSong\nAddicted to Your Heartache\nAlbum\nInterpolatesFrom\n2004\nSouthern Gothic Rock\nTRUE\nNA\n\n\nElectric Eel Love\nSong\nTwelve Bells of Augsburg\nSong\nInStyleOf\n2026\nPsychedelic Rock\nTRUE\nNA\n\n\nElectric Eel Love\nSong\nThe Crown We Wear\nSong\nCoverOf\n2022\nIndie Rock\nTRUE\nNA\n\n\nDriftwood Lullaby\nSong\nEchoes of Forgotten Light\nSong\nInStyleOf\n2004\nAlternative Rock\nTRUE\nNA\n\n\nSaltwater Hymn\nSong\nParallel Memories\nSong\nInStyleOf\n2028\nDream Pop\nTRUE\nNA\n\n\nMoon Over the Tide\nSong\nDivergent Memories\nSong\nInterpolatesFrom\n2017\nIndie Folk\nTRUE\n2017\n\n\nMoon Over the Tide\nSong\nSilent Steps in the Forest’s Embrace\nSong\nLyricalReferenceTo\n2023\nAvant-Garde Folk\nTRUE\n2023\n\n\nBarnacle Heart\nSong\nOur Inevitable Path\nSong\nInStyleOf\n2017\nIndie Folk\nTRUE\nNA\n\n\nFog & Fiddle\nSong\nProvence Aria\nSong\nInStyleOf\n2023\nIndie Rock\nTRUE\nNA\n\n\nFog & Fiddle\nSong\nCoastal Whispers of Biscay\nSong\nInterpolatesFrom\n2031\nAlternative Rock\nTRUE\nNA\n\n\nStormsong\nSong\nWhen the Bar Lights Go Up\nSong\nInStyleOf\n2000\nEmo/Pop Punk\nTRUE\nNA\n\n\nStormsong\nSong\nExoskeleton Dissolve\nSong\nDirectlySamples\n2020\nIndie Rock\nTRUE\n2020\n\n\nTidesworn Ballads\nAlbum\nDreamscape of Judgment\nSong\nCoverOf\n2023\nSymphonic Metal\nTRUE\nNA\n\n\n\n\n\n\n\nGet the complete information of the from node (From and To Info)\nfrom_info &lt;- nodes_all %&gt;%\n  select(name, `Node Type`, release_date, genre, notable, notoriety_date) %&gt;%\n  rename(\n    from = name,\n    `From Node Type` = `Node Type`,\n    from_release_date = release_date,\n    from_genre = genre,\n    from_notable = notable,\n    from_notoriety_date = notoriety_date\n  )\n\nto_info &lt;- nodes_all %&gt;%\n  select(name, `Node Type`, release_date, genre, notable, notoriety_date) %&gt;%\n  rename(\n    to = name,\n    `To Node Type` = `Node Type`,\n    to_release_date = release_date,\n    to_genre = genre,\n    to_notable = notable,\n    to_notoriety_date = notoriety_date\n  )\n\nedges_2nd_full &lt;- edges_2nd %&gt;%\n  left_join(from_info, by = \"from\") %&gt;%\n  left_join(to_info, by = \"to\") %&gt;%\n  select(\n    from, `From Node Type`, from_release_date, from_genre, from_notable, from_notoriety_date,\n    to, `To Node Type`, to_release_date, to_genre, to_notable, to_notoriety_date,\n    `Edge Type`\n  )\n\nknitr::kable(edges_2nd_full)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nFrom Node Type\nfrom_release_date\nfrom_genre\nfrom_notable\nfrom_notoriety_date\nto\nTo Node Type\nto_release_date\nto_genre\nto_notable\nto_notoriety_date\nEdge Type\n\n\n\n\nMelancholy Circuitry\nAlbum\n2033\nAmericana\nTRUE\nNA\nTwilight’s Threshold\nSong\n2007\nSynthwave\nTRUE\n2007\nCoverOf\n\n\nElectric Reverie\nAlbum\n2038\nOceanus Folk\nTRUE\nNA\nReflejo Interior\nSong\n1983\nAmericana\nTRUE\nNA\nInterpolatesFrom\n\n\nElectric Reverie\nAlbum\n2038\nOceanus Folk\nTRUE\nNA\nFolklore’s Heartbeat\nSong\n2020\nBlues Rock\nTRUE\n2033\nInStyleOf\n\n\nTides of Echos\nAlbum\n2029\nOceanus Folk\nTRUE\nNA\nThe Long Way Home\nAlbum\n2023\nDream Pop\nTRUE\nNA\nInStyleOf\n\n\nTides of Echos\nAlbum\n2029\nOceanus Folk\nTRUE\nNA\nWeathered Miles\nSong\n2023\nDoom Metal\nTRUE\nNA\nInterpolatesFrom\n\n\nThe Kelp Forest Canticles\nAlbum\n2024\nOceanus Folk\nTRUE\nNA\nHallowed Transaction\nAlbum\n2017\nDoom Metal\nTRUE\nNA\nDirectlySamples\n\n\nThe Kelp Forest Canticles\nAlbum\n2024\nOceanus Folk\nTRUE\nNA\nFür uns alle zusammen\nSong\n2017\nAlternative Rock\nTRUE\nNA\nCoverOf\n\n\nSalty Dreams\nAlbum\n2030\nOceanus Folk\nTRUE\nNA\nSusurros de Pasión\nSong\n2004\nSynthwave\nTRUE\n2004\nInStyleOf\n\n\nSalty Dreams\nAlbum\n2030\nOceanus Folk\nTRUE\nNA\nPartisan’s Lament\nSong\n2030\nIndie Pop\nTRUE\nNA\nCoverOf\n\n\nCoral Beats\nAlbum\n2034\nOceanus Folk\nTRUE\nNA\nSacred Fragments\nSong\n2003\nSynthwave\nTRUE\n2003\nInStyleOf\n\n\nCoral Beats\nAlbum\n2034\nOceanus Folk\nTRUE\nNA\nHarvest Dance at Ler Valley\nSong\n2010\nPsychedelic Rock\nTRUE\nNA\nCoverOf\n\n\nOceanbound\nAlbum\n2038\nOceanus Folk\nTRUE\nNA\nBold Without Apology\nSong\n2010\nIndie Rock\nTRUE\nNA\nLyricalReferenceTo\n\n\nOceanbound\nAlbum\n2038\nOceanus Folk\nTRUE\nNA\nAltitude of Mistakes\nSong\n2015\nAmericana\nTRUE\n2015\nLyricalReferenceTo\n\n\nHigh Tide Heartbeat\nSong\n2028\nOceanus Folk\nFALSE\nNA\nAddicted to Your Heartache\nAlbum\n2004\nSouthern Gothic Rock\nTRUE\nNA\nInterpolatesFrom\n\n\nElectric Eel Love\nSong\n2028\nOceanus Folk\nTRUE\nNA\nTwelve Bells of Augsburg\nSong\n2026\nPsychedelic Rock\nTRUE\nNA\nInStyleOf\n\n\nElectric Eel Love\nSong\n2028\nOceanus Folk\nTRUE\nNA\nThe Crown We Wear\nSong\n2022\nIndie Rock\nTRUE\nNA\nCoverOf\n\n\nDriftwood Lullaby\nSong\n2030\nOceanus Folk\nFALSE\nNA\nEchoes of Forgotten Light\nSong\n2004\nAlternative Rock\nTRUE\nNA\nInStyleOf\n\n\nSaltwater Hymn\nSong\n2032\nOceanus Folk\nFALSE\nNA\nParallel Memories\nSong\n2028\nDream Pop\nTRUE\nNA\nInStyleOf\n\n\nMoon Over the Tide\nSong\n2034\nOceanus Folk\nTRUE\nNA\nDivergent Memories\nSong\n2017\nIndie Folk\nTRUE\n2017\nInterpolatesFrom\n\n\nMoon Over the Tide\nSong\n2034\nOceanus Folk\nTRUE\nNA\nSilent Steps in the Forest’s Embrace\nSong\n2023\nAvant-Garde Folk\nTRUE\n2023\nLyricalReferenceTo\n\n\nBarnacle Heart\nSong\n2034\nOceanus Folk\nFALSE\nNA\nOur Inevitable Path\nSong\n2017\nIndie Folk\nTRUE\nNA\nInStyleOf\n\n\nFog & Fiddle\nSong\n2036\nOceanus Folk\nTRUE\nNA\nProvence Aria\nSong\n2023\nIndie Rock\nTRUE\nNA\nInStyleOf\n\n\nFog & Fiddle\nSong\n2036\nOceanus Folk\nTRUE\nNA\nCoastal Whispers of Biscay\nSong\n2031\nAlternative Rock\nTRUE\nNA\nInterpolatesFrom\n\n\nStormsong\nSong\n2038\nOceanus Folk\nTRUE\nNA\nWhen the Bar Lights Go Up\nSong\n2000\nEmo/Pop Punk\nTRUE\nNA\nInStyleOf\n\n\nStormsong\nSong\n2038\nOceanus Folk\nTRUE\nNA\nExoskeleton Dissolve\nSong\n2020\nIndie Rock\nTRUE\n2020\nDirectlySamples\n\n\nTidesworn Ballads\nAlbum\n2031\nOceanus Folk\nTRUE\nNA\nDreamscape of Judgment\nSong\n2023\nSymphonic Metal\nTRUE\nNA\nCoverOf\n\n\n\n\n\nNow we can observe the next layer — identifying which songs and related works have influenced Sailor Shift. At the same time, we also aim to incorporate the time dimension into this analysis.\n\n\nConstruct edges_time_ready data\n\n\nConstruct edges_time_ready data\nedges_time_ready &lt;- edges_2nd_full %&gt;%\n  mutate(\n    from_release_date = as.numeric(from_release_date),\n    to_release_date = as.numeric(to_release_date)\n  ) %&gt;%\n  filter(!is.na(from_release_date) & !is.na(to_release_date)) %&gt;%\n  mutate(\n    influencer_point = to,\n    sailor_point = from,\n    work_label = paste0(from, \" (Sailor)\"),\n    y_axis_label = paste0(from, \" (Sailor)\") \n  ) %&gt;%\n  tidyr::pivot_longer(\n    cols = c(to_release_date, from_release_date),\n    names_to = \"timepoint\",\n    values_to = \"year\"\n  ) %&gt;%\n  mutate(\n    point_type = ifelse(timepoint == \"from_release_date\", \"Sailor\", \"Influencer\"),\n    label = ifelse(point_type == \"Sailor\", from, to),\n    label_display = ifelse(point_type == \"Sailor\", paste0(label, \" (Sailor)\"), label),\n    genre = ifelse(point_type == \"Sailor\", from_genre, to_genre),\n    notable = ifelse(point_type == \"Sailor\", from_notable, to_notable)\n  )\n\n\n\np &lt;- ggplot(edges_time_ready, aes(x = year, y = y_axis_label, group = paste(from, to))) +\n  geom_line(\n    aes(text = paste(\"Influence:\", to, \"→\", from)),\n    color = \"grey40\", linewidth = 0.4, alpha = 0.6\n  ) +\n  geom_point(\n    aes(\n      text = paste0(\n        \"Year: \", year,\n        \"&lt;br&gt;Work: \", label_display,\n        \"&lt;br&gt;Type: \", point_type,\n        \"&lt;br&gt;Genre: \", genre,\n        \"&lt;br&gt;Notable: \", ifelse(notable == TRUE, \"Yes\", \"No\"),\n        \"&lt;br&gt;Edge Type: \", `Edge Type`\n      ),\n      color = point_type\n    ),\n    size = 1.8, alpha = 0.9\n  ) +\n  scale_color_manual(values = c(\"Influencer\" = \"#1F78B4\", \"Sailor\" = \"#E41A1C\")) +\n  labs(\n    title = \"Influence Timeline of Sailor Shift's Works\",\n    subtitle = \"Lines point to Sailor's works (fixed y-axis)\",\n    x = \"Release Year\", y = \"Sailor's Work\", color = \"Point Type\"\n  ) +\n  scale_x_continuous(breaks = pretty(edges_time_ready$year, n = 10)) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 7),\n    plot.title = element_text(hjust = 0, face = \"bold\", size = 16),\n    panel.grid.minor = element_blank(),\n    legend.position = \"bottom\",\n   \n  )\n\ninteractive_plot &lt;- plotly::ggplotly(p, tooltip = \"text\")\ninteractive_plot\n\n\n\n\n\n\n\n\n\n\n\nWhen was she influenced, by whom, and in what way?\n\n\n\nTiming and Type of Influence\n\nSailor Shift’s compositions were inspired by a wide temporal range of influencer works from the 1980s to the 2020s.\nNotable classics that shaped her music include:\nReflejo Interior (1983, Americana) → Influenced Electric Reverie\nTwilight’s Threshold (2007, Synthwave) → Influenced Tides of Echos\nHallowed Transaction (2017, Doom Metal) and Divergent Memories (2017, Indie Folk) → Contributed to her emerging Indie and Metal sounds\nFrom a genre perspective, Sailor draws from Synthwave, Doom Metal, Dream Pop, Indie Rock, and Psychedelic Rock, blending them into her distinctive Oceanus Folk style.\n\nTime Distribution & Creative Rhythm\n\n2015–2020 marks the starting phase of stylistic absorption.\n\nSongs like Melancholy Circuitry and Stormsong show early influence connections — indicating the onset of external musical borrowing.\n2023–2035 is her most active creative and stylistic integration period.\n\nThe visualization shows a dense cluster of red points (Sailor’s works) and blue points (influencer works), suggesting heavy external inspiration and high creative output during this time.\n\nCreative Maturity vs. Density of Inspiration\n\nSongs such as:\nTidesworn Ballads, Coral Beats, Driftwood Lullaby, Electric Reverie\n\nare influenced by multiple sources — identifying them as “convergent inspiration” pieces reflecting diverse stylistic integration.\nData also reveals:\nMost of Sailor’s songs are of the Oceanus Folk genre, while the influencers span Synthwave, Southern Gothic, Indie Pop, Symphonic Metal, and more.\nHer most notable works (marked as Notable = TRUE) tend to be those that were heavily influenced — indicating that inspiration led to impact.\n\n\n\nWe analyze the ‘Other Person → Other Work → Sailor’ connections that contribute to the influence on Sailor Shift’s second-layer works.\n\n\nConnections on Sailor Shift’s second-layer works\nnodes_tbl &lt;- nodes_tbl %&gt;% mutate(index = row_number())\n\nsailor_index &lt;- nodes_tbl %&gt;%\n  filter(name == \"Sailor Shift\") %&gt;%\n  pull(index)\n\nedges_from_sailor &lt;- edges_tbl %&gt;%\n  filter(from == sailor_index)\n\nfirst_layer_info &lt;- edges_from_sailor %&gt;%\n  inner_join(nodes_tbl, by = c(\"to\" = \"index\")) %&gt;%\n  filter(`Node Type` %in% c(\"Song\", \"Album\", \"MusicalGroup\", \"RecordLabel\"))\n\nfirst_layer_targets &lt;- first_layer_info$to\n\ninfluence_edges &lt;- c(\"InStyleOf\", \"LyricalReferenceTo\", \"InterpolatesFrom\", \"CoverOf\", \"DirectlySamples\")\n\nedges_2nd &lt;- edges_tbl %&gt;%\n  filter(from %in% first_layer_targets & `Edge Type` %in% influence_edges)\n\ninfluenced_works &lt;- edges_2nd$to\nsongs_with_outgoing &lt;- unique(edges_2nd$from)\n\nperson_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"LyricistOf\", \"ProducerOf\")\n\nedges_people_to_2nd &lt;- edges_tbl %&gt;%\n  filter(\n    to %in% influenced_works,\n    `Edge Type` %in% person_edge_types\n  ) %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, `Node Type`), by = c(\"from\" = \"index\")) %&gt;%\n  rename(`From Node Type` = `Node Type`) %&gt;%\n  filter(`From Node Type` %in% c(\"Person\", \"RecordLabel\")) %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, `Node Type`, release_date), by = c(\"to\" = \"index\")) %&gt;%\n  rename(`To Node Type` = `Node Type`, release_date = release_date)\n\n\n\n\nIndirectly influenced Sailor work and Sailor\nHere we can clearly see ,who has indirectly influenced Sailor work and Sailor.\n\nedges_people_to_2nd_tbl &lt;- edges_people_to_2nd %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, name), by = c(\"from\" = \"index\")) %&gt;%\n  rename(`Person Name` = name) %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, name), by = c(\"to\" = \"index\")) %&gt;%\n  rename(`Work Name` = name) %&gt;%\n  select(`Person Name`, `Work Name`, `Edge Type`, `From Node Type`, `To Node Type`, release_date)\n\nknitr::kable(edges_people_to_2nd_tbl)\n\n\n\n\n\n\n\n\n\n\n\n\nPerson Name\nWork Name\nEdge Type\nFrom Node Type\nTo Node Type\nrelease_date\n\n\n\n\nMing Ren\nProvence Aria\nPerformerOf\nPerson\nSong\n2023\n\n\nBelinda Knappe\nHarvest Dance at Ler Valley\nProducerOf\nPerson\nSong\n2010\n\n\nYang Peng\nSacred Fragments\nPerformerOf\nPerson\nSong\n2003\n\n\nYang Peng\nSacred Fragments\nProducerOf\nPerson\nSong\n2003\n\n\nMin Cao\nSacred Fragments\nPerformerOf\nPerson\nSong\n2003\n\n\nQiang Zhou\nBold Without Apology\nComposerOf\nPerson\nSong\n2010\n\n\nJing Kang\nBold Without Apology\nPerformerOf\nPerson\nSong\n2010\n\n\nJing Kang\nBold Without Apology\nProducerOf\nPerson\nSong\n2010\n\n\nJun Zhou\nSusurros de Pasión\nPerformerOf\nPerson\nSong\n2004\n\n\nYong Dong\nAltitude of Mistakes\nPerformerOf\nPerson\nSong\n2015\n\n\nUrszula Stochmal\nAddicted to Your Heartache\nPerformerOf\nPerson\nAlbum\n2004\n\n\nUrszula Stochmal\nAddicted to Your Heartache\nLyricistOf\nPerson\nAlbum\n2004\n\n\nUrszula Stochmal\nAddicted to Your Heartache\nComposerOf\nPerson\nAlbum\n2004\n\n\nMing Long\nTwilight’s Threshold\nPerformerOf\nPerson\nSong\n2007\n\n\nMing Long\nTwilight’s Threshold\nProducerOf\nPerson\nSong\n2007\n\n\nYong Lu\nTwilight’s Threshold\nLyricistOf\nPerson\nSong\n2007\n\n\nYang Wan\nSacred Fragments\nComposerOf\nPerson\nSong\n2003\n\n\nYoko Hashimoto\nHallowed Transaction\nProducerOf\nPerson\nAlbum\n2017\n\n\nKaori Ito\nHallowed Transaction\nComposerOf\nPerson\nAlbum\n2017\n\n\nNaoko Sato\nHallowed Transaction\nLyricistOf\nPerson\nAlbum\n2017\n\n\nNaoko Sato\nHallowed Transaction\nPerformerOf\nPerson\nAlbum\n2017\n\n\nYan Tang\nAltitude of Mistakes\nComposerOf\nPerson\nSong\n2015\n\n\nJeremiah Love\nTwelve Bells of Augsburg\nPerformerOf\nPerson\nSong\n2026\n\n\nJeremiah Love\nTwelve Bells of Augsburg\nProducerOf\nPerson\nSong\n2026\n\n\nZachary Francis\nTwelve Bells of Augsburg\nPerformerOf\nPerson\nSong\n2026\n\n\nRobert Woods\nTwelve Bells of Augsburg\nLyricistOf\nPerson\nSong\n2026\n\n\nRobert Woods\nTwelve Bells of Augsburg\nPerformerOf\nPerson\nSong\n2026\n\n\nSean Jones\nPartisan’s Lament\nProducerOf\nPerson\nSong\n2030\n\n\nMin Long\nSusurros de Pasión\nLyricistOf\nPerson\nSong\n2004\n\n\nMin Long\nSusurros de Pasión\nPerformerOf\nPerson\nSong\n2004\n\n\nGang Shao\nSusurros de Pasión\nLyricistOf\nPerson\nSong\n2004\n\n\nGang Shao\nSusurros de Pasión\nPerformerOf\nPerson\nSong\n2004\n\n\nQiang Yuan\nSusurros de Pasión\nPerformerOf\nPerson\nSong\n2004\n\n\nWei Zhao\nSusurros de Pasión\nProducerOf\nPerson\nSong\n2004\n\n\nJuan Zhou\nSusurros de Pasión\nPerformerOf\nPerson\nSong\n2004\n\n\nYang Zhao\nSusurros de Pasión\nPerformerOf\nPerson\nSong\n2004\n\n\nXiulan Fang\nAltitude of Mistakes\nPerformerOf\nPerson\nSong\n2015\n\n\nQiang Liu\nAltitude of Mistakes\nComposerOf\nPerson\nSong\n2015\n\n\nQiang Liu\nAltitude of Mistakes\nPerformerOf\nPerson\nSong\n2015\n\n\nJun Qiao\nAltitude of Mistakes\nPerformerOf\nPerson\nSong\n2015\n\n\nMing Huang\nAltitude of Mistakes\nPerformerOf\nPerson\nSong\n2015\n\n\nSamantha Bullock\nPartisan’s Lament\nPerformerOf\nPerson\nSong\n2030\n\n\nShannon Harvey\nOur Inevitable Path\nPerformerOf\nPerson\nSong\n2017\n\n\nShannon Harvey\nOur Inevitable Path\nLyricistOf\nPerson\nSong\n2017\n\n\nShannon Harvey\nOur Inevitable Path\nComposerOf\nPerson\nSong\n2017\n\n\nLori Massey\nWhen the Bar Lights Go Up\nPerformerOf\nPerson\nSong\n2000\n\n\nLori Massey\nWhen the Bar Lights Go Up\nLyricistOf\nPerson\nSong\n2000\n\n\nSheryl Roman\nReflejo Interior\nPerformerOf\nPerson\nSong\n1983\n\n\nJohn Graves\nReflejo Interior\nComposerOf\nPerson\nSong\n1983\n\n\nJason Aguirre\nReflejo Interior\nPerformerOf\nPerson\nSong\n1983\n\n\nMatthew Lane\nReflejo Interior\nProducerOf\nPerson\nSong\n1983\n\n\nCipriano Peranda\nExoskeleton Dissolve\nComposerOf\nPerson\nSong\n2020\n\n\nIgor Dyś\nEchoes of Forgotten Light\nPerformerOf\nPerson\nSong\n2004\n\n\nIgor Dyś\nEchoes of Forgotten Light\nLyricistOf\nPerson\nSong\n2004\n\n\nTao Gao\nSilent Steps in the Forest’s Embrace\nPerformerOf\nPerson\nSong\n2023\n\n\nTao Gao\nSilent Steps in the Forest’s Embrace\nProducerOf\nPerson\nSong\n2023\n\n\nJoseph Ponce\nFür uns alle zusammen\nPerformerOf\nPerson\nSong\n2017\n\n\nHerbert Mcfarland\nFür uns alle zusammen\nPerformerOf\nPerson\nSong\n2017\n\n\nRachel Montes\nFür uns alle zusammen\nPerformerOf\nPerson\nSong\n2017\n\n\nCaitlin Miller\nFür uns alle zusammen\nLyricistOf\nPerson\nSong\n2017\n\n\nRebecca Wise\nFür uns alle zusammen\nPerformerOf\nPerson\nSong\n2017\n\n\nPing Liao\nDreamscape of Judgment\nLyricistOf\nPerson\nSong\n2023\n\n\nTrevor Bass\nDreamscape of Judgment\nPerformerOf\nPerson\nSong\n2023\n\n\nXiuying Du\nDreamscape of Judgment\nPerformerOf\nPerson\nSong\n2023\n\n\nXia Yuan\nDreamscape of Judgment\nPerformerOf\nPerson\nSong\n2023\n\n\nSandra Burke\nDreamscape of Judgment\nPerformerOf\nPerson\nSong\n2023\n\n\nYan Li\nDreamscape of Judgment\nComposerOf\nPerson\nSong\n2023\n\n\nYan Li\nDreamscape of Judgment\nPerformerOf\nPerson\nSong\n2023\n\n\nPing Jin\nParallel Memories\nLyricistOf\nPerson\nSong\n2028\n\n\nTao Wen\nParallel Memories\nPerformerOf\nPerson\nSong\n2028\n\n\nTao Wen\nParallel Memories\nProducerOf\nPerson\nSong\n2028\n\n\nGuiying Ren\nParallel Memories\nPerformerOf\nPerson\nSong\n2028\n\n\nLei Shi\nParallel Memories\nPerformerOf\nPerson\nSong\n2028\n\n\nWei Liang\nParallel Memories\nComposerOf\nPerson\nSong\n2028\n\n\nWei Liang\nParallel Memories\nPerformerOf\nPerson\nSong\n2028\n\n\nJoshua Taylor\nDivergent Memories\nPerformerOf\nPerson\nSong\n2017\n\n\nJoshua Taylor\nDivergent Memories\nLyricistOf\nPerson\nSong\n2017\n\n\nJoshua Taylor\nDivergent Memories\nComposerOf\nPerson\nSong\n2017\n\n\nLei Fu\nProvence Aria\nPerformerOf\nPerson\nSong\n2023\n\n\nLei Fu\nProvence Aria\nProducerOf\nPerson\nSong\n2023\n\n\nYan Dai\nProvence Aria\nLyricistOf\nPerson\nSong\n2023\n\n\nYan Dai\nProvence Aria\nPerformerOf\nPerson\nSong\n2023\n\n\nDaniel Mccormick\nProvence Aria\nPerformerOf\nPerson\nSong\n2023\n\n\nLei Jin\nProvence Aria\nPerformerOf\nPerson\nSong\n2023\n\n\nJames Medina\nCoastal Whispers of Biscay\nPerformerOf\nPerson\nSong\n2031\n\n\nMatthew Best\nCoastal Whispers of Biscay\nLyricistOf\nPerson\nSong\n2031\n\n\nMatthew Best\nCoastal Whispers of Biscay\nPerformerOf\nPerson\nSong\n2031\n\n\nLinda Burns\nCoastal Whispers of Biscay\nPerformerOf\nPerson\nSong\n2031\n\n\nBrooke Olson\nFolklore’s Heartbeat\nPerformerOf\nPerson\nSong\n2020\n\n\nDavid Reese\nExoskeleton Dissolve\nPerformerOf\nPerson\nSong\n2020\n\n\nRyan Dunlap\nExoskeleton Dissolve\nPerformerOf\nPerson\nSong\n2020\n\n\nElmo Calbo\nExoskeleton Dissolve\nPerformerOf\nPerson\nSong\n2020\n\n\nAmico Luciani\nExoskeleton Dissolve\nPerformerOf\nPerson\nSong\n2020\n\n\nWei Zhao\nSilent Steps in the Forest’s Embrace\nComposerOf\nPerson\nSong\n2023\n\n\nTao Hu\nFolklore’s Heartbeat\nComposerOf\nPerson\nSong\n2020\n\n\nTao Hu\nFolklore’s Heartbeat\nPerformerOf\nPerson\nSong\n2020\n\n\nMing Qiao\nThe Long Way Home\nLyricistOf\nPerson\nAlbum\n2023\n\n\nNa Ye\nThe Long Way Home\nPerformerOf\nPerson\nAlbum\n2023\n\n\nNa Ye\nThe Long Way Home\nProducerOf\nPerson\nAlbum\n2023\n\n\nDebra Graham\nWeathered Miles\nComposerOf\nPerson\nSong\n2023\n\n\nDebra Graham\nWeathered Miles\nPerformerOf\nPerson\nSong\n2023\n\n\nEdward Evans\nWeathered Miles\nLyricistOf\nPerson\nSong\n2023\n\n\nDylan Schwartz\nWeathered Miles\nPerformerOf\nPerson\nSong\n2023\n\n\nJames Henderson\nWeathered Miles\nPerformerOf\nPerson\nSong\n2023\n\n\nAmy Powell\nWeathered Miles\nProducerOf\nPerson\nSong\n2023\n\n\nShawn Johnson\nWeathered Miles\nProducerOf\nPerson\nSong\n2023\n\n\nJoel Long\nWeathered Miles\nPerformerOf\nPerson\nSong\n2023\n\n\nMichael Nixon\nWeathered Miles\nComposerOf\nPerson\nSong\n2023\n\n\nMichael Nixon\nWeathered Miles\nPerformerOf\nPerson\nSong\n2023\n\n\nNathan Jones\nWeathered Miles\nPerformerOf\nPerson\nSong\n2023\n\n\nKimberly Estrada\nTwilight’s Threshold\nPerformerOf\nPerson\nSong\n2007\n\n\nFang Ding\nTwilight’s Threshold\nPerformerOf\nPerson\nSong\n2007\n\n\nMiss Jennifer Williams\nThe Crown We Wear\nPerformerOf\nPerson\nSong\n2022\n\n\nWilliam Robinson\nThe Crown We Wear\nPerformerOf\nPerson\nSong\n2022\n\n\nWilliam Robinson\nThe Crown We Wear\nProducerOf\nPerson\nSong\n2022\n\n\nJudy Yang\nThe Crown We Wear\nPerformerOf\nPerson\nSong\n2022\n\n\nJoanna Avery\nThe Crown We Wear\nPerformerOf\nPerson\nSong\n2022\n\n\nMolly Gonzalez\nThe Crown We Wear\nPerformerOf\nPerson\nSong\n2022\n\n\nJuan Shi\nSacred Fragments\nPerformerOf\nPerson\nSong\n2003\n\n\nMing Zhou\nSacred Fragments\nPerformerOf\nPerson\nSong\n2003\n\n\nSimone Säuberlich\nHarvest Dance at Ler Valley\nComposerOf\nPerson\nSong\n2010\n\n\nSimone Säuberlich\nHarvest Dance at Ler Valley\nPerformerOf\nPerson\nSong\n2010\n\n\nOceanic Records\nThe Saltwater Weavers\nProducerOf\nRecordLabel\nMusicalGroup\nNA\n\n\nOceanic Records\nThe Tide Singer’s Knot\nProducerOf\nRecordLabel\nMusicalGroup\nNA\n\n\nOceanus Records\nThe Salty Wakes\nProducerOf\nRecordLabel\nMusicalGroup\nNA\n\n\nOceanus Records\nThe Fiddle & The Fjord\nProducerOf\nRecordLabel\nMusicalGroup\nNA\n\n\n\n\n\n\n\nFinal Visualization Summary: Direct and Indirect Influences on Sailor Shift\n\nFirst Layer: Nodes directly connected from Sailor Shift.\n\nIncludes:\nSongs and albums (these will propagate influence to the next layer)\nBands and record labels (no further propagation needed)\n\nSecond Layer: All works that are influenced by the first-layer songs/albums and are linked to other individuals.\nThird Layer: The creators, producers, and other contributors behind the second-layer works, completing the indirect influence chain.\n\n\n\nFinal Visualization Summary-Direct and Indirect Influences on Sailor Shift\nnodes_tbl &lt;- nodes_tbl %&gt;% mutate(index = row_number())\n\nsailor_index &lt;- nodes_tbl %&gt;%\n  filter(name == \"Sailor Shift\") %&gt;%\n  pull(index)\n\nedges_from_sailor &lt;- edges_tbl %&gt;%\n  filter(from == sailor_index)\n\nfirst_layer_info &lt;- edges_from_sailor %&gt;%\n  inner_join(nodes_tbl, by = c(\"to\" = \"index\")) %&gt;%\n  filter(`Node Type` %in% c(\"Song\", \"Album\", \"MusicalGroup\", \"RecordLabel\"))\n\nfirst_layer_targets &lt;- first_layer_info$to\n\ninfluence_edges &lt;- c(\"InStyleOf\", \"LyricalReferenceTo\", \"InterpolatesFrom\", \"CoverOf\", \"DirectlySamples\")\n\nedges_2nd &lt;- edges_tbl %&gt;%\n  filter(from %in% first_layer_targets & `Edge Type` %in% influence_edges)\n\ninfluenced_works &lt;- edges_2nd$to\nsongs_with_outgoing &lt;- unique(edges_2nd$from)\n\nperson_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"LyricistOf\", \"ProducerOf\")\n\nedges_people_to_2nd &lt;- edges_tbl %&gt;%\n  filter(\n    to %in% influenced_works,\n    `Edge Type` %in% person_edge_types\n  ) %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, `Node Type`), by = c(\"from\" = \"index\")) %&gt;%\n  rename(`From Node Type` = `Node Type`) %&gt;%\n  filter(`From Node Type` %in% c(\"Person\", \"RecordLabel\")) %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, `Node Type`, release_date), by = c(\"to\" = \"index\")) %&gt;%\n  rename(`To Node Type` = `Node Type`, release_date = release_date)\n\nfirst_layer_filtered &lt;- first_layer_info %&gt;%\n  filter(\n    (`Node Type` %in% c(\"Song\", \"Album\") & to %in% songs_with_outgoing) |\n    (`Node Type` %in% c(\"MusicalGroup\", \"RecordLabel\"))\n  )\n\nedges_from_sailor_filtered &lt;- edges_from_sailor %&gt;%\n  semi_join(first_layer_filtered, by = c(\"to\" = \"to\"))\n\nall_edges &lt;- bind_rows(\n  edges_from_sailor_filtered,\n  edges_2nd,\n  edges_people_to_2nd %&gt;% rename(from = from, to = to)\n)\n\nnode_ids &lt;- unique(c(all_edges$from, all_edges$to))\n\nnodes_subgraph &lt;- nodes_tbl %&gt;%\n  filter(index %in% node_ids) %&gt;%\n  transmute(\n    id = index,\n    label = name,\n    group = `Node Type`\n  )\n\nedges_subgraph &lt;- all_edges %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    label = `Edge Type`,\n    title = paste0(\"Edge Type: \", `Edge Type`, \"&lt;br&gt;Release: \", release_date)\n  )\n\n\n\nvisNetwork(nodes_subgraph, edges_subgraph, width = \"100%\", height = \"700px\") %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLegend(\n    useGroups = TRUE,\n    position = \"right\",\n  ) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(gravitationalConstant = -80),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\nWho has she been most influenced?\n\n\n\nThe visual network clearly illustrates that Sailor Shift is not an isolated creator, but rather a convergence point within a multi-layered web of artistic influence.\nShe is directly influenced by several notable works, such as Tides of Echos and Electric Reverie, which themselves are shaped by earlier compositions and artists.\nAmong the sources of influence, four musical groups play a key role, including her own band Ivy Echos. The remaining groups—such as The Saltwater Weavers, The Fiddle & the Fjord, and The Salty Wakes—are projects she was closely involved in, either as a producer or performer. This dual role highlights her position as both an influencer and a participant in collaborative creation.\nIn the third layer of the influence network, most of the connections are formed through InStyleOf and InterpolatesFrom edges, indicating that Sailor Shift primarily draws inspiration from the style and structural elements of earlier works. Only a few edges fall under CoverOf, suggesting that her creative process leans more toward reinterpretation and transformation rather than direct replication.\nThis cascading network of style, melody, and lyrical influence reflects not only her artistic lineage, but also reveals the broader creative transmission ecosystem within the Oceanus Folk community.\n\n\n\n\n\n2.Who has she collaborated with and directly or indirectly influenced? &\n\n\n3.How has she influenced collaborators of the broader Oceanus Folk community\n\nFirst we will first answer ：Who has she influenced ?\nAnd here is the directly neighbours :\n\nnodes_tbl &lt;- nodes_tbl %&gt;% mutate(index = row_number())\n\nsailor_index &lt;- nodes_tbl %&gt;%\n  filter(name == \"Sailor Shift\") %&gt;%\n  pull(index)\n\ninfluence_edges &lt;- c(\"InStyleOf\", \"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\")\n\nedges_from_sailor &lt;- edges_tbl %&gt;%\n  filter(to == sailor_index & `Edge Type` %in% influence_edges)\n\ninfluenced1 &lt;- edges_from_sailor %&gt;%\n  left_join(nodes_tbl, by = c(\"from\" = \"index\")) %&gt;%\n  select(name, `Edge Type`, everything())\n\n\nknitr::kable(influenced1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nEdge Type\nsource\ntarget\nkey\nfrom\nto\nNode Type\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\n\n\n\n\nCassette Future\nInStyleOf\n17022\n17255\n0\n17023\n17256\nMusicalGroup\nNA\nNA\nNA\nNA\n17022\nNA\nNA\nNA\n\n\nSilver Veil\nLyricalReferenceTo\n17032\n17255\n0\n17033\n17256\nMusicalGroup\nNA\nNA\nNA\nNA\n17032\nNA\nNA\nNA\n\n\nThe Phantom Operators\nInterpolatesFrom\n17063\n17255\n0\n17064\n17256\nMusicalGroup\nNA\nNA\nNA\nNA\n17063\nNA\nNA\nNA\n\n\nThe Hollow Monarchs\nInStyleOf\n17110\n17255\n0\n17111\n17256\nMusicalGroup\nNA\nNA\nNA\nNA\n17110\nNA\nNA\nNA\n\n\nCassian Storm\nLyricalReferenceTo\n17126\n17255\n0\n17127\n17256\nPerson\nNA\nNA\nNA\nNA\n17126\nNA\nSeraphina Vale\nNA\n\n\nClaire Holmes\nInterpolatesFrom\n17155\n17255\n0\n17156\n17256\nPerson\nNA\nNA\nNA\nNA\n17155\nNA\nJaye Finch\nNA\n\n\nCopper Canyon Ghosts\nDirectlySamples\n17361\n17255\n0\n17362\n17256\nMusicalGroup\nNA\nNA\nNA\nNA\n17361\nNA\nNA\nNA\n\n\n\n\n\n\n\nDirectly neighbours that she has influenced\nsubgraph_in &lt;- extract_subnetwork(\n  graph, \n  node_name = \"Sailor Shift\", \n  distance = 3, \n  direction = \"in\"\n)\n\nedges_vn &lt;- igraph::as_data_frame(subgraph_in, what = \"edges\") %&gt;%\n  filter(`Edge Type` != \"ProducerOf\") %&gt;%\n  rename(from = from, to = to, label = `Edge Type`)\n\nnodes_vn &lt;- igraph::as_data_frame(subgraph_in, what = \"vertices\") %&gt;%\n  mutate(id = name, label = name, group = `Node Type`)\n\nused_nodes &lt;- unique(c(edges_vn$from, edges_vn$to))\nnodes_vn &lt;- nodes_vn %&gt;% filter(id %in% used_nodes)\n\n\n\nvisNetwork(nodes_vn, edges_vn, height = \"800px\", width = \"100%\") %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 3, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\"\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1234) %&gt;%\n  visInteraction(navigationButtons = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nWho has she influenced directly or indirectly？\n\n\n\nThese are edges originating from Sailor Shift, indicating how she influences other groups or works:\n\nInStyleOf: stylistic influence or similar musical style\nInterpolatesFrom: portions of her work have been interpolated\nLyricalReferenceTo: her name or lyrics are referenced\nDirectlySamples: her work has been directly sampled\n\nSailor Shift has a broad creative influence\n\nShe influences at least 5 different groups (e.g., Cassette Future, The Hollow Monarchs)\nThe types of influence span style, lyrics, and sampling.\n\nAn indirect “sub-network” is formed\n\nFor example, through the path Sailor Shift → Cassette Future → Zara Quinn, her influence extends to band members as well.\n\nStrong structural centrality\n\nSailor Shift is the hub of this network, with nearly all edges revolving around her.\nThis suggests she holds a central position of influence in this music community.\n\n\n\nWe attempted to trace Sailor Shift’s indirect influence through songs and albums to identify impacted individuals. However, this approach yielded no results, so we decided not to pursue this path further.\nBased on the results, Copper Canyon Ghosts is identified as an Oceanus Folk band. To explore the third question—“How has Sailor Shift influenced collaborators within the broader Oceanus Folk community?”—we will examine both direct and indirect influence paths .\n\n\nIdentify the artists and groups influenced by Sailor Shift in Oceanus Folk Genre\nFirst, we identify the artists and groups influenced by Sailor Shift. Among them, we determine which ones belong to the Oceanus Folk genre, using “genre” as our key search indicator.\n\n\nwhich ones belong to the Oceanus Folk genre?\nnodes_tbl &lt;- nodes_tbl %&gt;% mutate(index = row_number())\n\ncreator_names &lt;- c(\n  \"Zara Quinn\", \"Milo Knight\", \"Cassette Future\", \"Eliza Brooks\",\n  \"Jasper Reed\", \"Silver Veil\", \"Juno Ray\", \"Savannah Teal\",\n  \"The Phantom Operators\", \"Chloe Montgomery\", \"Nathaniel Brooks\", \"Clara Davis\",\n  \"The Hollow Monarchs\", \"Cassian Storm\", \"Claire Holmes\", \"Beatrice Albright\",\n  \"Daniel O'Connell\", \"Copper Canyon Ghosts\"\n)\n\ncreator_ids &lt;- nodes_tbl %&gt;%\n  filter(name %in% creator_names) %&gt;%\n  pull(index)\n\ntarget_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"LyricistOf\", \"ProducerOf\")\n\nedges_out &lt;- edges_tbl %&gt;%\n  filter(from %in% creator_ids, `Edge Type` %in% target_edge_types)\n\nedges_out_full &lt;- edges_out %&gt;%\n  left_join(nodes_tbl %&gt;% mutate(index = row_number()), by = c(\"to\" = \"index\")) %&gt;%\n  select(from, to, `Edge Type`, name, `Node Type`, release_date,genre,notable,notoriety_date)\n\nedges_out_full &lt;- edges_out_full %&gt;%\n  left_join(nodes_tbl %&gt;% select(index, creator_name = name), by = c(\"from\" = \"index\")) %&gt;%\n  select(creator_name, `Edge Type`, name, `Node Type`, release_date,genre,notable,notoriety_date)\n\n\n\nedges_oceanus &lt;- edges_out_full %&gt;%\n  filter(genre == \"Oceanus Folk\")\n\nknitr::kable(head(edges_oceanus, 6))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncreator_name\nEdge Type\nname\nNode Type\nrelease_date\ngenre\nnotable\nnotoriety_date\n\n\n\n\nBeatrice Albright\nPerformerOf\nTidesworn Ballads\nAlbum\n2031\nOceanus Folk\nTRUE\nNA\n\n\nBeatrice Albright\nLyricistOf\nTidesworn Ballads\nAlbum\n2031\nOceanus Folk\nTRUE\nNA\n\n\nBeatrice Albright\nPerformerOf\nTidesworn Ballads\nAlbum\n2031\nOceanus Folk\nTRUE\nNA\n\n\nBeatrice Albright\nPerformerOf\nThe Siren’s Sigh\nSong\n2031\nOceanus Folk\nTRUE\n2031\n\n\nBeatrice Albright\nPerformerOf\nWhispers on the Jetty Wind\nSong\n2031\nOceanus Folk\nTRUE\n2031\n\n\nBeatrice Albright\nPerformerOf\nMoonlit Kelp Forest Dance\nSong\n2031\nOceanus Folk\nTRUE\n2031\n\n\n\n\n\nThis table summarizes the creative contributions of Beatrice Albright, Daniel O’Connell, and Copper Canyon Ghosts to various albums and songs—all of which are part of the Oceanus Folk genre\n\n\nHow has Sailor Shift influenced collaborators within the broader Oceanus Folk community?\nedges_sailor &lt;- edges_all %&gt;%\n  filter(to == \"Sailor Shift\") %&gt;%\n  filter(`Edge Type` %in% c(\"InStyleOf\", \"LyricalReferenceTo\", \"CoverOf\", \"InterpolatesFrom\", \"DirectlySamples\")) %&gt;%\n  select(from, to, `Edge Type`)\n\ncreator_work_nodes &lt;- unique(c(edges_oceanus$creator_name, edges_oceanus$name))\n\nall_node_names &lt;- union(\n  creator_work_nodes,\n  unique(c(edges_sailor$from, edges_sailor$to, \"Sailor Shift\", \"Copper Canyon Ghosts\"))  \n)\n\nnodes_vn &lt;- nodes_tbl %&gt;%\n  filter(name %in% all_node_names) %&gt;%\n  mutate(\n    id = index,\n    label = name,\n    group = `Node Type`,\n    color.background = ifelse(name == \"Sailor Shift\", \"blue\", NA), \n    shape = ifelse(name == \"Sailor Shift\", \"star\", \"dot\")\n  )\n\nedges_vn_creator &lt;- edges_oceanus %&gt;%\n  rename(from = creator_name, to = name, label = `Edge Type`) %&gt;%\n  left_join(nodes_vn %&gt;% select(name, id), by = c(\"from\" = \"name\")) %&gt;%\n  rename(from_id = id) %&gt;%\n  left_join(nodes_vn %&gt;% select(name, id), by = c(\"to\" = \"name\")) %&gt;%\n  rename(to_id = id) %&gt;%\n  mutate(length = NA) %&gt;%\n  select(from = from_id, to = to_id, label, length) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\nedges_vn_sailor &lt;- edges_sailor %&gt;%\n  left_join(nodes_vn %&gt;% select(name, id), by = c(\"from\" = \"name\")) %&gt;%\n  rename(from_id = id) %&gt;%\n  left_join(nodes_vn %&gt;% select(name, id), by = c(\"to\" = \"name\")) %&gt;%\n  rename(to_id = id) %&gt;%\n  mutate(length = NA) %&gt;%\n  select(from = from_id, to = to_id, label = `Edge Type`, length) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\nforced_edge &lt;- tibble(\n  from = \"Copper Canyon Ghosts\",\n  to = \"Sailor Shift\",\n  label = \"DirectlySamples\",\n  length = 400\n)\n\nforced_edge_ids &lt;- forced_edge %&gt;%\n  left_join(nodes_vn %&gt;% select(name, id), by = c(\"from\" = \"name\")) %&gt;%\n  rename(from_id = id) %&gt;%\n  left_join(nodes_vn %&gt;% select(name, id), by = c(\"to\" = \"name\")) %&gt;%\n  rename(to_id = id) %&gt;%\n  select(from = from_id, to = to_id, label, length) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\nedges_final &lt;- bind_rows(\n  edges_vn_creator,\n  edges_vn_sailor,\n  forced_edge_ids\n)\n\n\n\nvisNetwork(nodes_vn, edges_final, height = \"700px\", width = \"100%\") %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\"\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(gravitationalConstant = -80),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  )\n\n\n\n\n\n\n\n\n\n\n\nHow has Sailor Shift influenced collaborators within the broader Oceanus Folk community?\n\n\n\nSailor Shift → influences Copper Canyon Ghosts → performs representative works → connects with Daniel and Beatrice through shared creations\nThis influence pathway shows that Sailor Shift’s creative style and content are indirectly transmitted to other members of the Oceanus Folk community through collaborative performances and reinterpretations.\n\nThe network visualization reveals that Sailor Shift influences key figures in the Oceanus Folk scene both directly and indirectly.\n\nShe is sampled by Copper Canyon Ghosts, a band that performs major works composed by Daniel O’Connell and Beatrice Albright.\n\nThese shared works form the musical core of the Oceanus Folk genre, creating a multi-layered influence network with Sailor Shift at its source.\n\nHer creative impact extends beyond direct collaboration—spreading throughout the community via the chain of work → band → collaborators, shaping the genre’s evolution and collective identity.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#summary-of-question-1",
    "href": "Take-home_Exercise/Take-home_Ex02/Take-home_Ex02.html#summary-of-question-1",
    "title": "Take Home Exercise 2",
    "section": "Summary of Question 1",
    "text": "Summary of Question 1\nSailor Shift is both a cultural inheritor and a creative engine. She draws on decades of musical history, spanning genres from Synthwave to Americana, integrating them into the Oceanus Folk style. Through direct performances and indirect stylistic channels, she influences a wide web of collaborators and emerging artists—serving as a stylistic and structural anchor for the Oceanus Folk scene. Her work demonstrates a rare balance between solo artistry and community participation, making her a pivotal node in the evolution of this genre.",
    "crumbs": [
      "Home",
      "Take-home Exercise",
      "Take-home Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.\n\n\n\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, ggplot2,\n               patchwork,DT, tidyverse) \n\n\n\n\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\",show_col_types = FALSE)\n\n\n\n\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:red; #&lt;&lt;\nfont-style:bold; color:white;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\nNotice that the background colour of the tooltip is red and the font colour is white and bold.\n\n\n\n\n\n\n\n\n\n1.Change the color of tooltip_css(use_fill = TRUE)\n2.Add the Hover Interaction to (primary = “yellow”, secondary = “red”)\n3.Set tooltip will be fixed(argument use_cursor_pos is set to FALSE )\n4.Activate zoom\n\n\nShow the code\ntooltip_css &lt;- \"background-color:black; \nfont-style:bold; color:white;\"\n\ncss_default_hover &lt;- girafe_css_bicolor(primary = \"yellow\", secondary = \"red\")\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS , fill = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID,data_id = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 0.5, \n    dotsize = 3,\n    method = \"histodot\",\n    color = NA) +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL) +\n  scale_fill_viridis_c() +\n  theme_minimal()+\n  xlim(min(exam_data$MATHS) - 1, max(exam_data$MATHS) + 1)\n  \ngirafe(                                  \n  ggobj = p + scale_color_viridis_c() ,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(\n  opts_hover(css = css_default_hover),\n  opts_tooltip(\n  use_fill = TRUE,\n  offx = 50,\n  offy = 50, \n  use_cursor_pos = FALSE),\n  opts_zoom(min = 1, max = 4),\n  opts_sizing(rescale = TRUE),\n  opts_toolbar(saveaspng = FALSE, position = \"bottom\", delay_mouseout = 5000)\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo enable hover interaction, we need to include a data_id mapping in geom_dotplot_interactive().\n\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, linewidth = 0.2\n\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                          \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe reason that a large orange highlight when interacting is because data_id = CLASS will bind all students in the same class into the same interaction group\n\n\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)      \n\n\n\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\n\n\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, x = ~ENGLISH, y = ~MATHS, color = ~RACE)\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\n\n\n\n\n\n\n\n\n\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#learning-outcome",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#learning-outcome",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#getting-started",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#getting-started",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "First, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, ggplot2,\n               patchwork,DT, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#importing-data",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#importing-data",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "In this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\",show_col_types = FALSE)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "ggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactivity",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactivity",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactivity-1",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactivity-1",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:red; #&lt;&lt;\nfont-style:bold; color:white;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\nNotice that the background colour of the tooltip is red and the font colour is white and bold.\n\n\n\n\n\n\n\n\n\n1.Change the color of tooltip_css(use_fill = TRUE)\n2.Add the Hover Interaction to (primary = “yellow”, secondary = “red”)\n3.Set tooltip will be fixed(argument use_cursor_pos is set to FALSE )\n4.Activate zoom\n\n\nShow the code\ntooltip_css &lt;- \"background-color:black; \nfont-style:bold; color:white;\"\n\ncss_default_hover &lt;- girafe_css_bicolor(primary = \"yellow\", secondary = \"red\")\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS , fill = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID,data_id = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 0.5, \n    dotsize = 3,\n    method = \"histodot\",\n    color = NA) +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL) +\n  scale_fill_viridis_c() +\n  theme_minimal()+\n  xlim(min(exam_data$MATHS) - 1, max(exam_data$MATHS) + 1)\n  \ngirafe(                                  \n  ggobj = p + scale_color_viridis_c() ,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(\n  opts_hover(css = css_default_hover),\n  opts_tooltip(\n  use_fill = TRUE,\n  offx = 50,\n  offy = 50, \n  use_cursor_pos = FALSE),\n  opts_zoom(min = 1, max = 4),\n  opts_sizing(rescale = TRUE),\n  opts_toolbar(saveaspng = FALSE, position = \"bottom\", delay_mouseout = 5000)\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo enable hover interaction, we need to include a data_id mapping in geom_dotplot_interactive().\n\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, linewidth = 0.2\n\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                          \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe reason that a large orange highlight when interacting is because data_id = CLASS will bind all students in the same class into the same interaction group\n\n\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)      \n\n\n\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "Plotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, x = ~ENGLISH, y = ~MATHS, color = ~RACE)\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "Crosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#reference",
    "href": "Hands-on_Ex/Hands_on_Ex03/Hands-on_Ex03A.html#reference",
    "title": "Hands-on Exercise 3A",
    "section": "",
    "text": "This link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 3A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html",
    "title": "Hands-on Ex4B",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default.\n-   To follow best practices for statistical reporting. For all statistica\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#learning-outcome",
    "title": "Hands-on Ex4B",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Ex4B",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default.\n-   To follow best practices for statistical reporting. For all statistica",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#getting-started",
    "title": "Hands-on Ex4B",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 4B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\nThe downloaded binary packages are in\n    /var/folders/4g/tj66tkn119jgpd8qmnnpwhjm0000gn/T//RtmplmdjnH/downloaded_packages\n\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#overview",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\nThe downloaded binary packages are in\n    /var/folders/4g/tj66tkn119jgpd8qmnnpwhjm0000gn/T//RtmplmdjnH/downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#importing-data",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#funnelplotr-methods",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "In this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04D.html#references",
    "title": "Hands-on_Ex04D",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\n\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\n\n\n\n\n\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n#GAStech_edgess &lt;- read_csv(\"data/GAStech_email_edge.csv\")\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\n\n\nIn this section, we will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, we are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\nvisOptions(highlightNearest = list(enabled = T, hover = T), \n             nodesIdSelection = T)\n\n\n\n\n\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nAdding one more select by group.\n\nvisNetwork(GAStech_nodes, GAStech_edges_aggregated, \n           height = \"700px\", width = \"100%\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%   \n  visOptions(\n    selectedBy = \"group\",                       \n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nAdding Data Manipulation\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123) %&gt;% \n  visOptions(manipulation = TRUE)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\n\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\n\n\n\n\n\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n#GAStech_edgess &lt;- read_csv(\"data/GAStech_email_edge.csv\")\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "In this section, we will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, we are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise5",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\nvisOptions(highlightNearest = list(enabled = T, hover = T), \n             nodesIdSelection = T)\n\n\n\n\n\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nAdding one more select by group.\n\nvisNetwork(GAStech_nodes, GAStech_edges_aggregated, \n           height = \"700px\", width = \"100%\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%   \n  visOptions(\n    selectedBy = \"group\",                       \n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nAdding Data Manipulation\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123) %&gt;% \n  visOptions(manipulation = TRUE)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package.\n\n\n\nBefore we get started, we are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nStudents who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ninstall.packages(\"devtools\",dependencies = TRUE)\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\", force = TRUE)\n\n\nNow you are ready to launch d3treeR package\n\n\nlibrary(d3treeR)\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm,rootname = \"Singapore\" )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#overview",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "Before we get started, we are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#data-wrangling",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "In this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nStudents who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "treemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "treemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09E.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 09E",
    "section": "",
    "text": "This slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ninstall.packages(\"devtools\",dependencies = TRUE)\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\", force = TRUE)\n\n\nNow you are ready to launch d3treeR package\n\n\nlibrary(d3treeR)\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm,rootname = \"Singapore\" )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9E"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html",
    "title": "Hands on Exercise 9C",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data.\n\n\n\nBefore you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, we will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse,heatmaply)\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.\n\n\n\n\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, we will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix, Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\n\n\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, we should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. We are also required to have the user manualof the package handy with us for reference purposes.\nIn this section, we will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#overview",
    "title": "Hands on Exercise 9C",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#installing-and-launching-r-packages",
    "title": "Hands on Exercise 9C",
    "section": "",
    "text": "Before you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, we will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse,heatmaply)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#importing-and-preparing-the-data-set",
    "title": "Hands on Exercise 9C",
    "section": "",
    "text": "In this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#static-heatmap",
    "title": "Hands on Exercise 9C",
    "section": "",
    "text": "There are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, we will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix, Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09C.html#creating-interactive-heatmap",
    "title": "Hands on Exercise 9C",
    "section": "",
    "text": "heatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, we should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. We are also required to have the user manualof the package handy with us for reference purposes.\nIn this section, we will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 9C"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for you to read the functional description of each function before using them.\n\n\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/yangyayong/Downloads/School/smu/yyyirene/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex08/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\n\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\nGeoDataFrame (geospatial data frame, from geopandas), which automatically displays only the first 10 records when printing or displaying data, to prevent the interface from being stuck or too much information to read due to rendering a large amount of complex geometry data at one time.\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntmap_mode(\"view\")  \ntmap_options(check.and.fix = TRUE)  \n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\nthings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"jenks\", n = 5) +\n  tm_borders(lwd = 0.01, alpha = 0.5)\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 5) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\ntmap_mode(\"plot\")\n\ntm_equal &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 5, title = \"Equal Intervals\") +\n  tm_borders()\n\ntm_quantile &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"quantile\", n = 5, title = \"Quantiles\") +\n  tm_borders()\n\ntm_jenks &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"jenks\", n = 5, title = \"Jenks Breaks\") +\n  tm_borders()\n\ntm_kmeans &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"kmeans\", n = 5, title = \"K-means\") +\n  tm_borders()\n\ntmap_arrange(tm_equal, tm_quantile, tm_jenks, tm_kmeans, ncol = 2)\n\n\n\n\n\n\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\ntm_n2 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 2, title = \"n = 2\") +\n  tm_borders()\n\ntm_n6 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 6, title = \"n = 6\") +\n  tm_borders()\n\ntm_n10 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 10, title = \"n = 10\") +\n  tm_borders()\n\ntm_n20 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 20, title = \"n = 20\") +\n  tm_borders()\n\ntmap_arrange(tm_n2, tm_n6, tm_n10, tm_n20, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\", \n              n = 5, \n              palette = \"Greens\") +    \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\n    col = \"DEPENDENCY\",        \n    style = \"quantile\",\n    n = 5,\n    palette = \"Blues\",         \n    title = \"Dependency Ratio\"  \n  ) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    frame = TRUE,\n    title = \"Distribution of Dependency Ratio by Planning Subzone\"\n  ) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\n    \"Source: Planning Sub-zone boundary from URA\\nand Population data from DOS\",\n    position = c(\"left\", \"bottom\")\n  )\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#overview",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for you to read the functional description of each function before using them.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#getting-started",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#importing-data-into-r",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/yangyayong/Downloads/School/smu/yyyirene/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex08/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\n\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\nGeoDataFrame (geospatial data frame, from geopandas), which automatically displays only the first 10 records when printing or displaying data, to prevent the interface from being stuck or too much information to read due to rendering a large amount of complex geometry data at one time.\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntmap_mode(\"view\")  \ntmap_options(check.and.fix = TRUE)  \n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\nthings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"jenks\", n = 5) +\n  tm_borders(lwd = 0.01, alpha = 0.5)\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 5) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\ntmap_mode(\"plot\")\n\ntm_equal &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 5, title = \"Equal Intervals\") +\n  tm_borders()\n\ntm_quantile &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"quantile\", n = 5, title = \"Quantiles\") +\n  tm_borders()\n\ntm_jenks &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"jenks\", n = 5, title = \"Jenks Breaks\") +\n  tm_borders()\n\ntm_kmeans &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"kmeans\", n = 5, title = \"K-means\") +\n  tm_borders()\n\ntmap_arrange(tm_equal, tm_quantile, tm_jenks, tm_kmeans, ncol = 2)\n\n\n\n\n\n\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\ntm_n2 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 2, title = \"n = 2\") +\n  tm_borders()\n\ntm_n6 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 6, title = \"n = 6\") +\n  tm_borders()\n\ntm_n10 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 10, title = \"n = 10\") +\n  tm_borders()\n\ntm_n20 &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n = 20, title = \"n = 20\") +\n  tm_borders()\n\ntmap_arrange(tm_n2, tm_n6, tm_n10, tm_n20, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\", \n              n = 5, \n              palette = \"Greens\") +    \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\n    col = \"DEPENDENCY\",        \n    style = \"quantile\",\n    n = 5,\n    palette = \"Blues\",         \n    title = \"Dependency Ratio\"  \n  ) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    frame = TRUE,\n    title = \"Distribution of Dependency Ratio by Planning Subzone\"\n  ) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\n    \"Source: Planning Sub-zone boundary from URA\\nand Population data from DOS\",\n    position = c(\"left\", \"bottom\")\n  )\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08A.html#reference",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8A"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#learning-outcome",
    "title": "Hands-on Exercise 8.2",
    "section": "Learning outcome",
    "text": "Learning outcome\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#the-data",
    "title": "Hands-on Exercise 8.2",
    "section": "The data",
    "text": "The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#data-import-and-preparation",
    "title": "Hands-on Exercise 8.2",
    "section": "Data Import and Preparation",
    "text": "Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 8.2",
    "section": "Creating a sf data frame from an aspatial data frame",
    "text": "Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\n\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 8.2",
    "section": "It all started with an interactive point symbol map",
    "text": "It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) + \n  tm_symbols(col = \"red\", \n             size = 1, \n             border.col = \"black\", \n             border.lwd = 1)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 8.2",
    "section": "Lets make it proportional",
    "text": "Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) + \n  tm_symbols(col = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n              border.col = \"black\", \n             border.lwd = 1)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 8.2",
    "section": "Lets give it a different colour",
    "text": "Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf) + \n  tm_symbols(col = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             border.col = \"black\",\n              border.lwd  = 1)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#i-have-a-twin-brothers",
    "title": "Hands-on Exercise 8.2",
    "section": "I have a twin brothers :)",
    "text": "I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(col = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             border.col = \"black\", \n             border.lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#all-about-tmap-package",
    "title": "Hands-on Exercise 8.2",
    "section": "All about tmap package",
    "text": "All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 8.2",
    "section": "Geospatial data wrangling",
    "text": "Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08B.html#data-wrangling",
    "title": "Hands-on Exercise 8.2",
    "section": "Data wrangling",
    "text": "Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 8B"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise6",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nIn this section, we will learn how to plot a calender heatmap programmatically by using ggplot2 package.\nBy the end of this section, will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n放图\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  #theme_tufte(base_family = \"Helvetica\")\n  theme_minimal(base_family = \"Helvetica\") +\ntheme(\n  panel.grid.major = element_line(color = \"white\"),     \n  panel.grid.minor = element_blank(),                   \n  panel.background = element_rect(fill = \"gray90\"),     \n  strip.background = element_rect(fill = \"gray70\"),     \n  plot.title = element_text(hjust = 0, face = \"bold\"),  \n  axis.text.x = element_text(angle = 90, hjust = 1)     \n)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 6"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise6",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 6"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise6",
    "section": "",
    "text": "Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 6"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise6",
    "section": "",
    "text": "In this section, we will learn how to plot a calender heatmap programmatically by using ggplot2 package.\nBy the end of this section, will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 6"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise6",
    "section": "",
    "text": "In this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n放图\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  #theme_tufte(base_family = \"Helvetica\")\n  theme_minimal(base_family = \"Helvetica\") +\ntheme(\n  panel.grid.major = element_line(color = \"white\"),     \n  panel.grid.minor = element_blank(),                   \n  panel.background = element_rect(fill = \"gray90\"),     \n  strip.background = element_rect(fill = \"gray70\"),     \n  plot.title = element_text(hjust = 0, face = \"bold\"),  \n  axis.text.x = element_text(angle = 90, hjust = 1)     \n)",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 6"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise6",
    "section": "",
    "text": "In this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor.",
    "crumbs": [
      "Home",
      "Hands-on Exercise",
      "Hands-on Exercise 6"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications.In this website, you will find my coursework prepared for this course.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html",
    "title": "In-class Ex4",
    "section": "",
    "text": "The ggstatsplot package offers a convenient way to generate various types of plots by adjusting a few parameters.\nBasic plots are effective for exploratory analysis and initial insights, whereas statistically enriched plots are valuable for drawing conclusions and supporting scientific reasoning.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nTwo-sample mean test: ggbetweenstats()\nFor example changing the type from\nnp : This one is showing median.\np : This will show mean value.\nr : This plot has remove the outliers.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"p\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"r\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you need show the statistic information,it would better advise to use ggstatsplot instead of ggplot2.\n\n\nThe difference between marginal = FALSE and marginal = TRUE\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  )\n\n\n\n\n\n\n\n\nCompare to what we learn from DAL mosaic plot and the plot belowed:\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\nThe one can reflect the insights for Significant Test of Association within the target group"
  }
]